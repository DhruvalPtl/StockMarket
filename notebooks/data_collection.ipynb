{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0dce67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to Groww!\n",
      "Logged into Groww!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from growwapi import GrowwAPI\n",
    "\n",
    "# --- CREDENTIALS ---\n",
    "API_KEY = \"eyJraWQiOiJaTUtjVXciLCJhbGciOiJFUzI1NiJ9.eyJleHAiOjI1NTM1Njg0NzYsImlhdCI6MTc2NTE2ODQ3NiwibmJmIjoxNzY1MTY4NDc2LCJzdWIiOiJ7XCJ0b2tlblJlZklkXCI6XCJhMTg3NDVhMy1hN2M1LTRlOTQtODE1MS1lZjUxZDQ5OGE2Y2RcIixcInZlbmRvckludGVncmF0aW9uS2V5XCI6XCJlMzFmZjIzYjA4NmI0MDZjODg3NGIyZjZkODQ5NTMxM1wiLFwidXNlckFjY291bnRJZFwiOlwiMDdmMDA0MGMtZTk4Zi00ZDNmLTk5Y2EtZDc1ZjBlYWU5M2NlXCIsXCJkZXZpY2VJZFwiOlwiZDMyMWIxMzUtZWQ5Mi01ZWJkLWJjMDUtZTY1NDY2OWRiMDM5XCIsXCJzZXNzaW9uSWRcIjpcIjBlOWMyYWZmLTM0NzktNDUyMi1iODE4LTczNTZlMzFkYmY1Y1wiLFwiYWRkaXRpb25hbERhdGFcIjpcIno1NC9NZzltdjE2WXdmb0gvS0EwYk1yOE5XVzhzdTNvZ080am1ZUzIwZEpSTkczdTlLa2pWZDNoWjU1ZStNZERhWXBOVi9UOUxIRmtQejFFQisybTdRPT1cIixcInJvbGVcIjpcImF1dGgtdG90cFwiLFwic291cmNlSXBBZGRyZXNzXCI6XCIyNDA5OjQwOTA6MTA4ZjpkYzA1OjNkMWQ6MWZmMDo1YWFjOjYwNTYsMTcyLjcxLjE5OC4xOSwzNS4yNDEuMjMuMTIzXCIsXCJ0d29GYUV4cGlyeVRzXCI6MjU1MzU2ODQ3NjQzNn0iLCJpc3MiOiJhcGV4LWF1dGgtcHJvZC1hcHAifQ.VuAMgqoC3e32gduObByNz97jFfG-ikXoREum26XPkvyMpj9JgCedXBI81jxGTPTrZD9i1wIL0s38LPd9vc9ApA\"\n",
    "API_SECRET = \"xy0sbQ4r*!HN3&&UKc9vpwti4xx8PR)(\"\n",
    "\n",
    "def auth():\n",
    "    try:\n",
    "        token = GrowwAPI.get_access_token(api_key=API_KEY, secret=API_SECRET)\n",
    "        return GrowwAPI(token)\n",
    "    except Exception as e:\n",
    "        print(f\"Auth failed: {e}\")\n",
    "        exit()\n",
    "\n",
    "groww = auth()\n",
    "print(\"Logged into Groww!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f5e52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANDLE_INTERVAL_DAY\n",
      "CANDLE_INTERVAL_HOUR_1\n",
      "CANDLE_INTERVAL_HOUR_4\n",
      "CANDLE_INTERVAL_MIN_1\n",
      "CANDLE_INTERVAL_MIN_10\n",
      "CANDLE_INTERVAL_MIN_15\n",
      "CANDLE_INTERVAL_MIN_2\n",
      "CANDLE_INTERVAL_MIN_3\n",
      "CANDLE_INTERVAL_MIN_30\n",
      "CANDLE_INTERVAL_MIN_5\n",
      "CANDLE_INTERVAL_MONTH\n",
      "CANDLE_INTERVAL_WEEK\n",
      "EXCHANGE_BSE\n",
      "EXCHANGE_MCX\n",
      "EXCHANGE_MCXSX\n",
      "EXCHANGE_NCDEX\n",
      "EXCHANGE_NSE\n",
      "EXCHANGE_US\n",
      "INSTRUMENT_CSV_URL\n",
      "ORDER_TYPE_LIMIT\n",
      "ORDER_TYPE_MARKET\n",
      "ORDER_TYPE_STOP_LOSS\n",
      "ORDER_TYPE_STOP_LOSS_MARKET\n",
      "PRODUCT_ARBITRAGE\n",
      "PRODUCT_BO\n",
      "PRODUCT_CNC\n",
      "PRODUCT_CO\n",
      "PRODUCT_MIS\n",
      "PRODUCT_MTF\n",
      "PRODUCT_NRML\n",
      "SEGMENT_CASH\n",
      "SEGMENT_COMMODITY\n",
      "SEGMENT_CURRENCY\n",
      "SEGMENT_FNO\n",
      "SMART_ORDER_STATUS_ACTIVE\n",
      "SMART_ORDER_STATUS_CANCELLED\n",
      "SMART_ORDER_STATUS_COMPLETED\n",
      "SMART_ORDER_STATUS_EXPIRED\n",
      "SMART_ORDER_STATUS_FAILED\n",
      "SMART_ORDER_STATUS_TRIGGERED\n",
      "SMART_ORDER_TYPE_GTT\n",
      "SMART_ORDER_TYPE_OCO\n",
      "TRANSACTION_TYPE_BUY\n",
      "TRANSACTION_TYPE_SELL\n",
      "TRIGGER_DIRECTION_DOWN\n",
      "TRIGGER_DIRECTION_UP\n",
      "VALIDITY_DAY\n",
      "VALIDITY_EOS\n",
      "VALIDITY_GTC\n",
      "VALIDITY_GTD\n",
      "VALIDITY_IOC\n",
      "_ERROR_MAP\n",
      "_GROWW_GENERATE_SOCKET_TOKEN_URL\n",
      "__annotate_func__\n",
      "__class__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__firstlineno__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__getstate__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__sizeof__\n",
      "__static_attributes__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "_build_headers\n",
      "_build_request_data\n",
      "_display_changelog\n",
      "_download_and_load_instruments\n",
      "_generate_checksum\n",
      "_get_changelog\n",
      "_load_instruments\n",
      "_parse_response\n",
      "_request_get\n",
      "_request_post\n",
      "_request_put\n",
      "cancel_order\n",
      "cancel_smart_order\n",
      "create_smart_order\n",
      "generate_socket_token\n",
      "get_access_token\n",
      "get_all_instruments\n",
      "get_available_margin_details\n",
      "get_contracts\n",
      "get_expiries\n",
      "get_greeks\n",
      "get_historical_candle_data\n",
      "get_historical_candles\n",
      "get_holdings_for_user\n",
      "get_instrument_by_exchange_and_trading_symbol\n",
      "get_instrument_by_exchange_token\n",
      "get_instrument_by_groww_symbol\n",
      "get_ltp\n",
      "get_ohlc\n",
      "get_option_chain\n",
      "get_order_detail\n",
      "get_order_list\n",
      "get_order_margin_details\n",
      "get_order_status\n",
      "get_order_status_by_reference\n",
      "get_position_for_trading_symbol\n",
      "get_positions_for_user\n",
      "get_quote\n",
      "get_smart_order\n",
      "get_smart_order_list\n",
      "get_trade_list_for_order\n",
      "get_user_profile\n",
      "modify_order\n",
      "modify_smart_order\n",
      "place_order\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Get a list of all attributes in the 'math' module\n",
    "math_attributes = dir(GrowwAPI)\n",
    "\n",
    "# Print each attribute\n",
    "for attribute in math_attributes:\n",
    "    print(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f102cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "# The new method requires these specific strings\n",
    "SYMBOL = \"NSE-NIFTY\" \n",
    "EXCHANGE = \"NSE\"         \n",
    "SEGMENT = \"CASH\"       \n",
    "INTERVAL = \"1minute\"           \n",
    "# --- CHUNKING LOGIC ---\n",
    "total_days = 3994\n",
    "chunk_size_days = 5\n",
    "end_date = pd.Timestamp.now()\n",
    "start_date = end_date - timedelta(days=total_days)\n",
    "\n",
    "all_candles = []\n",
    "current_start = start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batched download for NSE-NIFTY (CASH)...\n",
      "Fetching: 2015-01-01 12:17:12 -> 2015-01-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-01-06 12:17:12 -> 2015-01-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-01-11 12:17:12 -> 2015-01-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-01-16 12:17:12 -> 2015-01-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-01-21 12:17:12 -> 2015-01-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-01-26 12:17:12 -> 2015-01-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-01-31 12:17:12 -> 2015-02-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-02-05 12:17:12 -> 2015-02-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-02-10 12:17:12 -> 2015-02-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-02-15 12:17:12 -> 2015-02-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-02-20 12:17:12 -> 2015-02-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-02-25 12:17:12 -> 2015-03-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-03-02 12:17:12 -> 2015-03-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-03-07 12:17:12 -> 2015-03-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-03-12 12:17:12 -> 2015-03-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-03-17 12:17:12 -> 2015-03-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-03-22 12:17:12 -> 2015-03-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-03-27 12:17:12 -> 2015-04-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-04-01 12:17:12 -> 2015-04-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-04-06 12:17:12 -> 2015-04-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-04-11 12:17:12 -> 2015-04-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-04-16 12:17:12 -> 2015-04-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-04-21 12:17:12 -> 2015-04-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-04-26 12:17:12 -> 2015-05-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-05-01 12:17:12 -> 2015-05-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-05-06 12:17:12 -> 2015-05-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-05-11 12:17:12 -> 2015-05-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-05-16 12:17:12 -> 2015-05-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-05-21 12:17:12 -> 2015-05-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-05-26 12:17:12 -> 2015-05-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-05-31 12:17:12 -> 2015-06-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-06-05 12:17:12 -> 2015-06-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-06-10 12:17:12 -> 2015-06-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-06-15 12:17:12 -> 2015-06-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-06-20 12:17:12 -> 2015-06-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-06-25 12:17:12 -> 2015-06-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-06-30 12:17:12 -> 2015-07-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-07-05 12:17:12 -> 2015-07-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-07-10 12:17:12 -> 2015-07-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-07-15 12:17:12 -> 2015-07-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-07-20 12:17:12 -> 2015-07-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-07-25 12:17:12 -> 2015-07-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-07-30 12:17:12 -> 2015-08-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-08-04 12:17:12 -> 2015-08-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-08-09 12:17:12 -> 2015-08-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-08-14 12:17:12 -> 2015-08-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-08-19 12:17:12 -> 2015-08-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-08-24 12:17:12 -> 2015-08-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-08-29 12:17:12 -> 2015-09-03 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-09-03 12:17:12 -> 2015-09-08 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-09-08 12:17:12 -> 2015-09-13 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-09-13 12:17:12 -> 2015-09-18 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-09-18 12:17:12 -> 2015-09-23 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-09-23 12:17:12 -> 2015-09-28 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-09-28 12:17:12 -> 2015-10-03 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-10-03 12:17:12 -> 2015-10-08 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-10-08 12:17:12 -> 2015-10-13 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-10-13 12:17:12 -> 2015-10-18 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-10-18 12:17:12 -> 2015-10-23 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-10-23 12:17:12 -> 2015-10-28 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-10-28 12:17:12 -> 2015-11-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-11-02 12:17:12 -> 2015-11-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-11-07 12:17:12 -> 2015-11-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-11-12 12:17:12 -> 2015-11-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-11-17 12:17:12 -> 2015-11-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-11-22 12:17:12 -> 2015-11-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-11-27 12:17:12 -> 2015-12-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-12-02 12:17:12 -> 2015-12-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-12-07 12:17:12 -> 2015-12-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-12-12 12:17:12 -> 2015-12-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-12-17 12:17:12 -> 2015-12-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-12-22 12:17:12 -> 2015-12-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2015-12-27 12:17:12 -> 2016-01-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-01-01 12:17:12 -> 2016-01-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-01-06 12:17:12 -> 2016-01-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-01-11 12:17:12 -> 2016-01-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-01-16 12:17:12 -> 2016-01-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-01-21 12:17:12 -> 2016-01-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-01-26 12:17:12 -> 2016-01-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-01-31 12:17:12 -> 2016-02-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-02-05 12:17:12 -> 2016-02-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-02-10 12:17:12 -> 2016-02-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-02-15 12:17:12 -> 2016-02-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-02-20 12:17:12 -> 2016-02-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-02-25 12:17:12 -> 2016-03-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-03-01 12:17:12 -> 2016-03-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-03-06 12:17:12 -> 2016-03-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-03-11 12:17:12 -> 2016-03-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-03-16 12:17:12 -> 2016-03-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-03-21 12:17:12 -> 2016-03-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-03-26 12:17:12 -> 2016-03-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-03-31 12:17:12 -> 2016-04-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-04-05 12:17:12 -> 2016-04-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-04-10 12:17:12 -> 2016-04-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-04-15 12:17:12 -> 2016-04-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-04-20 12:17:12 -> 2016-04-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-04-25 12:17:12 -> 2016-04-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-04-30 12:17:12 -> 2016-05-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-05-05 12:17:12 -> 2016-05-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-05-10 12:17:12 -> 2016-05-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-05-15 12:17:12 -> 2016-05-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-05-20 12:17:12 -> 2016-05-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-05-25 12:17:12 -> 2016-05-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-05-30 12:17:12 -> 2016-06-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-06-04 12:17:12 -> 2016-06-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-06-09 12:17:12 -> 2016-06-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-06-14 12:17:12 -> 2016-06-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-06-19 12:17:12 -> 2016-06-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-06-24 12:17:12 -> 2016-06-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-06-29 12:17:12 -> 2016-07-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-07-04 12:17:12 -> 2016-07-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-07-09 12:17:12 -> 2016-07-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-07-14 12:17:12 -> 2016-07-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-07-19 12:17:12 -> 2016-07-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-07-24 12:17:12 -> 2016-07-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-07-29 12:17:12 -> 2016-08-03 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-08-03 12:17:12 -> 2016-08-08 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-08-08 12:17:12 -> 2016-08-13 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-08-13 12:17:12 -> 2016-08-18 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-08-18 12:17:12 -> 2016-08-23 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-08-23 12:17:12 -> 2016-08-28 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-08-28 12:17:12 -> 2016-09-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-09-02 12:17:12 -> 2016-09-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-09-07 12:17:12 -> 2016-09-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-09-12 12:17:12 -> 2016-09-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-09-17 12:17:12 -> 2016-09-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-09-22 12:17:12 -> 2016-09-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-09-27 12:17:12 -> 2016-10-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-10-02 12:17:12 -> 2016-10-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-10-07 12:17:12 -> 2016-10-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-10-12 12:17:12 -> 2016-10-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-10-17 12:17:12 -> 2016-10-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-10-22 12:17:12 -> 2016-10-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-10-27 12:17:12 -> 2016-11-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-11-01 12:17:12 -> 2016-11-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-11-06 12:17:12 -> 2016-11-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-11-11 12:17:12 -> 2016-11-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-11-16 12:17:12 -> 2016-11-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-11-21 12:17:12 -> 2016-11-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-11-26 12:17:12 -> 2016-12-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-12-01 12:17:12 -> 2016-12-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-12-06 12:17:12 -> 2016-12-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-12-11 12:17:12 -> 2016-12-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-12-16 12:17:12 -> 2016-12-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-12-21 12:17:12 -> 2016-12-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-12-26 12:17:12 -> 2016-12-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2016-12-31 12:17:12 -> 2017-01-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-01-05 12:17:12 -> 2017-01-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-01-10 12:17:12 -> 2017-01-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-01-15 12:17:12 -> 2017-01-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-01-20 12:17:12 -> 2017-01-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-01-25 12:17:12 -> 2017-01-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-01-30 12:17:12 -> 2017-02-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-02-04 12:17:12 -> 2017-02-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-02-09 12:17:12 -> 2017-02-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-02-14 12:17:12 -> 2017-02-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-02-19 12:17:12 -> 2017-02-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-02-24 12:17:12 -> 2017-03-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-03-01 12:17:12 -> 2017-03-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-03-06 12:17:12 -> 2017-03-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-03-11 12:17:12 -> 2017-03-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-03-16 12:17:12 -> 2017-03-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-03-21 12:17:12 -> 2017-03-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-03-26 12:17:12 -> 2017-03-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-03-31 12:17:12 -> 2017-04-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-04-05 12:17:12 -> 2017-04-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-04-10 12:17:12 -> 2017-04-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-04-15 12:17:12 -> 2017-04-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-04-20 12:17:12 -> 2017-04-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-04-25 12:17:12 -> 2017-04-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-04-30 12:17:12 -> 2017-05-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-05-05 12:17:12 -> 2017-05-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-05-10 12:17:12 -> 2017-05-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-05-15 12:17:12 -> 2017-05-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-05-20 12:17:12 -> 2017-05-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-05-25 12:17:12 -> 2017-05-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-05-30 12:17:12 -> 2017-06-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-06-04 12:17:12 -> 2017-06-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-06-09 12:17:12 -> 2017-06-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-06-14 12:17:12 -> 2017-06-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-06-19 12:17:12 -> 2017-06-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-06-24 12:17:12 -> 2017-06-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-06-29 12:17:12 -> 2017-07-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-07-04 12:17:12 -> 2017-07-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-07-09 12:17:12 -> 2017-07-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-07-14 12:17:12 -> 2017-07-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-07-19 12:17:12 -> 2017-07-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-07-24 12:17:12 -> 2017-07-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-07-29 12:17:12 -> 2017-08-03 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-08-03 12:17:12 -> 2017-08-08 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-08-08 12:17:12 -> 2017-08-13 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-08-13 12:17:12 -> 2017-08-18 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-08-18 12:17:12 -> 2017-08-23 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-08-23 12:17:12 -> 2017-08-28 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-08-28 12:17:12 -> 2017-09-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-09-02 12:17:12 -> 2017-09-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-09-07 12:17:12 -> 2017-09-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-09-12 12:17:12 -> 2017-09-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-09-17 12:17:12 -> 2017-09-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-09-22 12:17:12 -> 2017-09-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-09-27 12:17:12 -> 2017-10-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-10-02 12:17:12 -> 2017-10-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-10-07 12:17:12 -> 2017-10-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-10-12 12:17:12 -> 2017-10-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-10-17 12:17:12 -> 2017-10-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-10-22 12:17:12 -> 2017-10-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-10-27 12:17:12 -> 2017-11-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-11-01 12:17:12 -> 2017-11-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-11-06 12:17:12 -> 2017-11-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-11-11 12:17:12 -> 2017-11-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-11-16 12:17:12 -> 2017-11-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-11-21 12:17:12 -> 2017-11-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-11-26 12:17:12 -> 2017-12-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-12-01 12:17:12 -> 2017-12-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-12-06 12:17:12 -> 2017-12-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-12-11 12:17:12 -> 2017-12-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-12-16 12:17:12 -> 2017-12-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-12-21 12:17:12 -> 2017-12-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-12-26 12:17:12 -> 2017-12-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2017-12-31 12:17:12 -> 2018-01-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-01-05 12:17:12 -> 2018-01-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-01-10 12:17:12 -> 2018-01-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-01-15 12:17:12 -> 2018-01-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-01-20 12:17:12 -> 2018-01-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-01-25 12:17:12 -> 2018-01-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-01-30 12:17:12 -> 2018-02-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-02-04 12:17:12 -> 2018-02-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-02-09 12:17:12 -> 2018-02-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-02-14 12:17:12 -> 2018-02-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-02-19 12:17:12 -> 2018-02-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-02-24 12:17:12 -> 2018-03-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-03-01 12:17:12 -> 2018-03-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-03-06 12:17:12 -> 2018-03-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-03-11 12:17:12 -> 2018-03-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-03-16 12:17:12 -> 2018-03-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-03-21 12:17:12 -> 2018-03-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-03-26 12:17:12 -> 2018-03-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-03-31 12:17:12 -> 2018-04-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-04-05 12:17:12 -> 2018-04-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-04-10 12:17:12 -> 2018-04-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-04-15 12:17:12 -> 2018-04-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-04-20 12:17:12 -> 2018-04-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-04-25 12:17:12 -> 2018-04-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-04-30 12:17:12 -> 2018-05-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-05-05 12:17:12 -> 2018-05-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-05-10 12:17:12 -> 2018-05-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-05-15 12:17:12 -> 2018-05-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-05-20 12:17:12 -> 2018-05-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-05-25 12:17:12 -> 2018-05-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-05-30 12:17:12 -> 2018-06-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-06-04 12:17:12 -> 2018-06-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-06-09 12:17:12 -> 2018-06-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-06-14 12:17:12 -> 2018-06-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-06-19 12:17:12 -> 2018-06-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-06-24 12:17:12 -> 2018-06-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-06-29 12:17:12 -> 2018-07-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-07-04 12:17:12 -> 2018-07-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-07-09 12:17:12 -> 2018-07-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-07-14 12:17:12 -> 2018-07-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-07-19 12:17:12 -> 2018-07-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-07-24 12:17:12 -> 2018-07-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-07-29 12:17:12 -> 2018-08-03 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-08-03 12:17:12 -> 2018-08-08 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-08-08 12:17:12 -> 2018-08-13 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-08-13 12:17:12 -> 2018-08-18 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-08-18 12:17:12 -> 2018-08-23 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-08-23 12:17:12 -> 2018-08-28 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-08-28 12:17:12 -> 2018-09-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-09-02 12:17:12 -> 2018-09-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-09-07 12:17:12 -> 2018-09-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-09-12 12:17:12 -> 2018-09-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-09-17 12:17:12 -> 2018-09-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-09-22 12:17:12 -> 2018-09-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-09-27 12:17:12 -> 2018-10-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-10-02 12:17:12 -> 2018-10-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-10-07 12:17:12 -> 2018-10-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-10-12 12:17:12 -> 2018-10-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-10-17 12:17:12 -> 2018-10-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-10-22 12:17:12 -> 2018-10-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-10-27 12:17:12 -> 2018-11-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-11-01 12:17:12 -> 2018-11-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-11-06 12:17:12 -> 2018-11-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-11-11 12:17:12 -> 2018-11-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-11-16 12:17:12 -> 2018-11-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-11-21 12:17:12 -> 2018-11-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-11-26 12:17:12 -> 2018-12-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-12-01 12:17:12 -> 2018-12-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-12-06 12:17:12 -> 2018-12-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-12-11 12:17:12 -> 2018-12-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-12-16 12:17:12 -> 2018-12-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-12-21 12:17:12 -> 2018-12-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-12-26 12:17:12 -> 2018-12-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2018-12-31 12:17:12 -> 2019-01-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-01-05 12:17:12 -> 2019-01-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-01-10 12:17:12 -> 2019-01-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-01-15 12:17:12 -> 2019-01-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-01-20 12:17:12 -> 2019-01-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-01-25 12:17:12 -> 2019-01-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-01-30 12:17:12 -> 2019-02-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-02-04 12:17:12 -> 2019-02-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-02-09 12:17:12 -> 2019-02-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-02-14 12:17:12 -> 2019-02-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-02-19 12:17:12 -> 2019-02-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-02-24 12:17:12 -> 2019-03-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-03-01 12:17:12 -> 2019-03-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-03-06 12:17:12 -> 2019-03-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-03-11 12:17:12 -> 2019-03-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-03-16 12:17:12 -> 2019-03-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-03-21 12:17:12 -> 2019-03-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-03-26 12:17:12 -> 2019-03-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-03-31 12:17:12 -> 2019-04-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-04-05 12:17:12 -> 2019-04-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-04-10 12:17:12 -> 2019-04-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-04-15 12:17:12 -> 2019-04-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-04-20 12:17:12 -> 2019-04-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-04-25 12:17:12 -> 2019-04-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-04-30 12:17:12 -> 2019-05-05 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-05-05 12:17:12 -> 2019-05-10 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-05-10 12:17:12 -> 2019-05-15 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-05-15 12:17:12 -> 2019-05-20 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-05-20 12:17:12 -> 2019-05-25 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-05-25 12:17:12 -> 2019-05-30 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-05-30 12:17:12 -> 2019-06-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-06-04 12:17:12 -> 2019-06-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-06-09 12:17:12 -> 2019-06-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-06-14 12:17:12 -> 2019-06-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-06-19 12:17:12 -> 2019-06-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-06-24 12:17:12 -> 2019-06-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-06-29 12:17:12 -> 2019-07-04 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-07-04 12:17:12 -> 2019-07-09 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-07-09 12:17:12 -> 2019-07-14 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-07-14 12:17:12 -> 2019-07-19 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-07-19 12:17:12 -> 2019-07-24 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-07-24 12:17:12 -> 2019-07-29 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-07-29 12:17:12 -> 2019-08-03 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-08-03 12:17:12 -> 2019-08-08 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-08-08 12:17:12 -> 2019-08-13 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-08-13 12:17:12 -> 2019-08-18 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-08-18 12:17:12 -> 2019-08-23 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-08-23 12:17:12 -> 2019-08-28 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-08-28 12:17:12 -> 2019-09-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-09-02 12:17:12 -> 2019-09-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-09-07 12:17:12 -> 2019-09-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-09-12 12:17:12 -> 2019-09-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-09-17 12:17:12 -> 2019-09-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-09-22 12:17:12 -> 2019-09-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-09-27 12:17:12 -> 2019-10-02 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-10-02 12:17:12 -> 2019-10-07 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-10-07 12:17:12 -> 2019-10-12 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-10-12 12:17:12 -> 2019-10-17 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-10-17 12:17:12 -> 2019-10-22 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-10-22 12:17:12 -> 2019-10-27 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-10-27 12:17:12 -> 2019-11-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-11-01 12:17:12 -> 2019-11-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-11-06 12:17:12 -> 2019-11-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-11-11 12:17:12 -> 2019-11-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-11-16 12:17:12 -> 2019-11-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-11-21 12:17:12 -> 2019-11-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-11-26 12:17:12 -> 2019-12-01 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-12-01 12:17:12 -> 2019-12-06 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-12-06 12:17:12 -> 2019-12-11 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-12-11 12:17:12 -> 2019-12-16 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-12-16 12:17:12 -> 2019-12-21 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-12-21 12:17:12 -> 2019-12-26 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-12-26 12:17:12 -> 2019-12-31 12:17:12\n",
      "  > No data/Empty response. (Check if Market was open)\n",
      "Fetching: 2019-12-31 12:17:12 -> 2020-01-05 12:17:12\n",
      "  > Success: 1131 candles.\n",
      "Fetching: 2020-01-05 12:17:12 -> 2020-01-10 12:17:12\n",
      "  > Success: 1696 candles.\n",
      "Fetching: 2020-01-10 12:17:12 -> 2020-01-15 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-01-15 12:17:12 -> 2020-01-20 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-01-20 12:17:12 -> 2020-01-25 12:17:12\n",
      "  > Success: 1702 candles.\n",
      "Fetching: 2020-01-25 12:17:12 -> 2020-01-30 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2020-01-30 12:17:12 -> 2020-02-04 12:17:12\n",
      "  > Success: 1511 candles.\n",
      "Fetching: 2020-02-04 12:17:12 -> 2020-02-09 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2020-02-09 12:17:12 -> 2020-02-14 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2020-02-14 12:17:12 -> 2020-02-19 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-02-19 12:17:12 -> 2020-02-24 12:17:12\n",
      "  > Success: 756 candles.\n",
      "Fetching: 2020-02-24 12:17:12 -> 2020-02-29 12:17:12\n",
      "  > Success: 1702 candles.\n",
      "Fetching: 2020-02-29 12:17:12 -> 2020-03-05 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2020-03-05 12:17:12 -> 2020-03-10 12:17:12\n",
      "  > Success: 948 candles.\n",
      "Fetching: 2020-03-10 12:17:12 -> 2020-03-15 12:17:12\n",
      "  > Success: 1080 candles.\n",
      "Fetching: 2020-03-15 12:17:12 -> 2020-03-20 12:17:12\n",
      "  > Success: 1693 candles.\n",
      "Fetching: 2020-03-20 12:17:12 -> 2020-03-25 12:17:12\n",
      "  > Success: 1084 candles.\n",
      "Fetching: 2020-03-25 12:17:12 -> 2020-03-30 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-03-30 12:17:12 -> 2020-04-04 12:17:12\n",
      "  > Success: 1325 candles.\n",
      "Fetching: 2020-04-04 12:17:12 -> 2020-04-09 12:17:12\n",
      "  > Success: 940 candles.\n",
      "Fetching: 2020-04-09 12:17:12 -> 2020-04-14 12:17:12\n",
      "  > Success: 572 candles.\n",
      "Fetching: 2020-04-14 12:17:12 -> 2020-04-19 12:17:12\n",
      "  > Success: 1131 candles.\n",
      "Fetching: 2020-04-19 12:17:12 -> 2020-04-24 12:17:12\n",
      "  > Success: 1693 candles.\n",
      "Fetching: 2020-04-24 12:17:12 -> 2020-04-29 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-04-29 12:17:12 -> 2020-05-04 12:17:12\n",
      "  > Success: 757 candles.\n",
      "Fetching: 2020-05-04 12:17:12 -> 2020-05-09 12:17:12\n",
      "  > Success: 1702 candles.\n",
      "Fetching: 2020-05-09 12:17:12 -> 2020-05-14 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2020-05-14 12:17:12 -> 2020-05-19 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2020-05-19 12:17:12 -> 2020-05-24 12:17:12\n",
      "  > Success: 1325 candles.\n",
      "Fetching: 2020-05-24 12:17:12 -> 2020-05-29 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2020-05-29 12:17:12 -> 2020-06-03 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-06-03 12:17:12 -> 2020-06-08 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-06-08 12:17:12 -> 2020-06-13 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2020-06-13 12:17:12 -> 2020-06-18 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2020-06-18 12:17:12 -> 2020-06-23 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-06-23 12:17:12 -> 2020-06-28 12:17:12\n",
      "  > Success: 1325 candles.\n",
      "Fetching: 2020-06-28 12:17:12 -> 2020-07-03 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2020-07-03 12:17:12 -> 2020-07-08 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-07-08 12:17:12 -> 2020-07-13 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-07-13 12:17:12 -> 2020-07-18 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2020-07-18 12:17:12 -> 2020-07-23 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2020-07-23 12:17:12 -> 2020-07-28 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-07-28 12:17:12 -> 2020-08-02 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2020-08-02 12:17:12 -> 2020-08-07 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2020-08-07 12:17:12 -> 2020-08-12 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-08-12 12:17:12 -> 2020-08-17 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-08-17 12:17:12 -> 2020-08-22 12:17:12\n",
      "  > Success: 1704 candles.\n",
      "Fetching: 2020-08-22 12:17:12 -> 2020-08-27 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2020-08-27 12:17:12 -> 2020-09-01 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-09-01 12:17:12 -> 2020-09-06 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2020-09-06 12:17:12 -> 2020-09-11 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2020-09-11 12:17:12 -> 2020-09-16 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-09-16 12:17:12 -> 2020-09-21 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-09-21 12:17:12 -> 2020-09-26 12:17:12\n",
      "  > Success: 1702 candles.\n",
      "Fetching: 2020-09-26 12:17:12 -> 2020-10-01 12:17:12\n",
      "  > Success: 1318 candles.\n",
      "Fetching: 2020-10-01 12:17:12 -> 2020-10-06 12:17:12\n",
      "  > Success: 757 candles.\n",
      "Fetching: 2020-10-06 12:17:12 -> 2020-10-11 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2020-10-11 12:17:12 -> 2020-10-16 12:17:12\n",
      "  > Success: 1695 candles.\n",
      "Fetching: 2020-10-16 12:17:12 -> 2020-10-21 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-10-21 12:17:12 -> 2020-10-26 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-10-26 12:17:12 -> 2020-10-31 12:17:12\n",
      "  > Success: 1702 candles.\n",
      "Fetching: 2020-10-31 12:17:12 -> 2020-11-05 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2020-11-05 12:17:12 -> 2020-11-10 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-11-10 12:17:12 -> 2020-11-15 12:17:12\n",
      "  > Success: 1388 candles.\n",
      "Fetching: 2020-11-15 12:17:12 -> 2020-11-20 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2020-11-20 12:17:12 -> 2020-11-25 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2020-11-25 12:17:12 -> 2020-11-30 12:17:12\n",
      "  > Success: 949 candles.\n",
      "Fetching: 2020-11-30 12:17:12 -> 2020-12-05 12:17:12\n",
      "  > Success: 1508 candles.\n",
      "Fetching: 2020-12-05 12:17:12 -> 2020-12-10 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2020-12-10 12:17:12 -> 2020-12-15 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2020-12-15 12:17:12 -> 2020-12-20 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2020-12-20 12:17:12 -> 2020-12-25 12:17:12\n",
      "  > Success: 1509 candles.\n",
      "Fetching: 2020-12-25 12:17:12 -> 2020-12-30 12:17:12\n",
      "  > Success: 939 candles.\n",
      "Fetching: 2020-12-30 12:17:12 -> 2021-01-04 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-01-04 12:17:12 -> 2021-01-09 12:17:12\n",
      "  > Success: 1702 candles.\n",
      "Fetching: 2021-01-09 12:17:12 -> 2021-01-14 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2021-01-14 12:17:12 -> 2021-01-19 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-01-19 12:17:12 -> 2021-01-24 12:17:12\n",
      "  > Success: 1325 candles.\n",
      "Fetching: 2021-01-24 12:17:12 -> 2021-01-29 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2021-01-29 12:17:12 -> 2021-02-03 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-02-03 12:17:12 -> 2021-02-08 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-02-08 12:17:12 -> 2021-02-13 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2021-02-13 12:17:12 -> 2021-02-18 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2021-02-18 12:17:12 -> 2021-02-23 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-02-23 12:17:12 -> 2021-02-28 12:17:12\n",
      "  > Success: 1088 candles.\n",
      "Fetching: 2021-02-28 12:17:12 -> 2021-03-05 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2021-03-05 12:17:12 -> 2021-03-10 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-03-10 12:17:12 -> 2021-03-15 12:17:12\n",
      "  > Success: 756 candles.\n",
      "Fetching: 2021-03-15 12:17:12 -> 2021-03-20 12:17:12\n",
      "  > Success: 1702 candles.\n",
      "Fetching: 2021-03-20 12:17:12 -> 2021-03-25 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2021-03-25 12:17:12 -> 2021-03-30 12:17:12\n",
      "  > Success: 757 candles.\n",
      "Fetching: 2021-03-30 12:17:12 -> 2021-04-04 12:17:12\n",
      "  > Success: 947 candles.\n",
      "Fetching: 2021-04-04 12:17:12 -> 2021-04-09 12:17:12\n",
      "  > Success: 1693 candles.\n",
      "Fetching: 2021-04-09 12:17:12 -> 2021-04-14 12:17:12\n",
      "  > Success: 949 candles.\n",
      "Fetching: 2021-04-14 12:17:12 -> 2021-04-19 12:17:12\n",
      "  > Success: 939 candles.\n",
      "Fetching: 2021-04-19 12:17:12 -> 2021-04-24 12:17:12\n",
      "  > Success: 1325 candles.\n",
      "Fetching: 2021-04-24 12:17:12 -> 2021-04-29 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2021-04-29 12:17:12 -> 2021-05-04 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-05-04 12:17:12 -> 2021-05-09 12:17:12\n",
      "  > Success: 1325 candles.\n",
      "Fetching: 2021-05-09 12:17:12 -> 2021-05-14 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2021-05-14 12:17:12 -> 2021-05-19 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-05-19 12:17:12 -> 2021-05-24 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-05-24 12:17:12 -> 2021-05-29 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2021-05-29 12:17:12 -> 2021-06-03 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2021-06-03 12:17:12 -> 2021-06-08 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-06-08 12:17:12 -> 2021-06-13 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2021-06-13 12:17:12 -> 2021-06-18 12:17:12\n",
      "  > Success: 1693 candles.\n",
      "Fetching: 2021-06-18 12:17:12 -> 2021-06-23 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2021-06-23 12:17:12 -> 2021-06-28 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-06-28 12:17:12 -> 2021-07-03 12:17:12\n",
      "  > Success: 1725 candles.\n",
      "Fetching: 2021-07-03 12:17:12 -> 2021-07-08 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2021-07-08 12:17:12 -> 2021-07-13 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-07-13 12:17:12 -> 2021-07-18 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2021-07-18 12:17:12 -> 2021-07-23 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2021-07-23 12:17:12 -> 2021-07-28 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-07-28 12:17:12 -> 2021-08-02 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-08-02 12:17:12 -> 2021-08-07 12:17:12\n",
      "  > Success: 1706 candles.\n",
      "Fetching: 2021-08-07 12:17:12 -> 2021-08-12 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2021-08-12 12:17:12 -> 2021-08-17 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-08-17 12:17:12 -> 2021-08-22 12:17:12\n",
      "  > Success: 949 candles.\n",
      "Fetching: 2021-08-22 12:17:12 -> 2021-08-27 12:17:12\n",
      "  > Success: 1693 candles.\n",
      "Fetching: 2021-08-27 12:17:12 -> 2021-09-01 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-09-01 12:17:12 -> 2021-09-06 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-09-06 12:17:12 -> 2021-09-11 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2021-09-11 12:17:12 -> 2021-09-16 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2021-09-16 12:17:12 -> 2021-09-21 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-09-21 12:17:12 -> 2021-09-26 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2021-09-26 12:17:12 -> 2021-10-01 12:17:12\n",
      "  > Success: 1693 candles.\n",
      "Fetching: 2021-10-01 12:17:12 -> 2021-10-06 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-10-06 12:17:12 -> 2021-10-11 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-10-11 12:17:12 -> 2021-10-16 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2021-10-16 12:17:12 -> 2021-10-21 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2021-10-21 12:17:12 -> 2021-10-26 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-10-26 12:17:12 -> 2021-10-31 12:17:12\n",
      "  > Success: 1325 candles.\n",
      "Fetching: 2021-10-31 12:17:12 -> 2021-11-05 12:17:12\n",
      "  > Success: 1195 candles.\n",
      "Fetching: 2021-11-05 12:17:12 -> 2021-11-10 12:17:12\n",
      "  > Success: 939 candles.\n",
      "Fetching: 2021-11-10 12:17:12 -> 2021-11-15 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-11-15 12:17:12 -> 2021-11-20 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2021-11-20 12:17:12 -> 2021-11-25 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2021-11-25 12:17:12 -> 2021-11-30 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2021-11-30 12:17:12 -> 2021-12-05 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2021-12-05 12:17:12 -> 2021-12-10 12:17:12\n",
      "  > Success: 1693 candles.\n",
      "Fetching: 2021-12-10 12:17:12 -> 2021-12-15 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2021-12-15 12:17:12 -> 2021-12-20 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2021-12-20 12:17:12 -> 2021-12-25 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2021-12-25 12:17:12 -> 2021-12-30 12:17:12\n",
      "  > Success: 1318 candles.\n",
      "Fetching: 2021-12-30 12:17:12 -> 2022-01-04 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-01-04 12:17:12 -> 2022-01-09 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2022-01-09 12:17:12 -> 2022-01-14 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2022-01-14 12:17:12 -> 2022-01-19 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2022-01-19 12:17:12 -> 2022-01-24 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2022-01-24 12:17:12 -> 2022-01-29 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2022-01-29 12:17:12 -> 2022-02-03 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2022-02-03 12:17:12 -> 2022-02-08 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2022-02-08 12:17:12 -> 2022-02-13 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2022-02-13 12:17:12 -> 2022-02-18 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2022-02-18 12:17:12 -> 2022-02-23 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-02-23 12:17:12 -> 2022-02-28 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2022-02-28 12:17:12 -> 2022-03-05 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2022-03-05 12:17:12 -> 2022-03-10 12:17:12\n",
      "  > Success: 1276 candles.\n",
      "Fetching: 2022-03-10 12:17:12 -> 2022-03-15 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2022-03-15 12:17:12 -> 2022-03-20 12:17:12\n",
      "  > Success: 950 candles.\n",
      "Fetching: 2022-03-20 12:17:12 -> 2022-03-25 12:17:12\n",
      "  > Success: 1693 candles.\n",
      "Fetching: 2022-03-25 12:17:12 -> 2022-03-30 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-03-30 12:17:12 -> 2022-04-04 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-04-04 12:17:12 -> 2022-04-09 12:17:12\n",
      "  > Success: 1702 candles.\n",
      "Fetching: 2022-04-09 12:17:12 -> 2022-04-14 12:17:12\n",
      "  > Success: 1131 candles.\n",
      "Fetching: 2022-04-14 12:17:12 -> 2022-04-19 12:17:12\n",
      "  > Success: 563 candles.\n",
      "Fetching: 2022-04-19 12:17:12 -> 2022-04-24 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2022-04-24 12:17:12 -> 2022-04-29 12:17:12\n",
      "  > Success: 1695 candles.\n",
      "Fetching: 2022-04-29 12:17:12 -> 2022-05-04 12:17:12\n",
      "  > Success: 756 candles.\n",
      "Fetching: 2022-05-04 12:17:12 -> 2022-05-09 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2022-05-09 12:17:12 -> 2022-05-14 12:17:12\n",
      "  > Success: 1704 candles.\n",
      "Fetching: 2022-05-14 12:17:12 -> 2022-05-19 12:17:12\n",
      "  > Success: 1318 candles.\n",
      "Fetching: 2022-05-19 12:17:12 -> 2022-05-24 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2022-05-24 12:17:12 -> 2022-05-29 12:17:12\n",
      "  > Success: 1328 candles.\n",
      "Fetching: 2022-05-29 12:17:12 -> 2022-06-03 12:17:12\n",
      "  > Success: 1695 candles.\n",
      "Fetching: 2022-06-03 12:17:12 -> 2022-06-08 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-06-08 12:17:12 -> 2022-06-13 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2022-06-13 12:17:12 -> 2022-06-18 12:17:12\n",
      "  > Success: 1707 candles.\n",
      "Fetching: 2022-06-18 12:17:12 -> 2022-06-23 12:17:12\n",
      "  > Success: 1318 candles.\n",
      "Fetching: 2022-06-23 12:17:12 -> 2022-06-28 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2022-06-28 12:17:12 -> 2022-07-03 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2022-07-03 12:17:12 -> 2022-07-08 12:17:12\n",
      "  > Success: 1696 candles.\n",
      "Fetching: 2022-07-08 12:17:12 -> 2022-07-13 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-07-13 12:17:12 -> 2022-07-18 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2022-07-18 12:17:12 -> 2022-07-23 12:17:12\n",
      "  > Success: 1706 candles.\n",
      "Fetching: 2022-07-23 12:17:12 -> 2022-07-28 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2022-07-28 12:17:12 -> 2022-08-02 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-08-02 12:17:12 -> 2022-08-07 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2022-08-07 12:17:12 -> 2022-08-12 12:17:12\n",
      "  > Success: 1316 candles.\n",
      "Fetching: 2022-08-12 12:17:12 -> 2022-08-17 12:17:12\n",
      "  > Success: 757 candles.\n",
      "Fetching: 2022-08-17 12:17:12 -> 2022-08-22 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2022-08-22 12:17:12 -> 2022-08-27 12:17:12\n",
      "  > Success: 1704 candles.\n",
      "Fetching: 2022-08-27 12:17:12 -> 2022-09-01 12:17:12\n",
      "  > Success: 940 candles.\n",
      "Fetching: 2022-09-01 12:17:12 -> 2022-09-06 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2022-09-06 12:17:12 -> 2022-09-11 12:17:12\n",
      "  > Success: 1328 candles.\n",
      "Fetching: 2022-09-11 12:17:12 -> 2022-09-16 12:17:12\n",
      "  > Success: 1695 candles.\n",
      "Fetching: 2022-09-16 12:17:12 -> 2022-09-21 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-09-21 12:17:12 -> 2022-09-26 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2022-09-26 12:17:12 -> 2022-10-01 12:17:12\n",
      "  > Success: 1706 candles.\n",
      "Fetching: 2022-10-01 12:17:12 -> 2022-10-06 12:17:12\n",
      "  > Success: 939 candles.\n",
      "Fetching: 2022-10-06 12:17:12 -> 2022-10-11 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2022-10-11 12:17:12 -> 2022-10-16 12:17:12\n",
      "  > Success: 1328 candles.\n",
      "Fetching: 2022-10-16 12:17:12 -> 2022-10-21 12:17:12\n",
      "  > Success: 1695 candles.\n",
      "Fetching: 2022-10-21 12:17:12 -> 2022-10-26 12:17:12\n",
      "  > Success: 634 candles.\n",
      "Fetching: 2022-10-26 12:17:12 -> 2022-10-31 12:17:12\n",
      "  > Success: 940 candles.\n",
      "Fetching: 2022-10-31 12:17:12 -> 2022-11-05 12:17:12\n",
      "  > Success: 1705 candles.\n",
      "Fetching: 2022-11-05 12:17:12 -> 2022-11-10 12:17:12\n",
      "  > Success: 939 candles.\n",
      "Fetching: 2022-11-10 12:17:12 -> 2022-11-15 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-11-15 12:17:12 -> 2022-11-20 12:17:12\n",
      "  > Success: 1326 candles.\n",
      "Fetching: 2022-11-20 12:17:12 -> 2022-11-25 12:17:12\n",
      "  > Success: 1695 candles.\n",
      "Fetching: 2022-11-25 12:17:12 -> 2022-11-30 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2022-11-30 12:17:12 -> 2022-12-05 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-12-05 12:17:12 -> 2022-12-10 12:17:12\n",
      "  > Success: 1705 candles.\n",
      "Fetching: 2022-12-10 12:17:12 -> 2022-12-15 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2022-12-15 12:17:12 -> 2022-12-20 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2022-12-20 12:17:12 -> 2022-12-25 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2022-12-25 12:17:12 -> 2022-12-30 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2022-12-30 12:17:12 -> 2023-01-04 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2023-01-04 12:17:12 -> 2023-01-09 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2023-01-09 12:17:12 -> 2023-01-14 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2023-01-14 12:17:12 -> 2023-01-19 12:17:12\n",
      "  > Success: 1318 candles.\n",
      "Fetching: 2023-01-19 12:17:12 -> 2023-01-24 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2023-01-24 12:17:12 -> 2023-01-29 12:17:12\n",
      "  > Success: 950 candles.\n",
      "Fetching: 2023-01-29 12:17:12 -> 2023-02-03 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2023-02-03 12:17:12 -> 2023-02-08 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-02-08 12:17:12 -> 2023-02-13 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-02-13 12:17:12 -> 2023-02-18 12:17:12\n",
      "  > Success: 1705 candles.\n",
      "Fetching: 2023-02-18 12:17:12 -> 2023-02-23 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2023-02-23 12:17:12 -> 2023-02-28 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2023-02-28 12:17:12 -> 2023-03-05 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2023-03-05 12:17:12 -> 2023-03-10 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2023-03-10 12:17:12 -> 2023-03-15 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2023-03-15 12:17:12 -> 2023-03-20 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2023-03-20 12:17:12 -> 2023-03-25 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2023-03-25 12:17:12 -> 2023-03-30 12:17:12\n",
      "  > Success: 1131 candles.\n",
      "Fetching: 2023-03-30 12:17:12 -> 2023-04-04 12:17:12\n",
      "  > Success: 754 candles.\n",
      "Fetching: 2023-04-04 12:17:12 -> 2023-04-09 12:17:12\n",
      "  > Success: 755 candles.\n",
      "Fetching: 2023-04-09 12:17:12 -> 2023-04-14 12:17:12\n",
      "  > Success: 1509 candles.\n",
      "Fetching: 2023-04-14 12:17:12 -> 2023-04-19 12:17:12\n",
      "  > Success: 940 candles.\n",
      "Fetching: 2023-04-19 12:17:12 -> 2023-04-24 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2023-04-24 12:17:12 -> 2023-04-29 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2023-04-29 12:17:12 -> 2023-05-04 12:17:12\n",
      "  > Success: 939 candles.\n",
      "Fetching: 2023-05-04 12:17:12 -> 2023-05-09 12:17:12\n",
      "  > Success: 1133 candles.\n",
      "Fetching: 2023-05-09 12:17:12 -> 2023-05-14 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2023-05-14 12:17:12 -> 2023-05-19 12:17:12\n",
      "  > Success: 1696 candles.\n",
      "Fetching: 2023-05-19 12:17:12 -> 2023-05-24 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-05-24 12:17:12 -> 2023-05-29 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2023-05-29 12:17:12 -> 2023-06-03 12:17:12\n",
      "  > Success: 1707 candles.\n",
      "Fetching: 2023-06-03 12:17:12 -> 2023-06-08 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2023-06-08 12:17:12 -> 2023-06-13 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-06-13 12:17:12 -> 2023-06-18 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2023-06-18 12:17:12 -> 2023-06-23 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2023-06-23 12:17:12 -> 2023-06-28 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-06-28 12:17:12 -> 2023-07-03 12:17:12\n",
      "  > Success: 758 candles.\n",
      "Fetching: 2023-07-03 12:17:12 -> 2023-07-08 12:17:12\n",
      "  > Success: 1703 candles.\n",
      "Fetching: 2023-07-08 12:17:12 -> 2023-07-13 12:17:12\n",
      "  > Success: 1318 candles.\n",
      "Fetching: 2023-07-13 12:17:12 -> 2023-07-18 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-07-18 12:17:12 -> 2023-07-23 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2023-07-23 12:17:12 -> 2023-07-28 12:17:12\n",
      "  > Success: 1695 candles.\n",
      "Fetching: 2023-07-28 12:17:12 -> 2023-08-02 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-08-02 12:17:12 -> 2023-08-07 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-08-07 12:17:12 -> 2023-08-12 12:17:12\n",
      "  > Success: 1707 candles.\n",
      "Fetching: 2023-08-12 12:17:12 -> 2023-08-17 12:17:12\n",
      "  > Success: 940 candles.\n",
      "Fetching: 2023-08-17 12:17:12 -> 2023-08-22 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2023-08-22 12:17:12 -> 2023-08-27 12:17:12\n",
      "  > Success: 1328 candles.\n",
      "Fetching: 2023-08-27 12:17:12 -> 2023-09-01 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2023-09-01 12:17:12 -> 2023-09-06 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2023-09-06 12:17:12 -> 2023-09-11 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-09-11 12:17:12 -> 2023-09-16 12:17:12\n",
      "  > Success: 1707 candles.\n",
      "Fetching: 2023-09-16 12:17:12 -> 2023-09-21 12:17:12\n",
      "  > Success: 941 candles.\n",
      "Fetching: 2023-09-21 12:17:12 -> 2023-09-26 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2023-09-26 12:17:12 -> 2023-10-01 12:17:12\n",
      "  > Success: 1328 candles.\n",
      "Fetching: 2023-10-01 12:17:12 -> 2023-10-06 12:17:12\n",
      "  > Success: 1318 candles.\n",
      "Fetching: 2023-10-06 12:17:12 -> 2023-10-11 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-10-11 12:17:12 -> 2023-10-16 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2023-10-16 12:17:12 -> 2023-10-21 12:17:12\n",
      "  > Success: 1707 candles.\n",
      "Fetching: 2023-10-21 12:17:12 -> 2023-10-26 12:17:12\n",
      "  > Success: 941 candles.\n",
      "Fetching: 2023-10-26 12:17:12 -> 2023-10-31 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2023-10-31 12:17:12 -> 2023-11-05 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2023-11-05 12:17:12 -> 2023-11-10 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2023-11-10 12:17:12 -> 2023-11-15 12:17:12\n",
      "  > Success: 820 candles.\n",
      "Fetching: 2023-11-15 12:17:12 -> 2023-11-20 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2023-11-20 12:17:12 -> 2023-11-25 12:17:12\n",
      "  > Success: 1705 candles.\n",
      "Fetching: 2023-11-25 12:17:12 -> 2023-11-30 12:17:12\n",
      "  > Success: 940 candles.\n",
      "Fetching: 2023-11-30 12:17:12 -> 2023-12-05 12:17:12\n",
      "  > Success: 1137 candles.\n",
      "Fetching: 2023-12-05 12:17:12 -> 2023-12-10 12:17:12\n",
      "  > Success: 1328 candles.\n",
      "Fetching: 2023-12-10 12:17:12 -> 2023-12-15 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2023-12-15 12:17:12 -> 2023-12-20 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2023-12-20 12:17:12 -> 2023-12-25 12:17:12\n",
      "  > Success: 950 candles.\n",
      "Fetching: 2023-12-25 12:17:12 -> 2023-12-30 12:17:12\n",
      "  > Success: 1509 candles.\n",
      "Fetching: 2023-12-30 12:17:12 -> 2024-01-04 12:17:12\n",
      "  > Success: 1318 candles.\n",
      "Fetching: 2024-01-04 12:17:12 -> 2024-01-09 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2024-01-09 12:17:12 -> 2024-01-14 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-01-14 12:17:12 -> 2024-01-19 12:17:12\n",
      "  > Success: 1694 candles.\n",
      "Fetching: 2024-01-19 12:17:12 -> 2024-01-24 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2024-01-24 12:17:12 -> 2024-01-29 12:17:12\n",
      "  > Success: 758 candles.\n",
      "Fetching: 2024-01-29 12:17:12 -> 2024-02-03 12:17:12\n",
      "  > Success: 1704 candles.\n",
      "Fetching: 2024-02-03 12:17:12 -> 2024-02-08 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-02-08 12:17:12 -> 2024-02-13 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2024-02-13 12:17:12 -> 2024-02-18 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-02-18 12:17:12 -> 2024-02-23 12:17:12\n",
      "  > Success: 1696 candles.\n",
      "Fetching: 2024-02-23 12:17:12 -> 2024-02-28 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2024-02-28 12:17:12 -> 2024-03-04 12:17:12\n",
      "  > Success: 1245 candles.\n",
      "Fetching: 2024-03-04 12:17:12 -> 2024-03-09 12:17:12\n",
      "  > Success: 1328 candles.\n",
      "Fetching: 2024-03-09 12:17:12 -> 2024-03-14 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-03-14 12:17:12 -> 2024-03-19 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2024-03-19 12:17:12 -> 2024-03-24 12:17:12\n",
      "  > Success: 1327 candles.\n",
      "Fetching: 2024-03-24 12:17:12 -> 2024-03-29 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2024-03-29 12:17:12 -> 2024-04-03 12:17:12\n",
      "  > Success: 940 candles.\n",
      "Fetching: 2024-04-03 12:17:12 -> 2024-04-08 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2024-04-08 12:17:12 -> 2024-04-13 12:17:12\n",
      "  > Success: 1328 candles.\n",
      "Fetching: 2024-04-13 12:17:12 -> 2024-04-18 12:17:12\n",
      "  > Success: 941 candles.\n",
      "Fetching: 2024-04-18 12:17:12 -> 2024-04-23 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2024-04-23 12:17:12 -> 2024-04-28 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-04-28 12:17:12 -> 2024-05-03 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-05-03 12:17:12 -> 2024-05-08 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-05-08 12:17:12 -> 2024-05-13 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-05-13 12:17:12 -> 2024-05-18 12:17:12\n",
      "  > Success: 1806 candles.\n",
      "Fetching: 2024-05-18 12:17:12 -> 2024-05-23 12:17:12\n",
      "  > Success: 956 candles.\n",
      "Fetching: 2024-05-23 12:17:12 -> 2024-05-28 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-05-28 12:17:12 -> 2024-06-02 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-06-02 12:17:12 -> 2024-06-07 12:17:12\n",
      "  > Success: 1696 candles.\n",
      "Fetching: 2024-06-07 12:17:12 -> 2024-06-12 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-06-12 12:17:12 -> 2024-06-17 12:17:12\n",
      "  > Success: 951 candles.\n",
      "Fetching: 2024-06-17 12:17:12 -> 2024-06-22 12:17:12\n",
      "  > Success: 1512 candles.\n",
      "Fetching: 2024-06-22 12:17:12 -> 2024-06-27 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-06-27 12:17:12 -> 2024-07-02 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-07-02 12:17:12 -> 2024-07-07 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-07-07 12:17:12 -> 2024-07-12 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2024-07-12 12:17:12 -> 2024-07-17 12:17:12\n",
      "  > Success: 951 candles.\n",
      "Fetching: 2024-07-17 12:17:12 -> 2024-07-22 12:17:12\n",
      "  > Success: 942 candles.\n",
      "Fetching: 2024-07-22 12:17:12 -> 2024-07-27 12:17:12\n",
      "  > Success: 1707 candles.\n",
      "Fetching: 2024-07-27 12:17:12 -> 2024-08-01 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-08-01 12:17:12 -> 2024-08-06 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-08-06 12:17:12 -> 2024-08-11 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-08-11 12:17:12 -> 2024-08-16 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-08-16 12:17:12 -> 2024-08-21 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-08-21 12:17:12 -> 2024-08-26 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-08-26 12:17:12 -> 2024-08-31 12:17:12\n",
      "  > Success: 1706 candles.\n",
      "Fetching: 2024-08-31 12:17:12 -> 2024-09-05 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-09-05 12:17:12 -> 2024-09-10 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-09-10 12:17:12 -> 2024-09-15 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-09-15 12:17:12 -> 2024-09-20 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2024-09-20 12:17:12 -> 2024-09-25 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-09-25 12:17:12 -> 2024-09-30 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-09-30 12:17:12 -> 2024-10-05 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-10-05 12:17:12 -> 2024-10-10 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-10-10 12:17:12 -> 2024-10-15 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-10-15 12:17:12 -> 2024-10-20 12:17:12\n",
      "  > Success: 1329 candles.\n",
      "Fetching: 2024-10-20 12:17:12 -> 2024-10-25 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2024-10-25 12:17:12 -> 2024-10-30 12:17:12\n",
      "  > Success: 1135 candles.\n",
      "Fetching: 2024-10-30 12:17:12 -> 2024-11-04 12:17:12\n",
      "  > Success: 821 candles.\n",
      "Fetching: 2024-11-04 12:17:12 -> 2024-11-09 12:17:12\n",
      "  > Success: 1707 candles.\n",
      "Fetching: 2024-11-09 12:17:12 -> 2024-11-14 12:17:12\n",
      "  > Success: 1319 candles.\n",
      "Fetching: 2024-11-14 12:17:12 -> 2024-11-19 12:17:12\n",
      "  > Success: 758 candles.\n",
      "Fetching: 2024-11-19 12:17:12 -> 2024-11-24 12:17:12\n",
      "  > Success: 950 candles.\n",
      "Fetching: 2024-11-24 12:17:12 -> 2024-11-29 12:17:12\n",
      "  > Success: 1697 candles.\n",
      "Fetching: 2024-11-29 12:17:12 -> 2024-12-04 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-12-04 12:17:12 -> 2024-12-09 12:17:12\n",
      "  > Success: 1136 candles.\n",
      "Fetching: 2024-12-09 12:17:12 -> 2024-12-14 12:17:12\n",
      "  > Success: 1704 candles.\n",
      "Fetching: 2024-12-14 12:17:12 -> 2024-12-19 12:17:12\n",
      "  > Success: 1317 candles.\n",
      "Fetching: 2024-12-19 12:17:12 -> 2024-12-24 12:17:12\n",
      "  > Success: 1134 candles.\n",
      "Fetching: 2024-12-24 12:17:12 -> 2024-12-29 12:17:12\n",
      "  > Success: 950 candles.\n",
      "Fetching: 2024-12-29 12:17:12 -> 2025-01-03 12:17:12\n",
      "  > Success: 1717 candles.\n",
      "Fetching: 2025-01-03 12:17:12 -> 2025-01-08 12:17:12\n",
      "  > Success: 1157 candles.\n",
      "Fetching: 2025-01-08 12:17:12 -> 2025-01-13 12:17:12\n",
      "  > Success: 1155 candles.\n",
      "Fetching: 2025-01-13 12:17:12 -> 2025-01-18 12:17:12\n",
      "  > Success: 1734 candles.\n",
      "Fetching: 2025-01-18 12:17:12 -> 2025-01-23 12:17:12\n",
      "  > Success: 1346 candles.\n",
      "Fetching: 2025-01-23 12:17:12 -> 2025-01-28 12:17:12\n",
      "  > Success: 1155 candles.\n",
      "Fetching: 2025-01-28 12:17:12 -> 2025-02-02 12:17:12\n",
      "  > Success: 1735 candles.\n",
      "Fetching: 2025-02-02 12:17:12 -> 2025-02-07 12:17:12\n",
      "  > Success: 1730 candles.\n",
      "Fetching: 2025-02-07 12:17:12 -> 2025-02-12 12:17:12\n",
      "  > Success: 1155 candles.\n",
      "Fetching: 2025-02-12 12:17:12 -> 2025-02-17 12:17:12\n",
      "  > Success: 1156 candles.\n",
      "Fetching: 2025-02-17 12:17:12 -> 2025-02-22 12:17:12\n",
      "  > Success: 1735 candles.\n",
      "Fetching: 2025-02-22 12:17:12 -> 2025-02-27 12:17:12\n",
      "  > Success: 960 candles.\n",
      "Fetching: 2025-02-27 12:17:12 -> 2025-03-04 12:17:12\n",
      "  > Success: 1156 candles.\n",
      "Fetching: 2025-03-04 12:17:12 -> 2025-03-09 12:17:12\n",
      "  > Success: 1349 candles.\n",
      "Fetching: 2025-03-09 12:17:12 -> 2025-03-14 12:17:12\n",
      "  > Success: 1536 candles.\n",
      "Fetching: 2025-03-14 12:17:12 -> 2025-03-19 12:17:12\n",
      "  > Success: 962 candles.\n",
      "Fetching: 2025-03-19 12:17:12 -> 2025-03-24 12:17:12\n",
      "  > Success: 1157 candles.\n",
      "Fetching: 2025-03-24 12:17:12 -> 2025-03-29 12:17:12\n",
      "  > Success: 1732 candles.\n",
      "Fetching: 2025-03-29 12:17:12 -> 2025-04-03 12:17:12\n",
      "  > Success: 960 candles.\n",
      "Fetching: 2025-04-03 12:17:12 -> 2025-04-08 12:17:12\n",
      "  > Success: 1156 candles.\n",
      "Fetching: 2025-04-08 12:17:12 -> 2025-04-13 12:17:12\n",
      "  > Success: 964 candles.\n",
      "Fetching: 2025-04-13 12:17:12 -> 2025-04-18 12:17:12\n",
      "  > Success: 1155 candles.\n",
      "Fetching: 2025-04-18 12:17:12 -> 2025-04-23 12:17:12\n",
      "  > Success: 962 candles.\n",
      "Fetching: 2025-04-23 12:17:12 -> 2025-04-28 12:17:12\n",
      "  > Success: 1156 candles.\n",
      "Fetching: 2025-04-28 12:17:12 -> 2025-05-03 12:17:12\n",
      "  > Success: 1347 candles.\n",
      "Fetching: 2025-05-03 12:17:12 -> 2025-05-08 12:17:12\n",
      "  > Success: 1417 candles.\n",
      "Fetching: 2025-05-08 12:17:12 -> 2025-05-13 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-05-13 12:17:12 -> 2025-05-18 12:17:12\n",
      "  > Success: 1483 candles.\n",
      "Fetching: 2025-05-18 12:17:12 -> 2025-05-23 12:17:12\n",
      "  > Success: 1879 candles.\n",
      "Fetching: 2025-05-23 12:17:12 -> 2025-05-28 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-05-28 12:17:12 -> 2025-06-02 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-06-02 12:17:12 -> 2025-06-07 12:17:12\n",
      "  > Success: 1903 candles.\n",
      "Fetching: 2025-06-07 12:17:12 -> 2025-06-12 12:17:12\n",
      "  > Success: 1452 candles.\n",
      "Fetching: 2025-06-12 12:17:12 -> 2025-06-17 12:17:12\n",
      "  > Success: 1255 candles.\n",
      "Fetching: 2025-06-17 12:17:12 -> 2025-06-22 12:17:12\n",
      "  > Success: 1483 candles.\n",
      "Fetching: 2025-06-22 12:17:12 -> 2025-06-27 12:17:12\n",
      "  > Success: 1879 candles.\n",
      "Fetching: 2025-06-27 12:17:12 -> 2025-07-02 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-07-02 12:17:12 -> 2025-07-07 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-07-07 12:17:12 -> 2025-07-12 12:17:12\n",
      "  > Success: 1903 candles.\n",
      "Fetching: 2025-07-12 12:17:12 -> 2025-07-17 12:17:12\n",
      "  > Success: 1459 candles.\n",
      "Fetching: 2025-07-17 12:17:12 -> 2025-07-22 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-07-22 12:17:12 -> 2025-07-27 12:17:12\n",
      "  > Success: 1483 candles.\n",
      "Fetching: 2025-07-27 12:17:12 -> 2025-08-01 12:17:12\n",
      "  > Success: 1879 candles.\n",
      "Fetching: 2025-08-01 12:17:12 -> 2025-08-06 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-08-06 12:17:12 -> 2025-08-11 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-08-11 12:17:12 -> 2025-08-16 12:17:12\n",
      "  > Success: 1483 candles.\n",
      "Fetching: 2025-08-16 12:17:12 -> 2025-08-21 12:17:12\n",
      "  > Success: 1459 candles.\n",
      "Fetching: 2025-08-21 12:17:12 -> 2025-08-26 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-08-26 12:17:12 -> 2025-08-31 12:17:12\n",
      "  > Success: 1063 candles.\n",
      "Fetching: 2025-08-31 12:17:12 -> 2025-09-05 12:17:12\n",
      "  > Success: 1879 candles.\n",
      "Fetching: 2025-09-05 12:17:12 -> 2025-09-10 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-09-10 12:17:12 -> 2025-09-15 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-09-15 12:17:12 -> 2025-09-20 12:17:12\n",
      "  > Success: 1903 candles.\n",
      "Fetching: 2025-09-20 12:17:12 -> 2025-09-25 12:17:12\n",
      "  > Success: 1459 candles.\n",
      "Fetching: 2025-09-25 12:17:12 -> 2025-09-30 12:17:12\n",
      "  > Success: 1178 candles.\n",
      "Fetching: 2025-09-30 12:17:12 -> 2025-10-05 12:17:12\n",
      "  > Success: 1063 candles.\n",
      "Fetching: 2025-10-05 12:17:12 -> 2025-10-10 12:17:12\n",
      "  > Success: 1680 candles.\n",
      "Fetching: 2025-10-10 12:17:12 -> 2025-10-15 12:17:12\n",
      "  > Success: 1039 candles.\n",
      "Fetching: 2025-10-15 12:17:12 -> 2025-10-20 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-10-20 12:17:12 -> 2025-10-25 12:17:12\n",
      "  > Success: 1158 candles.\n",
      "Fetching: 2025-10-25 12:17:12 -> 2025-10-30 12:17:12\n",
      "  > Success: 1260 candles.\n",
      "Fetching: 2025-10-30 12:17:12 -> 2025-11-04 12:17:12\n",
      "  > Success: 1039 candles.\n",
      "Fetching: 2025-11-04 12:17:12 -> 2025-11-09 12:17:12\n",
      "  > Success: 1063 candles.\n",
      "Fetching: 2025-11-09 12:17:12 -> 2025-11-14 12:17:12\n",
      "  > Success: 1879 candles.\n",
      "Fetching: 2025-11-14 12:17:12 -> 2025-11-19 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-11-19 12:17:12 -> 2025-11-24 12:17:12\n",
      "  > Success: 1262 candles.\n",
      "Fetching: 2025-11-24 12:17:12 -> 2025-11-29 12:17:12\n",
      "  > Success: 1903 candles.\n",
      "Fetching: 2025-11-29 12:17:12 -> 2025-12-04 12:17:12\n",
      "  > Success: 1459 candles.\n",
      "Fetching: 2025-12-04 12:17:12 -> 2025-12-08 12:17:12\n",
      "  > Success: 826 candles.\n",
      "\n",
      "DONE! Saved 560149 candles to nifty_spot_1m.csv\n",
      "First 5 rows:\n",
      "            timestamp      open      high       low     close  volume  \\\n",
      "0 2020-01-01 09:07:00  12202.15  12202.15  12202.15  12202.15     0.0   \n",
      "1 2020-01-01 09:15:00  12201.55  12216.25  12201.55  12215.45     0.0   \n",
      "2 2020-01-01 09:16:00  12214.55  12216.45  12205.70  12206.50     0.0   \n",
      "3 2020-01-01 09:17:00  12205.85  12207.40  12202.70  12203.55     0.0   \n",
      "4 2020-01-01 09:18:00  12202.15  12208.40  12201.20  12208.35     0.0   \n",
      "\n",
      "  open_interest  \n",
      "0          None  \n",
      "1          None  \n",
      "2          None  \n",
      "3          None  \n",
      "4          None  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Starting batched download for {SYMBOL} ({SEGMENT})...\")\n",
    "\n",
    "while current_start < end_date:\n",
    "    current_end = current_start + timedelta(days=chunk_size_days)\n",
    "    if current_end > end_date:\n",
    "        current_end = end_date\n",
    "    \n",
    "    # Format dates to string as required by signature\n",
    "    s_str = current_start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    e_str = current_end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    print(f\"Fetching: {s_str} -> {e_str}\")\n",
    "    \n",
    "    try:\n",
    "        # UPDATED CALL MATCHING YOUR SIGNATURE\n",
    "        resp = groww.get_historical_candles(\n",
    "            exchange=EXCHANGE,\n",
    "            segment=SEGMENT,\n",
    "            groww_symbol=SYMBOL,\n",
    "            start_time=s_str,\n",
    "            end_time=e_str,\n",
    "            candle_interval=INTERVAL\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        if resp and \"candles\" in resp and resp[\"candles\"]:\n",
    "            chunk_data = resp[\"candles\"]\n",
    "            all_candles.extend(chunk_data)\n",
    "            print(f\"  > Success: {len(chunk_data)} candles.\")\n",
    "        else:\n",
    "            # Sometimes API returns empty or wrapped data, print to debug if needed\n",
    "            print(f\"  > No data/Empty response. (Check if Market was open)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  > Error: {e}\")\n",
    "\n",
    "    current_start = current_end\n",
    "    time.sleep(0.5) # Rate limit protection\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "# --- SAVE TO CSV ---\n",
    "if all_candles:\n",
    "    # 1. Create DataFrame\n",
    "    df = pd.DataFrame(all_candles)\n",
    "    \n",
    "    # 2. Rename Columns (Handle optional 7th column)\n",
    "    base_cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    rename_map = {i: col for i, col in enumerate(base_cols)}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "    \n",
    "    if len(df.columns) > 6:\n",
    "        df.rename(columns={6: \"open_interest\"}, inplace=True)\n",
    "    \n",
    "    # 3. ROBUST TIMESTAMP FIX\n",
    "    # Check the first value to decide how to convert\n",
    "    first_ts = df[\"timestamp\"].iloc[0]\n",
    "    \n",
    "    if isinstance(first_ts, str):\n",
    "        # Case A: API returns strings like '2025-11-07T13:43:00'\n",
    "        # Do NOT use unit='s' here.\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    else:\n",
    "        # Case B: API returns numbers (Epoch seconds) like 1735660000\n",
    "        # MUST use unit='s' here.\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit='s')\n",
    "    \n",
    "    # 4. Clean & Save\n",
    "    df.sort_values(\"timestamp\", inplace=True)\n",
    "    df.drop_duplicates(subset=\"timestamp\", inplace=True)\n",
    "    \n",
    "    filename = \"nifty_spot_1m.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"\\nDONE! Saved {len(df)} candles to {filename}\")\n",
    "    print(\"First 5 rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"\\nFAILED: No data collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307e86c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading interval: 5minute\n",
      "Saved nifty_spot_5minute.csv\n",
      "Downloading interval: 10minute\n",
      "Saved nifty_spot_10minute.csv\n",
      "Downloading interval: 15minute\n",
      "Saved nifty_spot_15minute.csv\n",
      "Downloading interval: 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Error: Not able to recognize candle_interval, having value 60minute\n",
      "Downloading interval: 1day\n",
      "Saved nifty_spot_1day.csv\n",
      "Downloading interval: 1week\n",
      "Saved nifty_spot_1week.csv\n"
     ]
    }
   ],
   "source": [
    "INTERVALS = [\"5minute\",\"10minute\",\"15minute\",\"60minute\",\"1day\",\"1week\"]\n",
    "\n",
    "for INTERVAL in INTERVALS:\n",
    "    all_candles = []\n",
    "    current_start = start_date\n",
    "    print(\"Downloading interval:\", INTERVAL)\n",
    "    while current_start < end_date:\n",
    "        current_end = current_start + timedelta(days=chunk_size_days)\n",
    "        if current_end > end_date:\n",
    "            current_end = end_date\n",
    "        s_str = current_start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        e_str = current_end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        try:\n",
    "            resp = groww.get_historical_candles(\n",
    "                exchange=EXCHANGE,\n",
    "                segment=SEGMENT,\n",
    "                groww_symbol=SYMBOL,\n",
    "                start_time=s_str,\n",
    "                end_time=e_str,\n",
    "                candle_interval=INTERVAL\n",
    "            )\n",
    "            if resp and \"candles\" in resp and resp[\"candles\"]:\n",
    "                all_candles.extend(resp[\"candles\"])\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "        current_start = current_end\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    if all_candles:\n",
    "        df = pd.DataFrame(all_candles)\n",
    "        # same robust timestamp fix as you already have...\n",
    "        # save file name by interval\n",
    "        df.to_csv(f\"nifty_spot_{INTERVAL}.csv\", index=False)\n",
    "        print(\"Saved\", f\"nifty_spot_{INTERVAL}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25501e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Authenticating...\n",
      "Ready to Groww!\n",
      "2. Fetching NSE-NIFTY-23Dec25-25800-CE...\n",
      "3. Success! Data found (336 rows).\n",
      "\n",
      "--- FIRST 5 ROWS ---\n",
      "            timestamp       o       h      l   close       v\n",
      "0 2025-12-17 09:15:00  182.50  189.70  172.8  182.00  585075\n",
      "1 2025-12-17 09:16:00  184.15  197.90  182.2  197.90  734325\n",
      "2 2025-12-17 09:17:00  198.20  200.05  194.3  197.80  581700\n",
      "3 2025-12-17 09:18:00  197.05  199.25  192.6  196.35  357150\n",
      "4 2025-12-17 09:19:00  196.85  197.40  191.7  192.95  237975\n",
      "\n",
      " Saved to single_contract_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from growwapi import GrowwAPI\n",
    "\n",
    "# --- CREDENTIALS ---\n",
    "API_KEY = \"eyJraWQiOiJaTUtjVXciLCJhbGciOiJFUzI1NiJ9.eyJleHAiOjI1NTQzNTIwMzYsImlhdCI6MTc2NTk1MjAzNiwibmJmIjoxNzY1OTUyMDM2LCJzdWIiOiJ7XCJ0b2tlblJlZklkXCI6XCI3NzljMTAyNy03ZDQ1LTRlOWItYWM5ZS1iNDgzMWRiODQzZTFcIixcInZlbmRvckludGVncmF0aW9uS2V5XCI6XCJlMzFmZjIzYjA4NmI0MDZjODg3NGIyZjZkODQ5NTMxM1wiLFwidXNlckFjY291bnRJZFwiOlwiMDdmMDA0MGMtZTk4Zi00ZDNmLTk5Y2EtZDc1ZjBlYWU5M2NlXCIsXCJkZXZpY2VJZFwiOlwiZDMyMWIxMzUtZWQ5Mi01ZWJkLWJjMDUtZTY1NDY2OWRiMDM5XCIsXCJzZXNzaW9uSWRcIjpcIjllODBhNjM2LTY4OGMtNDQ4OC1hMDhjLTU1NzQwMDQwNDMwZlwiLFwiYWRkaXRpb25hbERhdGFcIjpcIno1NC9NZzltdjE2WXdmb0gvS0EwYk1yOE5XVzhzdTNvZ080am1ZUzIwZEpSTkczdTlLa2pWZDNoWjU1ZStNZERhWXBOVi9UOUxIRmtQejFFQisybTdRPT1cIixcInJvbGVcIjpcImF1dGgtdG90cFwiLFwic291cmNlSXBBZGRyZXNzXCI6XCIyNDA5OjQwOTA6MTA4ZjpkYzA1OmM5ODU6OWEzNjo2ZTEyOjFjZWIsMTYyLjE1OC4yMzUuMjA0LDM1LjI0MS4yMy4xMjNcIixcInR3b0ZhRXhwaXJ5VHNcIjoyNTU0MzUyMDM2MzA0fSIsImlzcyI6ImFwZXgtYXV0aC1wcm9kLWFwcCJ9.vFYYnOrSLi-teVY6qhFF11SeSVZRIo-xBz_lVlOoTDujYw3ucWZSbOoP9sqFg11Oc8cCwWASqbg_R-9BfmPU0Q\"\n",
    "API_SECRET = \"Gb!4#@-d4*XbNz)F!)Y0iW8122uJiaTn\"\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SYMBOL = \"NSE-NIFTY-23Dec25-25800-CE\" \n",
    "START_TIME = \"2025-12-17 09:15:00\"\n",
    "END_TIME   = \"2025-12-17 14:50:00\"\n",
    "OUTPUT_CSV = \"single_contract_2025.csv\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"1. Authenticating...\")\n",
    "        token = GrowwAPI.get_access_token(api_key=API_KEY, secret=API_SECRET)\n",
    "        groww = GrowwAPI(token)\n",
    "        \n",
    "        print(f\"2. Fetching {SYMBOL}...\")\n",
    "        \n",
    "        resp = groww.get_historical_candles(\n",
    "            exchange=\"NSE\",\n",
    "            segment=\"FNO\",\n",
    "            groww_symbol=SYMBOL,\n",
    "            start_time=START_TIME,\n",
    "            end_time=END_TIME,\n",
    "            candle_interval=\"1minute\"\n",
    "        )\n",
    "        \n",
    "        if resp and \"candles\" in resp and len(resp[\"candles\"]) > 0:\n",
    "            print(f\"3. Success! Data found ({len(resp['candles'])} rows).\")\n",
    "            \n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame(resp[\"candles\"])\n",
    "            \n",
    "            # --- FIX 1: Handle 7 Columns (Auto-Detect OI) ---\n",
    "            if len(df.columns) == 7:\n",
    "                df.columns = ['ts', 'o', 'h', 'l', 'close', 'v', 'oi']\n",
    "            elif len(df.columns) == 6:\n",
    "                df.columns = ['ts', 'o', 'h', 'l', 'close', 'v']\n",
    "            else:\n",
    "                print(f\"Warning: Unexpected column count {len(df.columns)}\")\n",
    "                df.rename(columns={0: 'ts', 4: 'close'}, inplace=True)\n",
    "            \n",
    "            # --- FIX 2: Handle String vs Number Timestamp ---\n",
    "            # Check the first value to see if it's a string ('2020-01-01...') or int (1577836800)\n",
    "            first_ts = df['ts'].iloc[0]\n",
    "            \n",
    "            if isinstance(first_ts, str):\n",
    "                # It's already a string, pandas parses it directly\n",
    "                df['timestamp'] = pd.to_datetime(df['ts'])\n",
    "            else:\n",
    "                # It's a number (Unix timestamp), need unit='s'\n",
    "                df['timestamp'] = pd.to_datetime(df['ts'], unit='s')\n",
    "            \n",
    "            # Clean up\n",
    "            final_cols = ['timestamp', 'o', 'h', 'l', 'close', 'v']\n",
    "            if 'oi' in df.columns:\n",
    "                final_cols.append('oi')\n",
    "                \n",
    "            df = df[final_cols]\n",
    "            \n",
    "            print(\"\\n--- FIRST 5 ROWS ---\")\n",
    "            print(df.head())\n",
    "            \n",
    "            df.to_csv(OUTPUT_CSV, index=False)\n",
    "            print(f\"\\n Saved to {OUTPUT_CSV}\")\n",
    "            \n",
    "        else:\n",
    "            print(\" No data returned.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b28b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Spot Data from Final_nifty_spot_1minute_fixed_trimmed.csv...\n",
      "\n",
      "   Loaded 550600 rows.\n",
      "2. Pilot Subset: 1502 rows (Jan 2020 & Recent).   Loaded 550600 rows.\n",
      "2. Pilot Subset: 1502 rows (Jan 2020 & Recent).\n",
      "\n",
      "Ready to Groww!\n",
      "\n",
      "--- Starting Pilot Download ---\n",
      "\n",
      "Processing Expiry: 02Jan20\n",
      "Ready to Groww!\n",
      "\n",
      "--- Starting Pilot Download ---\n",
      "\n",
      "Processing Expiry: 02Jan20\n",
      "   Using Date: 02Jan20 | Fetching 12 contracts...\n",
      "   Using Date: 02Jan20 | Fetching 12 contracts...\n",
      "\n",
      "Processing Expiry: 09Dec25\n",
      "\n",
      "Processing Expiry: 09Dec25\n",
      "   Using Date: 09Dec25 | Fetching 18 contracts...\n",
      "   Using Date: 09Dec25 | Fetching 18 contracts...\n",
      "\n",
      "Processing Expiry: 09Jan20\n",
      "\n",
      "Processing Expiry: 09Jan20\n",
      "   Using Date: 09Jan20 | Fetching 8 contracts...\n",
      "   Using Date: 09Jan20 | Fetching 8 contracts...\n",
      "\n",
      " PILOT SUCCESS! Saved 1502 rows to test_pilot_output.csv\n",
      "First 5 Rows:\n",
      "            timestamp   expiry  atm_ce_ltp  atm_ce_oi\n",
      "0 2020-01-01 09:15:00  02Jan20       40.15  2403225.0\n",
      "1 2020-01-01 09:16:00  02Jan20       36.55  2403225.0\n",
      "2 2020-01-01 09:17:00  02Jan20       35.65  2540850.0\n",
      "3 2020-01-01 09:18:00  02Jan20       37.95  2540850.0\n",
      "4 2020-01-01 09:19:00  02Jan20       39.55  2540850.0\n",
      " PILOT SUCCESS! Saved 1502 rows to test_pilot_output.csv\n",
      "First 5 Rows:\n",
      "            timestamp   expiry  atm_ce_ltp  atm_ce_oi\n",
      "0 2020-01-01 09:15:00  02Jan20       40.15  2403225.0\n",
      "1 2020-01-01 09:16:00  02Jan20       36.55  2403225.0\n",
      "2 2020-01-01 09:17:00  02Jan20       35.65  2540850.0\n",
      "3 2020-01-01 09:18:00  02Jan20       37.95  2540850.0\n",
      "4 2020-01-01 09:19:00  02Jan20       39.55  2540850.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from growwapi import GrowwAPI\n",
    "\n",
    "# --- CREDENTIALS ---\n",
    "API_KEY = \"eyJraWQiOiJaTUtjVXciLCJhbGciOiJFUzI1NiJ9.eyJleHAiOjI1NTM1Njg0NzYsImlhdCI6MTc2NTE2ODQ3NiwibmJmIjoxNzY1MTY4NDc2LCJzdWIiOiJ7XCJ0b2tlblJlZklkXCI6XCJhMTg3NDVhMy1hN2M1LTRlOTQtODE1MS1lZjUxZDQ5OGE2Y2RcIixcInZlbmRvckludGVncmF0aW9uS2V5XCI6XCJlMzFmZjIzYjA4NmI0MDZjODg3NGIyZjZkODQ5NTMxM1wiLFwidXNlckFjY291bnRJZFwiOlwiMDdmMDA0MGMtZTk4Zi00ZDNmLTk5Y2EtZDc1ZjBlYWU5M2NlXCIsXCJkZXZpY2VJZFwiOlwiZDMyMWIxMzUtZWQ5Mi01ZWJkLWJjMDUtZTY1NDY2OWRiMDM5XCIsXCJzZXNzaW9uSWRcIjpcIjBlOWMyYWZmLTM0NzktNDUyMi1iODE4LTczNTZlMzFkYmY1Y1wiLFwiYWRkaXRpb25hbERhdGFcIjpcIno1NC9NZzltdjE2WXdmb0gvS0EwYk1yOE5XVzhzdTNvZ080am1ZUzIwZEpSTkczdTlLa2pWZDNoWjU1ZStNZERhWXBOVi9UOUxIRmtQejFFQisybTdRPT1cIixcInJvbGVcIjpcImF1dGgtdG90cFwiLFwic291cmNlSXBBZGRyZXNzXCI6XCIyNDA5OjQwOTA6MTA4ZjpkYzA1OjNkMWQ6MWZmMDo1YWFjOjYwNTYsMTcyLjcxLjE5OC4xOSwzNS4yNDEuMjMuMTIzXCIsXCJ0d29GYUV4cGlyeVRzXCI6MjU1MzU2ODQ3NjQzNn0iLCJpc3MiOiJhcGV4LWF1dGgtcHJvZC1hcHAifQ.VuAMgqoC3e32gduObByNz97jFfG-ikXoREum26XPkvyMpj9JgCedXBI81jxGTPTrZD9i1wIL0s38LPd9vc9ApA\"\n",
    "API_SECRET = \"xy0sbQ4r*!HN3&&UKc9vpwti4xx8PR)(\"\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SPOT_FILE = \"Final_nifty_spot_1minute_fixed_trimmed.csv\" # Your uploaded file\n",
    "OUTPUT_FILE = \"test_pilot_output.csv\"\n",
    "\n",
    "def auth():\n",
    "    try:\n",
    "        token = GrowwAPI.get_access_token(api_key=API_KEY, secret=API_SECRET)\n",
    "        return GrowwAPI(token)\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL: Auth failed. Error: {e}\")\n",
    "        exit()\n",
    "\n",
    "# --- 1. FIXED EXPIRY LOGIC (Handles Timezones & 2025 Switch) ---\n",
    "def get_target_expiry_date(date_obj):\n",
    "    # CRITICAL FIX: Remove timezone info (e.g. +05:30) for safe comparison\n",
    "    date_obj = date_obj.replace(tzinfo=None)\n",
    "    \n",
    "    # Logic: Thursday before Sep 1, 2025. Tuesday after.\n",
    "    switch_date = pd.Timestamp(\"2025-09-01\")\n",
    "    target_day = 1 if date_obj >= switch_date else 3 # 1=Tue, 3=Thu\n",
    "    \n",
    "    days_ahead = target_day - date_obj.weekday()\n",
    "    if days_ahead < 0: \n",
    "        days_ahead += 7\n",
    "        \n",
    "    return date_obj + timedelta(days=days_ahead)\n",
    "\n",
    "def run_pilot_test():\n",
    "    # 1. Load Data\n",
    "    print(f\"1. Loading Spot Data from {SPOT_FILE}...\")\n",
    "    try:\n",
    "        df_spot = pd.read_csv(SPOT_FILE)\n",
    "        \n",
    "        # Handle Timestamps with Timezone (e.g. +05:30)\n",
    "        # We use utc=True to normalize, then convert to naive if needed, or just let pandas handle it\n",
    "        df_spot['timestamp'] = pd.to_datetime(df_spot['timestamp'])\n",
    "        \n",
    "        # Remove timezone for easier processing\n",
    "        df_spot['timestamp'] = df_spot['timestamp'].dt.tz_localize(None)\n",
    "        \n",
    "        df_spot.sort_values('timestamp', inplace=True)\n",
    "        print(f\"   Loaded {len(df_spot)} rows.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"   Error: File not found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Select Test Ranges (First 2 days of 2020 and Last 2 days of data)\n",
    "    # This proves both 'Old' and 'New' formats work\n",
    "    start_2020 = df_spot['timestamp'].min()\n",
    "    end_2020 = start_2020 + timedelta(days=3)\n",
    "    \n",
    "    start_recent = df_spot['timestamp'].max() - timedelta(days=3)\n",
    "    end_recent = df_spot['timestamp'].max()\n",
    "    \n",
    "    mask = ((df_spot['timestamp'] >= start_2020) & (df_spot['timestamp'] <= end_2020)) | \\\n",
    "           ((df_spot['timestamp'] >= start_recent) & (df_spot['timestamp'] <= end_recent))\n",
    "           \n",
    "    df_test = df_spot.loc[mask].copy()\n",
    "    print(f\"2. Pilot Subset: {len(df_test)} rows (Jan 2020 & Recent).\")\n",
    "\n",
    "    # 3. Prepare Data\n",
    "    df_test['atm_strike'] = (df_test['close'] / 50).round() * 50\n",
    "    df_test['expiry_dt'] = df_test['timestamp'].apply(get_target_expiry_date)\n",
    "    df_test['expiry_str'] = df_test['expiry_dt'].dt.strftime(\"%d%b%y\")\n",
    "    \n",
    "    # 4. Run Download Loop (Mini Version)\n",
    "    groww = auth()\n",
    "    option_cache = {}\n",
    "    grouped = df_test.groupby('expiry_str')\n",
    "    \n",
    "    print(\"\\n--- Starting Pilot Download ---\")\n",
    "    \n",
    "    rows_collected = []\n",
    "    \n",
    "    for expiry_str, group in grouped:\n",
    "        print(f\"\\nProcessing Expiry: {expiry_str}\")\n",
    "        \n",
    "        # Identify Strikes\n",
    "        atm_strikes = group['atm_strike'].unique().astype(int)\n",
    "        strikes_to_fetch = set()\n",
    "        for k in atm_strikes:\n",
    "            strikes_to_fetch.add(k)      # ATM\n",
    "            strikes_to_fetch.add(k - 50) # ITM\n",
    "            strikes_to_fetch.add(k + 50) # OTM\n",
    "        \n",
    "        # Date Logic\n",
    "        primary_dt = group['expiry_dt'].iloc[0]\n",
    "        backup_dt = primary_dt - timedelta(days=1)\n",
    "        fmt_primary = primary_dt.strftime(\"%d%b%y\")\n",
    "        fmt_backup = backup_dt.strftime(\"%d%b%y\")\n",
    "        \n",
    "        # Active Format Detection\n",
    "        active_fmt = fmt_primary\n",
    "        # Quick check using first available strike\n",
    "        test_sym = f\"NSE-NIFTY-{fmt_primary}-{list(strikes_to_fetch)[0]}-CE\"\n",
    "        \n",
    "        try:\n",
    "            check_start = group['timestamp'].min().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            check_end = (group['timestamp'].min() + timedelta(days=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            resp = groww.get_historical_candles(\n",
    "                exchange=\"NSE\", segment=\"FNO\", groww_symbol=test_sym,\n",
    "                start_time=check_start, end_time=check_end, candle_interval=\"1minute\"\n",
    "            )\n",
    "            if not (resp and \"candles\" in resp and len(resp[\"candles\"]) > 0):\n",
    "                print(f\"   Note: Primary expiry {fmt_primary} empty, checking backup...\")\n",
    "                active_fmt = fmt_backup\n",
    "        except:\n",
    "            active_fmt = fmt_backup\n",
    "            \n",
    "        print(f\"   Using Date: {active_fmt} | Fetching {len(strikes_to_fetch)*2} contracts...\")\n",
    "\n",
    "        # Download\n",
    "        start_dt_str = group['timestamp'].min().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        end_dt_str = group['timestamp'].max().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        for strike in strikes_to_fetch:\n",
    "            for opt_type in ['CE', 'PE']:\n",
    "                sym = f\"NSE-NIFTY-{active_fmt}-{strike}-{opt_type}\"\n",
    "                if sym in option_cache: continue\n",
    "                \n",
    "                try:\n",
    "                    resp = groww.get_historical_candles(\n",
    "                        exchange=\"NSE\", segment=\"FNO\", groww_symbol=sym,\n",
    "                        start_time=start_dt_str, end_time=end_dt_str, candle_interval=\"1minute\"\n",
    "                    )\n",
    "                    \n",
    "                    if resp and \"candles\" in resp and len(resp[\"candles\"]) > 0:\n",
    "                        df = pd.DataFrame(resp[\"candles\"])\n",
    "                        \n",
    "                        # FIX: Handle Column Variations\n",
    "                        if len(df.columns) == 7:\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close', 'v', 'oi']\n",
    "                        elif len(df.columns) == 6:\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close', 'v']\n",
    "                            df['oi'] = 0\n",
    "                        else:\n",
    "                            df = df.iloc[:, :5]\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close']\n",
    "                            df['oi'] = 0\n",
    "                            \n",
    "                        # FIX: Handle String vs Int Timestamps\n",
    "                        if isinstance(df['ts'].iloc[0], str):\n",
    "                            df['timestamp'] = pd.to_datetime(df['ts'])\n",
    "                        else:\n",
    "                            df['timestamp'] = pd.to_datetime(df['ts'], unit='s')\n",
    "                            \n",
    "                        # Remove timezone for merging\n",
    "                        df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "                        \n",
    "                        df.set_index('timestamp', inplace=True)\n",
    "                        df = df[~df.index.duplicated(keep='first')]\n",
    "                        option_cache[sym] = df\n",
    "                except Exception:\n",
    "                    pass\n",
    "        \n",
    "        # Stitch\n",
    "        for index, row in group.iterrows():\n",
    "            ts = row['timestamp']\n",
    "            atm = int(row['atm_strike'])\n",
    "            \n",
    "            def get_data(s, t):\n",
    "                k = f\"NSE-NIFTY-{active_fmt}-{s}-{t}\"\n",
    "                if k in option_cache and ts in option_cache[k].index:\n",
    "                    d = option_cache[k].loc[ts]\n",
    "                    return d['close'], d.get('oi', 0)\n",
    "                return None, None\n",
    "\n",
    "            atm_ce, atm_ce_oi = get_data(atm, \"CE\")\n",
    "            atm_pe, atm_pe_oi = get_data(atm, \"PE\")\n",
    "            itm_ce, itm_ce_oi = get_data(atm-50, \"CE\")\n",
    "            itm_pe, itm_pe_oi = get_data(atm+50, \"PE\")\n",
    "            \n",
    "            rows_collected.append({\n",
    "                \"timestamp\": ts,\n",
    "                \"nifty_open\": row['open'],\n",
    "                \"nifty_high\": row['high'],\n",
    "                \"nifty_low\": row['low'],\n",
    "                \"nifty_close\": row['close'],\n",
    "                \"expiry\": expiry_str,\n",
    "                \"atm_strike\": atm,\n",
    "                \"atm_ce_ltp\": atm_ce, \"atm_ce_oi\": atm_ce_oi,\n",
    "                \"atm_pe_ltp\": atm_pe, \"atm_pe_oi\": atm_pe_oi,\n",
    "                \"itm_ce_ltp\": itm_ce, \"itm_ce_oi\": itm_ce_oi,\n",
    "                \"itm_pe_ltp\": itm_pe, \"itm_pe_oi\": itm_pe_oi\n",
    "            })\n",
    "        \n",
    "        option_cache.clear()\n",
    "\n",
    "    # Save\n",
    "    if rows_collected:\n",
    "        final_df = pd.DataFrame(rows_collected)\n",
    "        final_df.to_csv(OUTPUT_FILE, index=False)\n",
    "        print(f\"\\n PILOT SUCCESS! Saved {len(final_df)} rows to {OUTPUT_FILE}\")\n",
    "        print(\"First 5 Rows:\")\n",
    "        print(final_df[['timestamp', 'expiry', 'atm_ce_ltp', 'atm_ce_oi']].head())\n",
    "    else:\n",
    "        print(\"\\n PILOT FAILED: No rows collected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pilot_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d700f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Spot Data from Final_nifty_spot_1minute_fixed_trimmed.csv...\n",
      "\n",
      "   Loaded 550600 rows.\n",
      "2. Calculating Expiries & Strikes...\n",
      "   Loaded 550600 rows.\n",
      "2. Calculating Expiries & Strikes...\n",
      "Ready to Groww!\n",
      "\n",
      "--- Starting Full Download (312 Weeks) ---Ready to Groww!\n",
      "\n",
      "--- Starting Full Download (312 Weeks) ---\n",
      "\n",
      "\n",
      "[1/312] Processing Week: 01Apr21\n",
      "\n",
      "[1/312] Processing Week: 01Apr21\n",
      "   Date: 01Apr21 | Fetching 26 contracts...\n",
      "   Date: 01Apr21 | Fetching 26 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[2/312] Processing Week: 01Aug24\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[2/312] Processing Week: 01Aug24\n",
      "   Date: 01Aug24 | Fetching 30 contracts...\n",
      "   Date: 01Aug24 | Fetching 30 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[3/312] Processing Week: 01Dec22\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[3/312] Processing Week: 01Dec22\n",
      "   Date: 01Dec22 | Fetching 24 contracts...\n",
      "   Date: 01Dec22 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[4/312] Processing Week: 01Feb24\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[4/312] Processing Week: 01Feb24\n",
      "   Date: 01Feb24 | Fetching 22 contracts...\n",
      "   Date: 01Feb24 | Fetching 22 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[5/312] Processing Week: 01Jul21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[5/312] Processing Week: 01Jul21\n",
      "   Date: 01Jul21 | Fetching 16 contracts...\n",
      "   Date: 01Jul21 | Fetching 16 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[6/312] Processing Week: 01Jun23\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[6/312] Processing Week: 01Jun23\n",
      "   Date: 01Jun23 | Fetching 18 contracts...\n",
      "   Date: 01Jun23 | Fetching 18 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[7/312] Processing Week: 01May25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[7/312] Processing Week: 01May25\n",
      "   Date: 30Apr25 | Fetching 30 contracts...\n",
      "   Date: 30Apr25 | Fetching 30 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[8/312] Processing Week: 01Oct20\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[8/312] Processing Week: 01Oct20\n",
      "   Date: 01Oct20 | Fetching 30 contracts...\n",
      "   Date: 01Oct20 | Fetching 30 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[9/312] Processing Week: 01Sep22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[9/312] Processing Week: 01Sep22\n",
      "   Date: 01Sep22 | Fetching 32 contracts...\n",
      "   Date: 01Sep22 | Fetching 32 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[10/312] Processing Week: 02Apr20\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[10/312] Processing Week: 02Apr20\n",
      "   Date: 01Apr20 | Fetching 40 contracts...\n",
      "   Date: 01Apr20 | Fetching 40 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[11/312] Processing Week: 02Dec21\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[11/312] Processing Week: 02Dec21\n",
      "   Date: 02Dec21 | Fetching 30 contracts...\n",
      "   Date: 02Dec21 | Fetching 30 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[12/312] Processing Week: 02Dec25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[12/312] Processing Week: 02Dec25\n",
      "   Date: 02Dec25 | Fetching 20 contracts...\n",
      "   Date: 02Dec25 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[13/312] Processing Week: 02Feb23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[13/312] Processing Week: 02Feb23\n",
      "   Date: 02Feb23 | Fetching 30 contracts...\n",
      "   Date: 02Feb23 | Fetching 30 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[14/312] Processing Week: 02Jan20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[14/312] Processing Week: 02Jan20\n",
      "   Date: 02Jan20 | Fetching 12 contracts...\n",
      "   Date: 02Jan20 | Fetching 12 contracts...\n",
      "    Batch Saved (750 rows)\n",
      "\n",
      "[15/312] Processing Week: 02Jan25\n",
      "    Batch Saved (750 rows)\n",
      "\n",
      "[15/312] Processing Week: 02Jan25\n",
      "   Date: 02Jan25 | Fetching 36 contracts...\n",
      "   Date: 02Jan25 | Fetching 36 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[16/312] Processing Week: 02Jul20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[16/312] Processing Week: 02Jul20\n",
      "   Date: 02Jul20 | Fetching 20 contracts...\n",
      "   Date: 02Jul20 | Fetching 20 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[17/312] Processing Week: 02Jun22\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[17/312] Processing Week: 02Jun22\n",
      "   Date: 02Jun22 | Fetching 26 contracts...\n",
      "   Date: 02Jun22 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[18/312] Processing Week: 02Mar23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[18/312] Processing Week: 02Mar23\n",
      "   Date: 02Mar23 | Fetching 20 contracts...\n",
      "   Date: 02Mar23 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[19/312] Processing Week: 02May24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[19/312] Processing Week: 02May24\n",
      "   Date: 02May24 | Fetching 22 contracts...\n",
      "   Date: 02May24 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[20/312] Processing Week: 02Nov23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[20/312] Processing Week: 02Nov23\n",
      "   Date: 02Nov23 | Fetching 16 contracts...\n",
      "   Date: 02Nov23 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[21/312] Processing Week: 02Sep21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[21/312] Processing Week: 02Sep21\n",
      "   Date: 02Sep21 | Fetching 34 contracts...\n",
      "   Date: 02Sep21 | Fetching 34 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[22/312] Processing Week: 02Sep25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[22/312] Processing Week: 02Sep25\n",
      "   Date: 02Sep25 | Fetching 16 contracts...\n",
      "   Date: 02Sep25 | Fetching 16 contracts...\n",
      "    Batch Saved (752 rows)\n",
      "\n",
      "[23/312] Processing Week: 03Apr25\n",
      "    Batch Saved (752 rows)\n",
      "\n",
      "[23/312] Processing Week: 03Apr25\n",
      "   Date: 03Apr25 | Fetching 26 contracts...\n",
      "   Date: 03Apr25 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[24/312] Processing Week: 03Aug23\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[24/312] Processing Week: 03Aug23\n",
      "   Date: 03Aug23 | Fetching 26 contracts...\n",
      "   Date: 03Aug23 | Fetching 26 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[25/312] Processing Week: 03Dec20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[25/312] Processing Week: 03Dec20\n",
      "   Date: 03Dec20 | Fetching 16 contracts...\n",
      "   Date: 03Dec20 | Fetching 16 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[26/312] Processing Week: 03Feb22\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[26/312] Processing Week: 03Feb22\n",
      "   Date: 03Feb22 | Fetching 34 contracts...\n",
      "   Date: 03Feb22 | Fetching 34 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[27/312] Processing Week: 03Jul25\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[27/312] Processing Week: 03Jul25\n",
      "   Date: 03Jul25 | Fetching 16 contracts...\n",
      "   Date: 03Jul25 | Fetching 16 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[28/312] Processing Week: 03Jun21\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[28/312] Processing Week: 03Jun21\n",
      "   Date: 03Jun21 | Fetching 18 contracts...\n",
      "   Date: 03Jun21 | Fetching 18 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[29/312] Processing Week: 03Mar22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[29/312] Processing Week: 03Mar22\n",
      "   Date: 03Mar22 | Fetching 24 contracts...\n",
      "   Date: 03Mar22 | Fetching 24 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[30/312] Processing Week: 03Nov22\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[30/312] Processing Week: 03Nov22\n",
      "   Date: 03Nov22 | Fetching 22 contracts...\n",
      "   Date: 03Nov22 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[31/312] Processing Week: 03Oct24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[31/312] Processing Week: 03Oct24\n",
      "   Date: 03Oct24 | Fetching 46 contracts...\n",
      "   Date: 03Oct24 | Fetching 46 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[32/312] Processing Week: 03Sep20\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[32/312] Processing Week: 03Sep20\n",
      "   Date: 03Sep20 | Fetching 24 contracts...\n",
      "   Date: 03Sep20 | Fetching 24 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[33/312] Processing Week: 04Apr24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[33/312] Processing Week: 04Apr24\n",
      "   Date: 04Apr24 | Fetching 18 contracts...\n",
      "   Date: 04Apr24 | Fetching 18 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[34/312] Processing Week: 04Aug22\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[34/312] Processing Week: 04Aug22\n",
      "   Date: 04Aug22 | Fetching 26 contracts...\n",
      "   Date: 04Aug22 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[35/312] Processing Week: 04Feb21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[35/312] Processing Week: 04Feb21\n",
      "   Date: 04Feb21 | Fetching 58 contracts...\n",
      "   Date: 04Feb21 | Fetching 58 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[36/312] Processing Week: 04Jan24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[36/312] Processing Week: 04Jan24\n",
      "   Date: 04Jan24 | Fetching 20 contracts...\n",
      "   Date: 04Jan24 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[37/312] Processing Week: 04Jul24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[37/312] Processing Week: 04Jul24\n",
      "   Date: 04Jul24 | Fetching 22 contracts...\n",
      "   Date: 04Jul24 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[38/312] Processing Week: 04Jun20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[38/312] Processing Week: 04Jun20\n",
      "   Date: 04Jun20 | Fetching 36 contracts...\n",
      "   Date: 04Jun20 | Fetching 36 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[39/312] Processing Week: 04Mar21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[39/312] Processing Week: 04Mar21\n",
      "   Date: 04Mar21 | Fetching 38 contracts...\n",
      "   Date: 04Mar21 | Fetching 38 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[40/312] Processing Week: 04May23\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[40/312] Processing Week: 04May23\n",
      "   Date: 04May23 | Fetching 20 contracts...\n",
      "   Date: 04May23 | Fetching 20 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[41/312] Processing Week: 04Nov21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[41/312] Processing Week: 04Nov21\n",
      "   Date: 03Nov21 | Fetching 22 contracts...\n",
      "   Date: 03Nov21 | Fetching 22 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[42/312] Processing Week: 04Nov25\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[42/312] Processing Week: 04Nov25\n",
      "   Date: 04Nov25 | Fetching 26 contracts...\n",
      "   Date: 04Nov25 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[43/312] Processing Week: 04Sep25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[43/312] Processing Week: 04Sep25\n",
      "   Date: 03Sep25 | Fetching 12 contracts...\n",
      "   Date: 03Sep25 | Fetching 12 contracts...\n",
      "    Batch Saved (376 rows)\n",
      "\n",
      "[44/312] Processing Week: 05Aug21\n",
      "    Batch Saved (376 rows)\n",
      "\n",
      "[44/312] Processing Week: 05Aug21\n",
      "   Date: 05Aug21 | Fetching 30 contracts...\n",
      "   Date: 05Aug21 | Fetching 30 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[45/312] Processing Week: 05Dec24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[45/312] Processing Week: 05Dec24\n",
      "   Date: 05Dec24 | Fetching 42 contracts...\n",
      "   Date: 05Dec24 | Fetching 42 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[46/312] Processing Week: 05Jan23\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[46/312] Processing Week: 05Jan23\n",
      "   Date: 05Jan23 | Fetching 20 contracts...\n",
      "   Date: 05Jan23 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[47/312] Processing Week: 05Jun25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[47/312] Processing Week: 05Jun25\n",
      "   Date: 05Jun25 | Fetching 22 contracts...\n",
      "   Date: 05Jun25 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[48/312] Processing Week: 05Mar20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[48/312] Processing Week: 05Mar20\n",
      "   Date: 05Mar20 | Fetching 22 contracts...\n",
      "   Date: 05Mar20 | Fetching 22 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[49/312] Processing Week: 05May22\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[49/312] Processing Week: 05May22\n",
      "   Date: 05May22 | Fetching 34 contracts...\n",
      "   Date: 05May22 | Fetching 34 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[50/312] Processing Week: 05Nov20    Batch Saved (1503 rows)\n",
      "\n",
      "[50/312] Processing Week: 05Nov20\n",
      "\n",
      "   Date: 05Nov20 | Fetching 30 contracts...\n",
      "   Date: 05Nov20 | Fetching 30 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[51/312] Processing Week: 05Oct23\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[51/312] Processing Week: 05Oct23\n",
      "   Date: 05Oct23 | Fetching 20 contracts...\n",
      "   Date: 05Oct23 | Fetching 20 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[52/312] Processing Week: 05Sep24\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[52/312] Processing Week: 05Sep24\n",
      "   Date: 05Sep24 | Fetching 14 contracts...\n",
      "   Date: 05Sep24 | Fetching 14 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[53/312] Processing Week: 06Apr23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[53/312] Processing Week: 06Apr23\n",
      "   Date: 06Apr23 | Fetching 22 contracts...\n",
      "   Date: 06Apr23 | Fetching 22 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[54/312] Processing Week: 06Aug20\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[54/312] Processing Week: 06Aug20\n",
      "   Date: 06Aug20 | Fetching 20 contracts...\n",
      "   Date: 06Aug20 | Fetching 20 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[55/312] Processing Week: 06Feb20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[55/312] Processing Week: 06Feb20\n",
      "   Date: 06Feb20 | Fetching 28 contracts...\n",
      "   Date: 06Feb20 | Fetching 28 contracts...\n",
      "    Batch Saved (2253 rows)\n",
      "\n",
      "[56/312] Processing Week: 06Feb25    Batch Saved (2253 rows)\n",
      "\n",
      "[56/312] Processing Week: 06Feb25\n",
      "\n",
      "   Date: 06Feb25 | Fetching 28 contracts...\n",
      "   Date: 06Feb25 | Fetching 28 contracts...\n",
      "    Batch Saved (2256 rows)\n",
      "\n",
      "[57/312] Processing Week: 06Jan22    Batch Saved (2256 rows)\n",
      "\n",
      "[57/312] Processing Week: 06Jan22\n",
      "\n",
      "   Date: 06Jan22 | Fetching 32 contracts...\n",
      "   Date: 06Jan22 | Fetching 32 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[58/312] Processing Week: 06Jul23\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[58/312] Processing Week: 06Jul23\n",
      "   Date: 06Jul23 | Fetching 24 contracts...\n",
      "   Date: 06Jul23 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[59/312] Processing Week: 06Jun24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[59/312] Processing Week: 06Jun24\n",
      "   Date: 06Jun24 | Fetching 86 contracts...\n",
      "   Date: 06Jun24 | Fetching 86 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[60/312] Processing Week: 06Mar25    Batch Saved (1880 rows)\n",
      "\n",
      "[60/312] Processing Week: 06Mar25\n",
      "\n",
      "   Date: 06Mar25 | Fetching 30 contracts...\n",
      "   Date: 06Mar25 | Fetching 30 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[61/312] Processing Week: 06May21    Batch Saved (1881 rows)\n",
      "\n",
      "[61/312] Processing Week: 06May21\n",
      "\n",
      "   Date: 06May21 | Fetching 22 contracts...\n",
      "   Date: 06May21 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[62/312] Processing Week: 06Oct22    Batch Saved (1877 rows)\n",
      "\n",
      "[62/312] Processing Week: 06Oct22\n",
      "\n",
      "   Date: 06Oct22 | Fetching 32 contracts...\n",
      "   Date: 06Oct22 | Fetching 32 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[63/312] Processing Week: 07Apr22\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[63/312] Processing Week: 07Apr22\n",
      "   Date: 07Apr22 | Fetching 32 contracts...\n",
      "   Date: 07Apr22 | Fetching 32 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[64/312] Processing Week: 07Aug25    Batch Saved (1877 rows)\n",
      "\n",
      "[64/312] Processing Week: 07Aug25\n",
      "\n",
      "   Date: 07Aug25 | Fetching 24 contracts...\n",
      "   Date: 07Aug25 | Fetching 24 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[65/312] Processing Week: 07Dec23\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[65/312] Processing Week: 07Dec23\n",
      "   Date: 07Dec23 | Fetching 34 contracts...\n",
      "   Date: 07Dec23 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[66/312] Processing Week: 07Jan21    Batch Saved (1881 rows)\n",
      "\n",
      "[66/312] Processing Week: 07Jan21\n",
      "\n",
      "   Date: 07Jan21 | Fetching 18 contracts...\n",
      "   Date: 07Jan21 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[67/312] Processing Week: 07Jul22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[67/312] Processing Week: 07Jul22\n",
      "   Date: 07Jul22 | Fetching 32 contracts...\n",
      "   Date: 07Jul22 | Fetching 32 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[68/312] Processing Week: 07Mar24    Batch Saved (1878 rows)\n",
      "\n",
      "[68/312] Processing Week: 07Mar24\n",
      "\n",
      "   Date: 07Mar24 | Fetching 22 contracts...\n",
      "   Date: 07Mar24 | Fetching 22 contracts...\n",
      "    Batch Saved (1988 rows)\n",
      "\n",
      "[69/312] Processing Week: 07May20\n",
      "    Batch Saved (1988 rows)\n",
      "\n",
      "[69/312] Processing Week: 07May20\n",
      "   Date: 07May20 | Fetching 22 contracts...\n",
      "   Date: 07May20 | Fetching 22 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[70/312] Processing Week: 07Nov24\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[70/312] Processing Week: 07Nov24\n",
      "   Date: 07Nov24 | Fetching 36 contracts...\n",
      "   Date: 07Nov24 | Fetching 36 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[71/312] Processing Week: 07Oct21    Batch Saved (1505 rows)\n",
      "\n",
      "[71/312] Processing Week: 07Oct21\n",
      "\n",
      "   Date: 07Oct21 | Fetching 24 contracts...\n",
      "   Date: 07Oct21 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[72/312] Processing Week: 07Oct25\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[72/312] Processing Week: 07Oct25\n",
      "   Date: 07Oct25 | Fetching 30 contracts...\n",
      "   Date: 07Oct25 | Fetching 30 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[73/312] Processing Week: 07Sep23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[73/312] Processing Week: 07Sep23\n",
      "   Date: 07Sep23 | Fetching 26 contracts...\n",
      "   Date: 07Sep23 | Fetching 26 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[74/312] Processing Week: 08Apr21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[74/312] Processing Week: 08Apr21\n",
      "   Date: 08Apr21 | Fetching 28 contracts...\n",
      "   Date: 08Apr21 | Fetching 28 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[75/312] Processing Week: 08Aug24    Batch Saved (1501 rows)\n",
      "\n",
      "[75/312] Processing Week: 08Aug24\n",
      "\n",
      "   Date: 08Aug24 | Fetching 38 contracts...\n",
      "   Date: 08Aug24 | Fetching 38 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[76/312] Processing Week: 08Dec22    Batch Saved (1881 rows)\n",
      "\n",
      "[76/312] Processing Week: 08Dec22\n",
      "\n",
      "   Date: 08Dec22 | Fetching 14 contracts...\n",
      "   Date: 08Dec22 | Fetching 14 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[77/312] Processing Week: 08Feb24\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[77/312] Processing Week: 08Feb24\n",
      "   Date: 08Feb24 | Fetching 24 contracts...\n",
      "   Date: 08Feb24 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[78/312] Processing Week: 08Jul21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[78/312] Processing Week: 08Jul21\n",
      "   Date: 08Jul21 | Fetching 16 contracts...\n",
      "   Date: 08Jul21 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[79/312] Processing Week: 08Jun23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[79/312] Processing Week: 08Jun23\n",
      "   Date: 08Jun23 | Fetching 18 contracts...\n",
      "   Date: 08Jun23 | Fetching 18 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[80/312] Processing Week: 08May25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[80/312] Processing Week: 08May25\n",
      "   Date: 08May25 | Fetching 24 contracts...\n",
      "   Date: 08May25 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[81/312] Processing Week: 08Oct20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[81/312] Processing Week: 08Oct20\n",
      "   Date: 08Oct20 | Fetching 24 contracts...\n",
      "   Date: 08Oct20 | Fetching 24 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[82/312] Processing Week: 08Sep22\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[82/312] Processing Week: 08Sep22\n",
      "   Date: 08Sep22 | Fetching 18 contracts...\n",
      "   Date: 08Sep22 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[83/312] Processing Week: 09Apr20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[83/312] Processing Week: 09Apr20\n",
      "   Date: 09Apr20 | Fetching 50 contracts...\n",
      "   Date: 09Apr20 | Fetching 50 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[84/312] Processing Week: 09Dec21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[84/312] Processing Week: 09Dec21\n",
      "   Date: 09Dec21 | Fetching 32 contracts...\n",
      "   Date: 09Dec21 | Fetching 32 contracts...\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[85/312] Processing Week: 09Dec25\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[85/312] Processing Week: 09Dec25\n",
      "   Date: 09Dec25 | Fetching 18 contracts...\n",
      "   Date: 09Dec25 | Fetching 18 contracts...\n",
      "    Batch Saved (1423 rows)\n",
      "\n",
      "[86/312] Processing Week: 09Feb23\n",
      "    Batch Saved (1423 rows)\n",
      "\n",
      "[86/312] Processing Week: 09Feb23\n",
      "   Date: 09Feb23 | Fetching 18 contracts...\n",
      "   Date: 09Feb23 | Fetching 18 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[87/312] Processing Week: 09Jan20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[87/312] Processing Week: 09Jan20\n",
      "   Date: 09Jan20 | Fetching 18 contracts...\n",
      "   Date: 09Jan20 | Fetching 18 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[88/312] Processing Week: 09Jan25\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[88/312] Processing Week: 09Jan25\n",
      "   Date: 09Jan25 | Fetching 34 contracts...\n",
      "   Date: 09Jan25 | Fetching 34 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[89/312] Processing Week: 09Jul20    Batch Saved (1882 rows)\n",
      "\n",
      "[89/312] Processing Week: 09Jul20\n",
      "\n",
      "   Date: 09Jul20 | Fetching 18 contracts...\n",
      "   Date: 09Jul20 | Fetching 18 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[90/312] Processing Week: 09Jun22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[90/312] Processing Week: 09Jun22\n",
      "   Date: 09Jun22 | Fetching 28 contracts...\n",
      "   Date: 09Jun22 | Fetching 28 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[91/312] Processing Week: 09Mar23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[91/312] Processing Week: 09Mar23\n",
      "   Date: 09Mar23 | Fetching 20 contracts...\n",
      "   Date: 09Mar23 | Fetching 20 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[92/312] Processing Week: 09May24\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[92/312] Processing Week: 09May24\n",
      "   Date: 09May24 | Fetching 40 contracts...\n",
      "   Date: 09May24 | Fetching 40 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[93/312] Processing Week: 09Nov23    Batch Saved (1882 rows)\n",
      "\n",
      "[93/312] Processing Week: 09Nov23\n",
      "\n",
      "   Date: 09Nov23 | Fetching 16 contracts...\n",
      "   Date: 09Nov23 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[94/312] Processing Week: 09Sep21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[94/312] Processing Week: 09Sep21\n",
      "   Date: 09Sep21 | Fetching 16 contracts...\n",
      "   Date: 09Sep21 | Fetching 16 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[95/312] Processing Week: 09Sep25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[95/312] Processing Week: 09Sep25\n",
      "   Date: 09Sep25 | Fetching 22 contracts...\n",
      "   Date: 09Sep25 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[96/312] Processing Week: 10Apr25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[96/312] Processing Week: 10Apr25\n",
      "   Date: 09Apr25 | Fetching 60 contracts...\n",
      "   Date: 09Apr25 | Fetching 60 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[97/312] Processing Week: 10Aug23    Batch Saved (1505 rows)\n",
      "\n",
      "[97/312] Processing Week: 10Aug23\n",
      "\n",
      "   Date: 10Aug23 | Fetching 14 contracts...\n",
      "   Date: 10Aug23 | Fetching 14 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[98/312] Processing Week: 10Dec20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[98/312] Processing Week: 10Dec20\n",
      "   Date: 10Dec20 | Fetching 22 contracts...\n",
      "   Date: 10Dec20 | Fetching 22 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[99/312] Processing Week: 10Feb22\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[99/312] Processing Week: 10Feb22\n",
      "   Date: 10Feb22 | Fetching 30 contracts...\n",
      "   Date: 10Feb22 | Fetching 30 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[100/312] Processing Week: 10Jul25\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[100/312] Processing Week: 10Jul25\n",
      "   Date: 10Jul25 | Fetching 14 contracts...\n",
      "   Date: 10Jul25 | Fetching 14 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[101/312] Processing Week: 10Jun21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[101/312] Processing Week: 10Jun21\n",
      "   Date: 10Jun21 | Fetching 16 contracts...\n",
      "   Date: 10Jun21 | Fetching 16 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[102/312] Processing Week: 10Mar22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[102/312] Processing Week: 10Mar22\n",
      "   Date: 10Mar22 | Fetching 50 contracts...\n",
      "   Date: 10Mar22 | Fetching 50 contracts...\n",
      "    Batch Saved (1837 rows)\n",
      "\n",
      "[103/312] Processing Week: 10Nov22    Batch Saved (1837 rows)\n",
      "\n",
      "[103/312] Processing Week: 10Nov22\n",
      "\n",
      "   Date: 10Nov22 | Fetching 18 contracts...\n",
      "   Date: 10Nov22 | Fetching 18 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[104/312] Processing Week: 10Oct24\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[104/312] Processing Week: 10Oct24\n",
      "   Date: 10Oct24 | Fetching 38 contracts...\n",
      "   Date: 10Oct24 | Fetching 38 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[105/312] Processing Week: 10Sep20    Batch Saved (1881 rows)\n",
      "\n",
      "[105/312] Processing Week: 10Sep20\n",
      "\n",
      "   Date: 10Sep20 | Fetching 16 contracts...   Date: 10Sep20 | Fetching 16 contracts...\n",
      "\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[106/312] Processing Week: 11Apr24    Batch Saved (1877 rows)\n",
      "\n",
      "[106/312] Processing Week: 11Apr24\n",
      "\n",
      "   Date: 10Apr24 | Fetching 18 contracts...   Date: 10Apr24 | Fetching 18 contracts...\n",
      "\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[107/312] Processing Week: 11Aug22\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[107/312] Processing Week: 11Aug22\n",
      "   Date: 11Aug22 | Fetching 20 contracts...\n",
      "   Date: 11Aug22 | Fetching 20 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[108/312] Processing Week: 11Feb21\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[108/312] Processing Week: 11Feb21\n",
      "   Date: 11Feb21 | Fetching 22 contracts...\n",
      "   Date: 11Feb21 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[109/312] Processing Week: 11Jan24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[109/312] Processing Week: 11Jan24\n",
      "   Date: 11Jan24 | Fetching 16 contracts...\n",
      "   Date: 11Jan24 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[110/312] Processing Week: 11Jul24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[110/312] Processing Week: 11Jul24\n",
      "   Date: 11Jul24 | Fetching 18 contracts...\n",
      "   Date: 11Jul24 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[111/312] Processing Week: 11Jun20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[111/312] Processing Week: 11Jun20\n",
      "   Date: 11Jun20 | Fetching 24 contracts...\n",
      "   Date: 11Jun20 | Fetching 24 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[112/312] Processing Week: 11Mar21\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[112/312] Processing Week: 11Mar21\n",
      "   Date: 10Mar21 | Fetching 20 contracts...\n",
      "   Date: 10Mar21 | Fetching 20 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[113/312] Processing Week: 11May23\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[113/312] Processing Week: 11May23\n",
      "   Date: 11May23 | Fetching 18 contracts...\n",
      "   Date: 11May23 | Fetching 18 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[114/312] Processing Week: 11Nov21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[114/312] Processing Week: 11Nov21\n",
      "   Date: 11Nov21 | Fetching 18 contracts...\n",
      "   Date: 11Nov21 | Fetching 18 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[115/312] Processing Week: 11Nov25\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[115/312] Processing Week: 11Nov25\n",
      "   Date: 11Nov25 | Fetching 22 contracts...\n",
      "   Date: 11Nov25 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[116/312] Processing Week: 12Aug21\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[116/312] Processing Week: 12Aug21\n",
      "   Date: 12Aug21 | Fetching 14 contracts...   Date: 12Aug21 | Fetching 14 contracts...\n",
      "\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[117/312] Processing Week: 12Dec24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[117/312] Processing Week: 12Dec24\n",
      "   Date: 12Dec24 | Fetching 16 contracts...\n",
      "   Date: 12Dec24 | Fetching 16 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[118/312] Processing Week: 12Jan23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[118/312] Processing Week: 12Jan23\n",
      "   Date: 12Jan23 | Fetching 22 contracts...\n",
      "   Date: 12Jan23 | Fetching 22 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[119/312] Processing Week: 12Jun25    Batch Saved (1878 rows)\n",
      "\n",
      "[119/312] Processing Week: 12Jun25\n",
      "\n",
      "   Date: 12Jun25 | Fetching 26 contracts...\n",
      "   Date: 12Jun25 | Fetching 26 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[120/312] Processing Week: 12Mar20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[120/312] Processing Week: 12Mar20\n",
      "   Date: 11Mar20 | Fetching 62 contracts...\n",
      "   Date: 11Mar20 | Fetching 62 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[121/312] Processing Week: 12May22\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[121/312] Processing Week: 12May22\n",
      "   Date: 12May22 | Fetching 36 contracts...\n",
      "   Date: 12May22 | Fetching 36 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[122/312] Processing Week: 12Nov20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[122/312] Processing Week: 12Nov20\n",
      "   Date: 12Nov20 | Fetching 30 contracts...\n",
      "   Date: 12Nov20 | Fetching 30 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[123/312] Processing Week: 12Oct23\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[123/312] Processing Week: 12Oct23\n",
      "   Date: 12Oct23 | Fetching 20 contracts...\n",
      "   Date: 12Oct23 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[124/312] Processing Week: 12Sep24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[124/312] Processing Week: 12Sep24\n",
      "   Date: 12Sep24 | Fetching 34 contracts...\n",
      "   Date: 12Sep24 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[125/312] Processing Week: 13Apr23    Batch Saved (1881 rows)\n",
      "\n",
      "[125/312] Processing Week: 13Apr23\n",
      "\n",
      "   Date: 13Apr23 | Fetching 16 contracts...\n",
      "   Date: 13Apr23 | Fetching 16 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[126/312] Processing Week: 13Aug20\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[126/312] Processing Week: 13Aug20\n",
      "   Date: 13Aug20 | Fetching 14 contracts...\n",
      "   Date: 13Aug20 | Fetching 14 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[127/312] Processing Week: 13Feb20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[127/312] Processing Week: 13Feb20\n",
      "   Date: 13Feb20 | Fetching 16 contracts...\n",
      "   Date: 13Feb20 | Fetching 16 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[128/312] Processing Week: 13Feb25\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[128/312] Processing Week: 13Feb25\n",
      "   Date: 13Feb25 | Fetching 42 contracts...\n",
      "   Date: 13Feb25 | Fetching 42 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[129/312] Processing Week: 13Jan22\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[129/312] Processing Week: 13Jan22\n",
      "   Date: 13Jan22 | Fetching 28 contracts...\n",
      "   Date: 13Jan22 | Fetching 28 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[130/312] Processing Week: 13Jul23    Batch Saved (1877 rows)\n",
      "\n",
      "[130/312] Processing Week: 13Jul23\n",
      "\n",
      "   Date: 13Jul23 | Fetching 16 contracts...\n",
      "   Date: 13Jul23 | Fetching 16 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[131/312] Processing Week: 13Jun24\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[131/312] Processing Week: 13Jun24\n",
      "   Date: 13Jun24 | Fetching 32 contracts...\n",
      "   Date: 13Jun24 | Fetching 32 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[132/312] Processing Week: 13Mar25    Batch Saved (1882 rows)\n",
      "\n",
      "[132/312] Processing Week: 13Mar25\n",
      "\n",
      "   Date: 13Mar25 | Fetching 20 contracts...\n",
      "   Date: 13Mar25 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[133/312] Processing Week: 13May21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[133/312] Processing Week: 13May21\n",
      "   Date: 12May21 | Fetching 18 contracts...\n",
      "   Date: 12May21 | Fetching 18 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[134/312] Processing Week: 13Oct22\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[134/312] Processing Week: 13Oct22\n",
      "   Date: 13Oct22 | Fetching 22 contracts...\n",
      "   Date: 13Oct22 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[135/312] Processing Week: 14Apr22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[135/312] Processing Week: 14Apr22\n",
      "   Date: 13Apr22 | Fetching 22 contracts...\n",
      "   Date: 13Apr22 | Fetching 22 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[136/312] Processing Week: 14Aug25\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[136/312] Processing Week: 14Aug25\n",
      "   Date: 14Aug25 | Fetching 20 contracts...\n",
      "   Date: 14Aug25 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[137/312] Processing Week: 14Dec23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[137/312] Processing Week: 14Dec23\n",
      "   Date: 14Dec23 | Fetching 24 contracts...\n",
      "   Date: 14Dec23 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[138/312] Processing Week: 14Jan21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[138/312] Processing Week: 14Jan21\n",
      "   Date: 14Jan21 | Fetching 22 contracts...\n",
      "   Date: 14Jan21 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[139/312] Processing Week: 14Jul22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[139/312] Processing Week: 14Jul22\n",
      "   Date: 14Jul22 | Fetching 22 contracts...\n",
      "   Date: 14Jul22 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[140/312] Processing Week: 14Mar24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[140/312] Processing Week: 14Mar24\n",
      "   Date: 14Mar24 | Fetching 30 contracts...\n",
      "   Date: 14Mar24 | Fetching 30 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[141/312] Processing Week: 14May20\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[141/312] Processing Week: 14May20\n",
      "   Date: 14May20 | Fetching 24 contracts...\n",
      "   Date: 14May20 | Fetching 24 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[142/312] Processing Week: 14Nov24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[142/312] Processing Week: 14Nov24\n",
      "   Date: 14Nov24 | Fetching 40 contracts...\n",
      "   Date: 14Nov24 | Fetching 40 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[143/312] Processing Week: 14Oct21    Batch Saved (1881 rows)\n",
      "\n",
      "[143/312] Processing Week: 14Oct21\n",
      "\n",
      "   Date: 14Oct21 | Fetching 26 contracts...\n",
      "   Date: 14Oct21 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[144/312] Processing Week: 14Oct25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[144/312] Processing Week: 14Oct25\n",
      "   Date: 14Oct25 | Fetching 18 contracts...\n",
      "   Date: 14Oct25 | Fetching 18 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[145/312] Processing Week: 14Sep23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[145/312] Processing Week: 14Sep23\n",
      "   Date: 14Sep23 | Fetching 22 contracts...   Date: 14Sep23 | Fetching 22 contracts...\n",
      "\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[146/312] Processing Week: 15Apr21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[146/312] Processing Week: 15Apr21\n",
      "   Date: 15Apr21 | Fetching 30 contracts...\n",
      "   Date: 15Apr21 | Fetching 30 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[147/312] Processing Week: 15Aug24\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[147/312] Processing Week: 15Aug24\n",
      "   Date: 14Aug24 | Fetching 20 contracts...\n",
      "   Date: 14Aug24 | Fetching 20 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[148/312] Processing Week: 15Dec22\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[148/312] Processing Week: 15Dec22\n",
      "   Date: 15Dec22 | Fetching 20 contracts...\n",
      "   Date: 15Dec22 | Fetching 20 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[149/312] Processing Week: 15Feb24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[149/312] Processing Week: 15Feb24\n",
      "   Date: 15Feb24 | Fetching 22 contracts...\n",
      "   Date: 15Feb24 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[150/312] Processing Week: 15Jul21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[150/312] Processing Week: 15Jul21\n",
      "   Date: 15Jul21 | Fetching 18 contracts...\n",
      "   Date: 15Jul21 | Fetching 18 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[151/312] Processing Week: 15Jun23\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[151/312] Processing Week: 15Jun23\n",
      "   Date: 15Jun23 | Fetching 16 contracts...\n",
      "   Date: 15Jun23 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[152/312] Processing Week: 15May25    Batch Saved (1880 rows)\n",
      "\n",
      "[152/312] Processing Week: 15May25\n",
      "\n",
      "   Date: 15May25 | Fetching 44 contracts...\n",
      "   Date: 15May25 | Fetching 44 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[153/312] Processing Week: 15Oct20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[153/312] Processing Week: 15Oct20\n",
      "   Date: 15Oct20 | Fetching 20 contracts...\n",
      "   Date: 15Oct20 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[154/312] Processing Week: 15Sep22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[154/312] Processing Week: 15Sep22\n",
      "   Date: 15Sep22 | Fetching 18 contracts...\n",
      "   Date: 15Sep22 | Fetching 18 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[155/312] Processing Week: 16Apr20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[155/312] Processing Week: 16Apr20\n",
      "   Date: 16Apr20 | Fetching 22 contracts...\n",
      "   Date: 16Apr20 | Fetching 22 contracts...\n",
      "    Batch Saved (1126 rows)\n",
      "\n",
      "[156/312] Processing Week: 16Dec21\n",
      "    Batch Saved (1126 rows)\n",
      "\n",
      "[156/312] Processing Week: 16Dec21\n",
      "   Date: 16Dec21 | Fetching 24 contracts...\n",
      "   Date: 16Dec21 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[157/312] Processing Week: 16Feb23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[157/312] Processing Week: 16Feb23\n",
      "   Date: 16Feb23 | Fetching 24 contracts...\n",
      "   Date: 16Feb23 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[158/312] Processing Week: 16Jan20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[158/312] Processing Week: 16Jan20\n",
      "   Date: 16Jan20 | Fetching 14 contracts...\n",
      "   Date: 16Jan20 | Fetching 14 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[159/312] Processing Week: 16Jan25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[159/312] Processing Week: 16Jan25\n",
      "   Date: 16Jan25 | Fetching 28 contracts...\n",
      "   Date: 16Jan25 | Fetching 28 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[160/312] Processing Week: 16Jul20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[160/312] Processing Week: 16Jul20\n",
      "   Date: 16Jul20 | Fetching 20 contracts...\n",
      "   Date: 16Jul20 | Fetching 20 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[161/312] Processing Week: 16Jun22\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[161/312] Processing Week: 16Jun22\n",
      "   Date: 16Jun22 | Fetching 38 contracts...\n",
      "   Date: 16Jun22 | Fetching 38 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[162/312] Processing Week: 16Mar23    Batch Saved (1881 rows)\n",
      "\n",
      "[162/312] Processing Week: 16Mar23\n",
      "\n",
      "   Date: 16Mar23 | Fetching 34 contracts...\n",
      "   Date: 16Mar23 | Fetching 34 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[163/312] Processing Week: 16May24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[163/312] Processing Week: 16May24\n",
      "   Date: 16May24 | Fetching 32 contracts...\n",
      "   Date: 16May24 | Fetching 32 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[164/312] Processing Week: 16Nov23    Batch Saved (1881 rows)\n",
      "\n",
      "[164/312] Processing Week: 16Nov23\n",
      "\n",
      "   Date: 16Nov23 | Fetching 26 contracts...\n",
      "   Date: 16Nov23 | Fetching 26 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[165/312] Processing Week: 16Sep21\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[165/312] Processing Week: 16Sep21\n",
      "   Date: 16Sep21 | Fetching 22 contracts...\n",
      "   Date: 16Sep21 | Fetching 22 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[166/312] Processing Week: 16Sep25\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[166/312] Processing Week: 16Sep25\n",
      "   Date: 16Sep25 | Fetching 20 contracts...\n",
      "   Date: 16Sep25 | Fetching 20 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[167/312] Processing Week: 17Apr25\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[167/312] Processing Week: 17Apr25\n",
      "   Date: 17Apr25 | Fetching 44 contracts...\n",
      "   Date: 17Apr25 | Fetching 44 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[168/312] Processing Week: 17Aug23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[168/312] Processing Week: 17Aug23\n",
      "   Date: 17Aug23 | Fetching 16 contracts...\n",
      "   Date: 17Aug23 | Fetching 16 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[169/312] Processing Week: 17Dec20\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[169/312] Processing Week: 17Dec20\n",
      "   Date: 17Dec20 | Fetching 20 contracts...\n",
      "   Date: 17Dec20 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[170/312] Processing Week: 17Feb22    Batch Saved (1877 rows)\n",
      "\n",
      "[170/312] Processing Week: 17Feb22\n",
      "\n",
      "   Date: 17Feb22 | Fetching 34 contracts...\n",
      "   Date: 17Feb22 | Fetching 34 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[171/312] Processing Week: 17Jul25    Batch Saved (1876 rows)\n",
      "\n",
      "[171/312] Processing Week: 17Jul25\n",
      "\n",
      "   Date: 17Jul25 | Fetching 18 contracts...\n",
      "   Date: 17Jul25 | Fetching 18 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[172/312] Processing Week: 17Jun21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[172/312] Processing Week: 17Jun21\n",
      "   Date: 17Jun21 | Fetching 18 contracts...\n",
      "   Date: 17Jun21 | Fetching 18 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[173/312] Processing Week: 17Mar22\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[173/312] Processing Week: 17Mar22\n",
      "   Date: 17Mar22 | Fetching 38 contracts...\n",
      "   Date: 17Mar22 | Fetching 38 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[174/312] Processing Week: 17Nov22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[174/312] Processing Week: 17Nov22\n",
      "   Date: 17Nov22 | Fetching 14 contracts...\n",
      "   Date: 17Nov22 | Fetching 14 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[175/312] Processing Week: 17Oct24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[175/312] Processing Week: 17Oct24\n",
      "   Date: 17Oct24 | Fetching 24 contracts...\n",
      "   Date: 17Oct24 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[176/312] Processing Week: 17Sep20    Batch Saved (1881 rows)\n",
      "\n",
      "[176/312] Processing Week: 17Sep20\n",
      "\n",
      "   Date: 17Sep20 | Fetching 14 contracts...\n",
      "   Date: 17Sep20 | Fetching 14 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[177/312] Processing Week: 18Apr24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[177/312] Processing Week: 18Apr24\n",
      "   Date: 18Apr24 | Fetching 36 contracts...\n",
      "   Date: 18Apr24 | Fetching 36 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[178/312] Processing Week: 18Aug22\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[178/312] Processing Week: 18Aug22\n",
      "   Date: 18Aug22 | Fetching 20 contracts...\n",
      "   Date: 18Aug22 | Fetching 20 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[179/312] Processing Week: 18Feb21\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[179/312] Processing Week: 18Feb21\n",
      "   Date: 18Feb21 | Fetching 20 contracts...\n",
      "   Date: 18Feb21 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[180/312] Processing Week: 18Jan24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[180/312] Processing Week: 18Jan24\n",
      "   Date: 18Jan24 | Fetching 38 contracts...\n",
      "   Date: 18Jan24 | Fetching 38 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[181/312] Processing Week: 18Jul24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[181/312] Processing Week: 18Jul24\n",
      "   Date: 18Jul24 | Fetching 26 contracts...\n",
      "   Date: 18Jul24 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[182/312] Processing Week: 18Jun20\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[182/312] Processing Week: 18Jun20\n",
      "   Date: 18Jun20 | Fetching 24 contracts...\n",
      "   Date: 18Jun20 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[183/312] Processing Week: 18Mar21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[183/312] Processing Week: 18Mar21\n",
      "   Date: 18Mar21 | Fetching 40 contracts...\n",
      "   Date: 18Mar21 | Fetching 40 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[184/312] Processing Week: 18May23\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[184/312] Processing Week: 18May23\n",
      "   Date: 18May23 | Fetching 20 contracts...\n",
      "   Date: 18May23 | Fetching 20 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[185/312] Processing Week: 18Nov21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[185/312] Processing Week: 18Nov21\n",
      "   Date: 18Nov21 | Fetching 26 contracts...\n",
      "   Date: 18Nov21 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[186/312] Processing Week: 18Nov25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[186/312] Processing Week: 18Nov25\n",
      "   Date: 18Nov25 | Fetching 16 contracts...\n",
      "   Date: 18Nov25 | Fetching 16 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[187/312] Processing Week: 19Aug21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[187/312] Processing Week: 19Aug21\n",
      "   Date: 18Aug21 | Fetching 18 contracts...\n",
      "   Date: 18Aug21 | Fetching 18 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[188/312] Processing Week: 19Dec24\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[188/312] Processing Week: 19Dec24\n",
      "   Date: 19Dec24 | Fetching 42 contracts...\n",
      "   Date: 19Dec24 | Fetching 42 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[189/312] Processing Week: 19Jan23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[189/312] Processing Week: 19Jan23\n",
      "   Date: 19Jan23 | Fetching 24 contracts...\n",
      "   Date: 19Jan23 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[190/312] Processing Week: 19Jun25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[190/312] Processing Week: 19Jun25\n",
      "   Date: 19Jun25 | Fetching 22 contracts...\n",
      "   Date: 19Jun25 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[191/312] Processing Week: 19Mar20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[191/312] Processing Week: 19Mar20\n",
      "   Date: 19Mar20 | Fetching 98 contracts...\n",
      "   Date: 19Mar20 | Fetching 98 contracts...\n",
      "    Batch Saved (1824 rows)\n",
      "\n",
      "[192/312] Processing Week: 19May22\n",
      "    Batch Saved (1824 rows)\n",
      "\n",
      "[192/312] Processing Week: 19May22\n",
      "   Date: 19May22 | Fetching 32 contracts...\n",
      "   Date: 19May22 | Fetching 32 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[193/312] Processing Week: 19Nov20\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[193/312] Processing Week: 19Nov20\n",
      "   Date: 19Nov20 | Fetching 20 contracts...\n",
      "   Date: 19Nov20 | Fetching 20 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[194/312] Processing Week: 19Oct23    Batch Saved (1501 rows)\n",
      "\n",
      "[194/312] Processing Week: 19Oct23\n",
      "\n",
      "   Date: 19Oct23 | Fetching 20 contracts...\n",
      "   Date: 19Oct23 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[195/312] Processing Week: 19Sep24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[195/312] Processing Week: 19Sep24\n",
      "   Date: 19Sep24 | Fetching 18 contracts...\n",
      "   Date: 19Sep24 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[196/312] Processing Week: 20Apr23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[196/312] Processing Week: 20Apr23\n",
      "   Date: 20Apr23 | Fetching 12 contracts...\n",
      "   Date: 20Apr23 | Fetching 12 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[197/312] Processing Week: 20Aug20\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[197/312] Processing Week: 20Aug20\n",
      "   Date: 20Aug20 | Fetching 20 contracts...\n",
      "   Date: 20Aug20 | Fetching 20 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[198/312] Processing Week: 20Feb20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[198/312] Processing Week: 20Feb20\n",
      "   Date: 20Feb20 | Fetching 20 contracts...\n",
      "   Date: 20Feb20 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[199/312] Processing Week: 20Feb25\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[199/312] Processing Week: 20Feb25\n",
      "   Date: 20Feb25 | Fetching 22 contracts...\n",
      "   Date: 20Feb25 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[200/312] Processing Week: 20Jan22\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[200/312] Processing Week: 20Jan22\n",
      "   Date: 20Jan22 | Fetching 34 contracts...\n",
      "   Date: 20Jan22 | Fetching 34 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[201/312] Processing Week: 20Jul23\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[201/312] Processing Week: 20Jul23\n",
      "   Date: 20Jul23 | Fetching 28 contracts...\n",
      "   Date: 20Jul23 | Fetching 28 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[202/312] Processing Week: 20Jun24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[202/312] Processing Week: 20Jun24\n",
      "   Date: 20Jun24 | Fetching 18 contracts...\n",
      "   Date: 20Jun24 | Fetching 18 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[203/312] Processing Week: 20Mar25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[203/312] Processing Week: 20Mar25\n",
      "   Date: 20Mar25 | Fetching 36 contracts...\n",
      "   Date: 20Mar25 | Fetching 36 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[204/312] Processing Week: 20May21\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[204/312] Processing Week: 20May21\n",
      "   Date: 20May21 | Fetching 28 contracts...\n",
      "   Date: 20May21 | Fetching 28 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[205/312] Processing Week: 20Oct22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[205/312] Processing Week: 20Oct22\n",
      "   Date: 20Oct22 | Fetching 26 contracts...\n",
      "   Date: 20Oct22 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[206/312] Processing Week: 21Apr22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[206/312] Processing Week: 21Apr22\n",
      "   Date: 21Apr22 | Fetching 28 contracts...\n",
      "   Date: 21Apr22 | Fetching 28 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[207/312] Processing Week: 21Aug25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[207/312] Processing Week: 21Aug25\n",
      "   Date: 21Aug25 | Fetching 18 contracts...\n",
      "   Date: 21Aug25 | Fetching 18 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[208/312] Processing Week: 21Dec23\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[208/312] Processing Week: 21Dec23\n",
      "   Date: 21Dec23 | Fetching 30 contracts...\n",
      "   Date: 21Dec23 | Fetching 30 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[209/312] Processing Week: 21Jan21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[209/312] Processing Week: 21Jan21\n",
      "   Date: 21Jan21 | Fetching 26 contracts...\n",
      "   Date: 21Jan21 | Fetching 26 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[210/312] Processing Week: 21Jul22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[210/312] Processing Week: 21Jul22\n",
      "   Date: 21Jul22 | Fetching 32 contracts...\n",
      "   Date: 21Jul22 | Fetching 32 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[211/312] Processing Week: 21Mar24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[211/312] Processing Week: 21Mar24\n",
      "   Date: 21Mar24 | Fetching 22 contracts...\n",
      "   Date: 21Mar24 | Fetching 22 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[212/312] Processing Week: 21May20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[212/312] Processing Week: 21May20\n",
      "   Date: 21May20 | Fetching 22 contracts...\n",
      "   Date: 21May20 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[213/312] Processing Week: 21Nov24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[213/312] Processing Week: 21Nov24\n",
      "   Date: 21Nov24 | Fetching 28 contracts...\n",
      "   Date: 21Nov24 | Fetching 28 contracts...\n",
      "    Batch Saved (1129 rows)\n",
      "\n",
      "[214/312] Processing Week: 21Oct21\n",
      "    Batch Saved (1129 rows)\n",
      "\n",
      "[214/312] Processing Week: 21Oct21\n",
      "   Date: 21Oct21 | Fetching 28 contracts...\n",
      "   Date: 21Oct21 | Fetching 28 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[215/312] Processing Week: 21Oct25\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[215/312] Processing Week: 21Oct25\n",
      "   Date: 20Oct25 | Fetching 38 contracts...\n",
      "   Date: 20Oct25 | Fetching 38 contracts...\n",
      "    Batch Saved (1601 rows)\n",
      "\n",
      "[216/312] Processing Week: 21Sep23\n",
      "    Batch Saved (1601 rows)\n",
      "\n",
      "[216/312] Processing Week: 21Sep23\n",
      "   Date: 21Sep23 | Fetching 26 contracts...\n",
      "   Date: 21Sep23 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[217/312] Processing Week: 22Apr21\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[217/312] Processing Week: 22Apr21\n",
      "   Date: 22Apr21 | Fetching 28 contracts...\n",
      "   Date: 22Apr21 | Fetching 28 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[218/312] Processing Week: 22Aug24\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[218/312] Processing Week: 22Aug24\n",
      "   Date: 22Aug24 | Fetching 32 contracts...\n",
      "   Date: 22Aug24 | Fetching 32 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[219/312] Processing Week: 22Dec22\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[219/312] Processing Week: 22Dec22\n",
      "   Date: 22Dec22 | Fetching 22 contracts...\n",
      "   Date: 22Dec22 | Fetching 22 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[220/312] Processing Week: 22Feb24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[220/312] Processing Week: 22Feb24\n",
      "   Date: 22Feb24 | Fetching 20 contracts...\n",
      "   Date: 22Feb24 | Fetching 20 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[221/312] Processing Week: 22Jul21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[221/312] Processing Week: 22Jul21\n",
      "   Date: 22Jul21 | Fetching 20 contracts...\n",
      "   Date: 22Jul21 | Fetching 20 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[222/312] Processing Week: 22Jun23\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[222/312] Processing Week: 22Jun23\n",
      "   Date: 22Jun23 | Fetching 16 contracts...\n",
      "   Date: 22Jun23 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[223/312] Processing Week: 22May25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[223/312] Processing Week: 22May25\n",
      "   Date: 22May25 | Fetching 30 contracts...\n",
      "   Date: 22May25 | Fetching 30 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[224/312] Processing Week: 22Oct20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[224/312] Processing Week: 22Oct20\n",
      "   Date: 22Oct20 | Fetching 20 contracts...\n",
      "   Date: 22Oct20 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[225/312] Processing Week: 22Sep22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[225/312] Processing Week: 22Sep22\n",
      "   Date: 22Sep22 | Fetching 24 contracts...\n",
      "   Date: 22Sep22 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[226/312] Processing Week: 23Apr20\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[226/312] Processing Week: 23Apr20\n",
      "   Date: 23Apr20 | Fetching 24 contracts...\n",
      "   Date: 23Apr20 | Fetching 24 contracts...\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[227/312] Processing Week: 23Dec21\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[227/312] Processing Week: 23Dec21\n",
      "   Date: 23Dec21 | Fetching 40 contracts...\n",
      "   Date: 23Dec21 | Fetching 40 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[228/312] Processing Week: 23Feb23\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[228/312] Processing Week: 23Feb23\n",
      "   Date: 23Feb23 | Fetching 30 contracts...\n",
      "   Date: 23Feb23 | Fetching 30 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[229/312] Processing Week: 23Jan20\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[229/312] Processing Week: 23Jan20\n",
      "   Date: 23Jan20 | Fetching 18 contracts...\n",
      "   Date: 23Jan20 | Fetching 18 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[230/312] Processing Week: 23Jan25\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[230/312] Processing Week: 23Jan25\n",
      "   Date: 23Jan25 | Fetching 22 contracts...\n",
      "   Date: 23Jan25 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[231/312] Processing Week: 23Jul20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[231/312] Processing Week: 23Jul20\n",
      "   Date: 23Jul20 | Fetching 24 contracts...\n",
      "   Date: 23Jul20 | Fetching 24 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[232/312] Processing Week: 23Jun22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[232/312] Processing Week: 23Jun22\n",
      "   Date: 23Jun22 | Fetching 26 contracts...\n",
      "   Date: 23Jun22 | Fetching 26 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[233/312] Processing Week: 23Mar23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[233/312] Processing Week: 23Mar23\n",
      "   Date: 23Mar23 | Fetching 20 contracts...\n",
      "   Date: 23Mar23 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[234/312] Processing Week: 23May24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[234/312] Processing Week: 23May24\n",
      "   Date: 23May24 | Fetching 32 contracts...\n",
      "   Date: 23May24 | Fetching 32 contracts...\n",
      "    Batch Saved (1616 rows)\n",
      "\n",
      "[235/312] Processing Week: 23Nov23\n",
      "    Batch Saved (1616 rows)\n",
      "\n",
      "[235/312] Processing Week: 23Nov23\n",
      "   Date: 23Nov23 | Fetching 14 contracts...\n",
      "   Date: 23Nov23 | Fetching 14 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[236/312] Processing Week: 23Sep21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[236/312] Processing Week: 23Sep21\n",
      "   Date: 23Sep21 | Fetching 26 contracts...\n",
      "   Date: 23Sep21 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[237/312] Processing Week: 23Sep25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[237/312] Processing Week: 23Sep25\n",
      "   Date: 23Sep25 | Fetching 20 contracts...\n",
      "   Date: 23Sep25 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[238/312] Processing Week: 24Apr25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[238/312] Processing Week: 24Apr25\n",
      "   Date: 24Apr25 | Fetching 24 contracts...\n",
      "   Date: 24Apr25 | Fetching 24 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[239/312] Processing Week: 24Aug23\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[239/312] Processing Week: 24Aug23\n",
      "   Date: 24Aug23 | Fetching 20 contracts...\n",
      "   Date: 24Aug23 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[240/312] Processing Week: 24Dec20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[240/312] Processing Week: 24Dec20\n",
      "   Date: 24Dec20 | Fetching 30 contracts...\n",
      "   Date: 24Dec20 | Fetching 30 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[241/312] Processing Week: 24Feb22\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[241/312] Processing Week: 24Feb22\n",
      "   Date: 24Feb22 | Fetching 54 contracts...\n",
      "   Date: 24Feb22 | Fetching 54 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[242/312] Processing Week: 24Jul25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[242/312] Processing Week: 24Jul25\n",
      "   Date: 24Jul25 | Fetching 20 contracts...\n",
      "   Date: 24Jul25 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[243/312] Processing Week: 24Jun21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[243/312] Processing Week: 24Jun21\n",
      "   Date: 24Jun21 | Fetching 24 contracts...\n",
      "   Date: 24Jun21 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[244/312] Processing Week: 24Mar22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[244/312] Processing Week: 24Mar22\n",
      "   Date: 24Mar22 | Fetching 24 contracts...\n",
      "   Date: 24Mar22 | Fetching 24 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[245/312] Processing Week: 24Nov22\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[245/312] Processing Week: 24Nov22\n",
      "   Date: 24Nov22 | Fetching 20 contracts...\n",
      "   Date: 24Nov22 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[246/312] Processing Week: 24Oct24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[246/312] Processing Week: 24Oct24\n",
      "   Date: 24Oct24 | Fetching 30 contracts...\n",
      "   Date: 24Oct24 | Fetching 30 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[247/312] Processing Week: 24Sep20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[247/312] Processing Week: 24Sep20\n",
      "   Date: 24Sep20 | Fetching 38 contracts...\n",
      "   Date: 24Sep20 | Fetching 38 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[248/312] Processing Week: 25Apr24\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[248/312] Processing Week: 25Apr24\n",
      "   Date: 25Apr24 | Fetching 38 contracts...\n",
      "   Date: 25Apr24 | Fetching 38 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[249/312] Processing Week: 25Aug22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[249/312] Processing Week: 25Aug22\n",
      "   Date: 25Aug22 | Fetching 30 contracts...\n",
      "   Date: 25Aug22 | Fetching 30 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[250/312] Processing Week: 25Feb21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[250/312] Processing Week: 25Feb21\n",
      "   Date: 25Feb21 | Fetching 26 contracts...\n",
      "   Date: 25Feb21 | Fetching 26 contracts...\n",
      "    Batch Saved (1557 rows)\n",
      "\n",
      "[251/312] Processing Week: 25Jan24\n",
      "    Batch Saved (1557 rows)\n",
      "\n",
      "[251/312] Processing Week: 25Jan24\n",
      "   Date: 25Jan24 | Fetching 30 contracts...\n",
      "   Date: 25Jan24 | Fetching 30 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[252/312] Processing Week: 25Jul24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[252/312] Processing Week: 25Jul24\n",
      "   Date: 25Jul24 | Fetching 34 contracts...\n",
      "   Date: 25Jul24 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[253/312] Processing Week: 25Jun20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[253/312] Processing Week: 25Jun20\n",
      "   Date: 25Jun20 | Fetching 24 contracts...\n",
      "   Date: 25Jun20 | Fetching 24 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[254/312] Processing Week: 25Mar21\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[254/312] Processing Week: 25Mar21\n",
      "   Date: 25Mar21 | Fetching 32 contracts...\n",
      "   Date: 25Mar21 | Fetching 32 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[255/312] Processing Week: 25May23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[255/312] Processing Week: 25May23\n",
      "   Date: 25May23 | Fetching 20 contracts...\n",
      "   Date: 25May23 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[256/312] Processing Week: 25Nov21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[256/312] Processing Week: 25Nov21\n",
      "   Date: 25Nov21 | Fetching 26 contracts...\n",
      "   Date: 25Nov21 | Fetching 26 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[257/312] Processing Week: 25Nov25\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[257/312] Processing Week: 25Nov25\n",
      "   Date: 25Nov25 | Fetching 22 contracts...\n",
      "   Date: 25Nov25 | Fetching 22 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[258/312] Processing Week: 26Aug21\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[258/312] Processing Week: 26Aug21\n",
      "   Date: 26Aug21 | Fetching 18 contracts...\n",
      "   Date: 26Aug21 | Fetching 18 contracts...\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[259/312] Processing Week: 26Dec24\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[259/312] Processing Week: 26Dec24\n",
      "   Date: 26Dec24 | Fetching 26 contracts...\n",
      "   Date: 26Dec24 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[260/312] Processing Week: 26Jan23\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[260/312] Processing Week: 26Jan23\n",
      "   Date: 25Jan23 | Fetching 20 contracts...\n",
      "   Date: 25Jan23 | Fetching 20 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[261/312] Processing Week: 26Jun25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[261/312] Processing Week: 26Jun25\n",
      "   Date: 26Jun25 | Fetching 36 contracts...\n",
      "   Date: 26Jun25 | Fetching 36 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[262/312] Processing Week: 26Mar20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[262/312] Processing Week: 26Mar20\n",
      "   Date: 26Mar20 | Fetching 60 contracts...\n",
      "   Date: 26Mar20 | Fetching 60 contracts...\n",
      "    Batch Saved (1827 rows)\n",
      "\n",
      "[263/312] Processing Week: 26May22\n",
      "    Batch Saved (1827 rows)\n",
      "\n",
      "[263/312] Processing Week: 26May22\n",
      "   Date: 26May22 | Fetching 26 contracts...\n",
      "   Date: 26May22 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[264/312] Processing Week: 26Nov20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[264/312] Processing Week: 26Nov20\n",
      "   Date: 26Nov20 | Fetching 22 contracts...\n",
      "   Date: 26Nov20 | Fetching 22 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[265/312] Processing Week: 26Oct23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[265/312] Processing Week: 26Oct23\n",
      "   Date: 26Oct23 | Fetching 36 contracts...\n",
      "   Date: 26Oct23 | Fetching 36 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[266/312] Processing Week: 26Sep24\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[266/312] Processing Week: 26Sep24\n",
      "   Date: 26Sep24 | Fetching 38 contracts...\n",
      "   Date: 26Sep24 | Fetching 38 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[267/312] Processing Week: 27Apr23\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[267/312] Processing Week: 27Apr23\n",
      "   Date: 27Apr23 | Fetching 22 contracts...\n",
      "   Date: 27Apr23 | Fetching 22 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[268/312] Processing Week: 27Aug20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[268/312] Processing Week: 27Aug20\n",
      "   Date: 27Aug20 | Fetching 16 contracts...\n",
      "   Date: 27Aug20 | Fetching 16 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[269/312] Processing Week: 27Feb20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[269/312] Processing Week: 27Feb20\n",
      "   Date: 27Feb20 | Fetching 24 contracts...\n",
      "   Date: 27Feb20 | Fetching 24 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[270/312] Processing Week: 27Feb25\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[270/312] Processing Week: 27Feb25\n",
      "   Date: 27Feb25 | Fetching 22 contracts...\n",
      "   Date: 27Feb25 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[271/312] Processing Week: 27Jan22\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[271/312] Processing Week: 27Jan22\n",
      "   Date: 27Jan22 | Fetching 40 contracts...\n",
      "   Date: 27Jan22 | Fetching 40 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[272/312] Processing Week: 27Jul23\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[272/312] Processing Week: 27Jul23\n",
      "   Date: 27Jul23 | Fetching 18 contracts...\n",
      "   Date: 27Jul23 | Fetching 18 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[273/312] Processing Week: 27Jun24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[273/312] Processing Week: 27Jun24\n",
      "   Date: 27Jun24 | Fetching 36 contracts...\n",
      "   Date: 27Jun24 | Fetching 36 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[274/312] Processing Week: 27Mar25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[274/312] Processing Week: 27Mar25\n",
      "   Date: 27Mar25 | Fetching 34 contracts...\n",
      "   Date: 27Mar25 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[275/312] Processing Week: 27May21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[275/312] Processing Week: 27May21\n",
      "   Date: 27May21 | Fetching 20 contracts...\n",
      "   Date: 27May21 | Fetching 20 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[276/312] Processing Week: 27Oct22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[276/312] Processing Week: 27Oct22\n",
      "   Date: 27Oct22 | Fetching 18 contracts...\n",
      "   Date: 27Oct22 | Fetching 18 contracts...\n",
      "    Batch Saved (1127 rows)\n",
      "\n",
      "[277/312] Processing Week: 28Apr22\n",
      "    Batch Saved (1127 rows)\n",
      "\n",
      "[277/312] Processing Week: 28Apr22\n",
      "   Date: 28Apr22 | Fetching 22 contracts...\n",
      "   Date: 28Apr22 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[278/312] Processing Week: 28Aug25\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[278/312] Processing Week: 28Aug25\n",
      "   Date: 28Aug25 | Fetching 28 contracts...\n",
      "   Date: 28Aug25 | Fetching 28 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[279/312] Processing Week: 28Dec23\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[279/312] Processing Week: 28Dec23\n",
      "   Date: 28Dec23 | Fetching 28 contracts...\n",
      "   Date: 28Dec23 | Fetching 28 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[280/312] Processing Week: 28Jan21\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[280/312] Processing Week: 28Jan21\n",
      "   Date: 28Jan21 | Fetching 40 contracts...\n",
      "   Date: 28Jan21 | Fetching 40 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[281/312] Processing Week: 28Jul22\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[281/312] Processing Week: 28Jul22\n",
      "   Date: 28Jul22 | Fetching 26 contracts...\n",
      "   Date: 28Jul22 | Fetching 26 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[282/312] Processing Week: 28Mar24\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[282/312] Processing Week: 28Mar24\n",
      "   Date: 28Mar24 | Fetching 30 contracts...\n",
      "   Date: 28Mar24 | Fetching 30 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[283/312] Processing Week: 28May20\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[283/312] Processing Week: 28May20\n",
      "   Date: 28May20 | Fetching 28 contracts...\n",
      "   Date: 28May20 | Fetching 28 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[284/312] Processing Week: 28Nov24\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[284/312] Processing Week: 28Nov24\n",
      "   Date: 28Nov24 | Fetching 44 contracts...\n",
      "   Date: 28Nov24 | Fetching 44 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[285/312] Processing Week: 28Oct21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[285/312] Processing Week: 28Oct21\n",
      "   Date: 28Oct21 | Fetching 28 contracts...\n",
      "   Date: 28Oct21 | Fetching 28 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[286/312] Processing Week: 28Oct25\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[286/312] Processing Week: 28Oct25\n",
      "   Date: 28Oct25 | Fetching 22 contracts...\n",
      "   Date: 28Oct25 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[287/312] Processing Week: 28Sep23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[287/312] Processing Week: 28Sep23\n",
      "   Date: 28Sep23 | Fetching 18 contracts...\n",
      "   Date: 28Sep23 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[288/312] Processing Week: 29Apr21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[288/312] Processing Week: 29Apr21\n",
      "   Date: 29Apr21 | Fetching 36 contracts...\n",
      "   Date: 29Apr21 | Fetching 36 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[289/312] Processing Week: 29Aug24\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[289/312] Processing Week: 29Aug24\n",
      "   Date: 29Aug24 | Fetching 22 contracts...\n",
      "   Date: 29Aug24 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[290/312] Processing Week: 29Dec22\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[290/312] Processing Week: 29Dec22\n",
      "   Date: 29Dec22 | Fetching 22 contracts...\n",
      "   Date: 29Dec22 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[291/312] Processing Week: 29Feb24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[291/312] Processing Week: 29Feb24\n",
      "   Date: 29Feb24 | Fetching 24 contracts...\n",
      "   Date: 29Feb24 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[292/312] Processing Week: 29Jul21\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[292/312] Processing Week: 29Jul21\n",
      "   Date: 29Jul21 | Fetching 20 contracts...\n",
      "   Date: 29Jul21 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[293/312] Processing Week: 29Jun23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[293/312] Processing Week: 29Jun23\n",
      "   Date: 28Jun23 | Fetching 20 contracts...\n",
      "   Date: 28Jun23 | Fetching 20 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[294/312] Processing Week: 29May25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[294/312] Processing Week: 29May25\n",
      "   Date: 29May25 | Fetching 26 contracts...\n",
      "   Date: 29May25 | Fetching 26 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[295/312] Processing Week: 29Oct20\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[295/312] Processing Week: 29Oct20\n",
      "   Date: 29Oct20 | Fetching 20 contracts...\n",
      "   Date: 29Oct20 | Fetching 20 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[296/312] Processing Week: 29Sep22\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[296/312] Processing Week: 29Sep22\n",
      "   Date: 29Sep22 | Fetching 40 contracts...\n",
      "   Date: 29Sep22 | Fetching 40 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[297/312] Processing Week: 30Apr20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[297/312] Processing Week: 30Apr20\n",
      "   Date: 30Apr20 | Fetching 36 contracts...\n",
      "   Date: 30Apr20 | Fetching 36 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[298/312] Processing Week: 30Dec21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[298/312] Processing Week: 30Dec21\n",
      "   Date: 30Dec21 | Fetching 24 contracts...\n",
      "   Date: 30Dec21 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[299/312] Processing Week: 30Jan20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[299/312] Processing Week: 30Jan20\n",
      "   Date: 30Jan20 | Fetching 16 contracts...\n",
      "   Date: 30Jan20 | Fetching 16 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[300/312] Processing Week: 30Jan25\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[300/312] Processing Week: 30Jan25\n",
      "   Date: 30Jan25 | Fetching 28 contracts...\n",
      "   Date: 30Jan25 | Fetching 28 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[301/312] Processing Week: 30Jul20\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[301/312] Processing Week: 30Jul20\n",
      "   Date: 30Jul20 | Fetching 16 contracts...\n",
      "   Date: 30Jul20 | Fetching 16 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[302/312] Processing Week: 30Jun22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[302/312] Processing Week: 30Jun22\n",
      "   Date: 30Jun22 | Fetching 18 contracts...\n",
      "   Date: 30Jun22 | Fetching 18 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[303/312] Processing Week: 30Mar23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[303/312] Processing Week: 30Mar23\n",
      "   Date: 29Mar23 | Fetching 14 contracts...\n",
      "   Date: 29Mar23 | Fetching 14 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[304/312] Processing Week: 30May24\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[304/312] Processing Week: 30May24\n",
      "   Date: 30May24 | Fetching 34 contracts...\n",
      "   Date: 30May24 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[305/312] Processing Week: 30Nov23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[305/312] Processing Week: 30Nov23\n",
      "   Date: 30Nov23 | Fetching 22 contracts...\n",
      "   Date: 30Nov23 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[306/312] Processing Week: 30Sep21\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[306/312] Processing Week: 30Sep21\n",
      "   Date: 30Sep21 | Fetching 20 contracts...\n",
      "   Date: 30Sep21 | Fetching 20 contracts...\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[307/312] Processing Week: 30Sep25\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[307/312] Processing Week: 30Sep25\n",
      "   Date: 30Sep25 | Fetching 28 contracts...\n",
      "   Date: 30Sep25 | Fetching 28 contracts...\n",
      "    Batch Saved (1827 rows)\n",
      "\n",
      "[308/312] Processing Week: 31Aug23\n",
      "    Batch Saved (1827 rows)\n",
      "\n",
      "[308/312] Processing Week: 31Aug23\n",
      "   Date: 31Aug23 | Fetching 14 contracts...\n",
      "   Date: 31Aug23 | Fetching 14 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[309/312] Processing Week: 31Dec20\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[309/312] Processing Week: 31Dec20\n",
      "   Date: 31Dec20 | Fetching 14 contracts...\n",
      "   Date: 31Dec20 | Fetching 14 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[310/312] Processing Week: 31Jul25\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[310/312] Processing Week: 31Jul25\n",
      "   Date: 31Jul25 | Fetching 22 contracts...\n",
      "   Date: 31Jul25 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[311/312] Processing Week: 31Mar22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[311/312] Processing Week: 31Mar22\n",
      "   Date: 31Mar22 | Fetching 28 contracts...\n",
      "   Date: 31Mar22 | Fetching 28 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[312/312] Processing Week: 31Oct24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[312/312] Processing Week: 31Oct24\n",
      "   Date: 31Oct24 | Fetching 24 contracts...\n",
      "   Date: 31Oct24 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      " SUCCESS! Full History Saved to nifty_full_market_data_2020_2025.csv\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      " SUCCESS! Full History Saved to nifty_full_market_data_2020_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from growwapi import GrowwAPI\n",
    "\n",
    "# --- CREDENTIALS ---\n",
    "API_KEY = \"eyJraWQiOiJaTUtjVXciLCJhbGciOiJFUzI1NiJ9.eyJleHAiOjI1NTM1Njg0NzYsImlhdCI6MTc2NTE2ODQ3NiwibmJmIjoxNzY1MTY4NDc2LCJzdWIiOiJ7XCJ0b2tlblJlZklkXCI6XCJhMTg3NDVhMy1hN2M1LTRlOTQtODE1MS1lZjUxZDQ5OGE2Y2RcIixcInZlbmRvckludGVncmF0aW9uS2V5XCI6XCJlMzFmZjIzYjA4NmI0MDZjODg3NGIyZjZkODQ5NTMxM1wiLFwidXNlckFjY291bnRJZFwiOlwiMDdmMDA0MGMtZTk4Zi00ZDNmLTk5Y2EtZDc1ZjBlYWU5M2NlXCIsXCJkZXZpY2VJZFwiOlwiZDMyMWIxMzUtZWQ5Mi01ZWJkLWJjMDUtZTY1NDY2OWRiMDM5XCIsXCJzZXNzaW9uSWRcIjpcIjBlOWMyYWZmLTM0NzktNDUyMi1iODE4LTczNTZlMzFkYmY1Y1wiLFwiYWRkaXRpb25hbERhdGFcIjpcIno1NC9NZzltdjE2WXdmb0gvS0EwYk1yOE5XVzhzdTNvZ080am1ZUzIwZEpSTkczdTlLa2pWZDNoWjU1ZStNZERhWXBOVi9UOUxIRmtQejFFQisybTdRPT1cIixcInJvbGVcIjpcImF1dGgtdG90cFwiLFwic291cmNlSXBBZGRyZXNzXCI6XCIyNDA5OjQwOTA6MTA4ZjpkYzA1OjNkMWQ6MWZmMDo1YWFjOjYwNTYsMTcyLjcxLjE5OC4xOSwzNS4yNDEuMjMuMTIzXCIsXCJ0d29GYUV4cGlyeVRzXCI6MjU1MzU2ODQ3NjQzNn0iLCJpc3MiOiJhcGV4LWF1dGgtcHJvZC1hcHAifQ.VuAMgqoC3e32gduObByNz97jFfG-ikXoREum26XPkvyMpj9JgCedXBI81jxGTPTrZD9i1wIL0s38LPd9vc9ApA\"\n",
    "API_SECRET = \"xy0sbQ4r*!HN3&&UKc9vpwti4xx8PR)(\"\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SPOT_FILE = \"Final_nifty_spot_1minute_fixed_trimmed.csv\"  # Your verified spot file\n",
    "OUTPUT_FILE = \"nifty_full_market_data_2020_2025.csv\"      # The final result\n",
    "\n",
    "def auth():\n",
    "    try:\n",
    "        token = GrowwAPI.get_access_token(api_key=API_KEY, secret=API_SECRET)\n",
    "        return GrowwAPI(token)\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL: Auth failed. Error: {e}\")\n",
    "        exit()\n",
    "\n",
    "# --- 1. SMART EXPIRY LOGIC (Handles 2025 Rule Change) ---\n",
    "def get_target_expiry_date(date_obj):\n",
    "    # Remove timezone info for safe comparison\n",
    "    date_obj = date_obj.replace(tzinfo=None)\n",
    "    \n",
    "    # Logic: Thursday before Sep 1, 2025. Tuesday after.\n",
    "    switch_date = pd.Timestamp(\"2025-09-01\")\n",
    "    target_day = 1 if date_obj >= switch_date else 3 # 1=Tue, 3=Thu\n",
    "    \n",
    "    days_ahead = target_day - date_obj.weekday()\n",
    "    if days_ahead < 0: \n",
    "        days_ahead += 7\n",
    "        \n",
    "    return date_obj + timedelta(days=days_ahead)\n",
    "\n",
    "def main():\n",
    "    # 1. Load Data\n",
    "    print(f\"1. Loading Spot Data from {SPOT_FILE}...\")\n",
    "    try:\n",
    "        df_spot = pd.read_csv(SPOT_FILE)\n",
    "        \n",
    "        # Robust Timestamp Parsing\n",
    "        # (Handles both '2020-01-01' strings and Unix timestamps)\n",
    "        if pd.api.types.is_numeric_dtype(df_spot['timestamp']):\n",
    "            df_spot['timestamp'] = pd.to_datetime(df_spot['timestamp'], unit='s')\n",
    "        else:\n",
    "            df_spot['timestamp'] = pd.to_datetime(df_spot['timestamp'])\n",
    "            \n",
    "        # Normalize Timezone (Remove +05:30 for easier processing)\n",
    "        df_spot['timestamp'] = df_spot['timestamp'].dt.tz_localize(None)\n",
    "        \n",
    "        df_spot.sort_values('timestamp', inplace=True)\n",
    "        print(f\"   Loaded {len(df_spot)} rows.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"   Error: Spot file not found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Prepare Metadata\n",
    "    print(\"2. Calculating Expiries & Strikes...\")\n",
    "    df_spot['atm_strike'] = (df_spot['close'] / 50).round() * 50\n",
    "    df_spot['expiry_dt'] = df_spot['timestamp'].apply(get_target_expiry_date)\n",
    "    # Groww Format: 09Jan20\n",
    "    df_spot['expiry_str'] = df_spot['expiry_dt'].dt.strftime(\"%d%b%y\")\n",
    "    \n",
    "    # 3. Start Download Loop\n",
    "    groww = auth()\n",
    "    option_cache = {}\n",
    "    grouped = df_spot.groupby('expiry_str')\n",
    "    \n",
    "    print(f\"\\n--- Starting Full Download ({len(grouped)} Weeks) ---\")\n",
    "    \n",
    "    # Check if we are resuming (append mode)\n",
    "    file_exists = False\n",
    "    try:\n",
    "        pd.read_csv(OUTPUT_FILE, nrows=1)\n",
    "        file_exists = True\n",
    "        print(\"   (Appending to existing file...)\")\n",
    "    except FileNotFoundError:\n",
    "        file_exists = False\n",
    "\n",
    "    # Counters for progress\n",
    "    processed_weeks = 0\n",
    "    total_weeks = len(grouped)\n",
    "\n",
    "    for expiry_str, group in grouped:\n",
    "        processed_weeks += 1\n",
    "        print(f\"\\n[{processed_weeks}/{total_weeks}] Processing Week: {expiry_str}\")\n",
    "        \n",
    "        # A. Identify Strikes to Fetch (ATM, ITM, OTM)\n",
    "        atm_strikes = group['atm_strike'].unique().astype(int)\n",
    "        strikes_to_fetch = set()\n",
    "        for k in atm_strikes:\n",
    "            strikes_to_fetch.add(k)      # ATM\n",
    "            strikes_to_fetch.add(k - 50) # ITM Call / OTM Put\n",
    "            strikes_to_fetch.add(k + 50) # OTM Call / ITM Put\n",
    "        \n",
    "        # B. Smart Date Detection (Primary vs Backup)\n",
    "        primary_dt = group['expiry_dt'].iloc[0]\n",
    "        backup_dt = primary_dt - timedelta(days=1)\n",
    "        fmt_primary = primary_dt.strftime(\"%d%b%y\")\n",
    "        fmt_backup = backup_dt.strftime(\"%d%b%y\")\n",
    "        \n",
    "        active_fmt = fmt_primary\n",
    "        \n",
    "        # Quick Check: Does Primary Date have data?\n",
    "        # We test the first strike to avoid wasting API calls on holidays\n",
    "        test_sym = f\"NSE-NIFTY-{fmt_primary}-{list(strikes_to_fetch)[0]}-CE\"\n",
    "        try:\n",
    "            check_start = group['timestamp'].min().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            check_end = (group['timestamp'].min() + timedelta(days=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            resp = groww.get_historical_candles(\n",
    "                exchange=\"NSE\", segment=\"FNO\", groww_symbol=test_sym,\n",
    "                start_time=check_start, end_time=check_end, candle_interval=\"1minute\"\n",
    "            )\n",
    "            # If empty list or None, assume holiday -> Switch to Backup\n",
    "            if not (resp and \"candles\" in resp and len(resp[\"candles\"]) > 0):\n",
    "                active_fmt = fmt_backup\n",
    "        except:\n",
    "            active_fmt = fmt_backup\n",
    "            \n",
    "        print(f\"   Date: {active_fmt} | Fetching {len(strikes_to_fetch)*2} contracts...\")\n",
    "\n",
    "        # C. Download Contracts\n",
    "        start_dt_str = group['timestamp'].min().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        end_dt_str = group['timestamp'].max().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        for strike in strikes_to_fetch:\n",
    "            for opt_type in ['CE', 'PE']:\n",
    "                sym = f\"NSE-NIFTY-{active_fmt}-{strike}-{opt_type}\"\n",
    "                if sym in option_cache: continue\n",
    "                \n",
    "                try:\n",
    "                    resp = groww.get_historical_candles(\n",
    "                        exchange=\"NSE\", segment=\"FNO\", groww_symbol=sym,\n",
    "                        start_time=start_dt_str, end_time=end_dt_str, candle_interval=\"1minute\"\n",
    "                    )\n",
    "                    \n",
    "                    if resp and \"candles\" in resp and len(resp[\"candles\"]) > 0:\n",
    "                        df = pd.DataFrame(resp[\"candles\"])\n",
    "                        \n",
    "                        # FIX: Handle Column Variations (6 vs 7 cols)\n",
    "                        if len(df.columns) == 7:\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close', 'v', 'oi']\n",
    "                        elif len(df.columns) == 6:\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close', 'v']\n",
    "                            df['oi'] = 0 # Default if missing\n",
    "                        else:\n",
    "                            df = df.iloc[:, :5]\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close']\n",
    "                            df['oi'] = 0\n",
    "                            \n",
    "                        # FIX: Handle String vs Int Timestamps\n",
    "                        if isinstance(df['ts'].iloc[0], str):\n",
    "                            df['timestamp'] = pd.to_datetime(df['ts'])\n",
    "                        else:\n",
    "                            df['timestamp'] = pd.to_datetime(df['ts'], unit='s')\n",
    "                        \n",
    "                        # Remove timezone for clean merging\n",
    "                        df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "                        \n",
    "                        df.set_index('timestamp', inplace=True)\n",
    "                        df = df[~df.index.duplicated(keep='first')]\n",
    "                        option_cache[sym] = df\n",
    "                except Exception:\n",
    "                    pass\n",
    "        \n",
    "        # D. Stitch & Save\n",
    "        rows_collected = []\n",
    "        for index, row in group.iterrows():\n",
    "            ts = row['timestamp']\n",
    "            atm = int(row['atm_strike'])\n",
    "            \n",
    "            # Data Retrieval Helper\n",
    "            def get_data(s, t):\n",
    "                k = f\"NSE-NIFTY-{active_fmt}-{s}-{t}\"\n",
    "                if k in option_cache and ts in option_cache[k].index:\n",
    "                    d = option_cache[k].loc[ts]\n",
    "                    return d['close'], d.get('oi', 0)\n",
    "                return None, None\n",
    "\n",
    "            # Fetch all needed data points\n",
    "            atm_ce, atm_ce_oi = get_data(atm, \"CE\")\n",
    "            atm_pe, atm_pe_oi = get_data(atm, \"PE\")\n",
    "            itm_ce, itm_ce_oi = get_data(atm-50, \"CE\")\n",
    "            itm_pe, itm_pe_oi = get_data(atm+50, \"PE\")\n",
    "            \n",
    "            rows_collected.append({\n",
    "                \"timestamp\": ts,\n",
    "                \"nifty_open\": row['open'],\n",
    "                \"nifty_high\": row['high'],\n",
    "                \"nifty_low\": row['low'],\n",
    "                \"nifty_close\": row['close'],\n",
    "                # \"nifty_vol\": row.get('volume', 0), # Optional\n",
    "                \"expiry\": expiry_str,\n",
    "                \"atm_strike\": atm,\n",
    "                \"atm_ce_ltp\": atm_ce, \"atm_ce_oi\": atm_ce_oi,\n",
    "                \"atm_pe_ltp\": atm_pe, \"atm_pe_oi\": atm_pe_oi,\n",
    "                \"itm_ce_ltp\": itm_ce, \"itm_ce_oi\": itm_ce_oi,\n",
    "                \"itm_pe_ltp\": itm_pe, \"itm_pe_oi\": itm_pe_oi\n",
    "            })\n",
    "        \n",
    "        # Save Batch to Disk\n",
    "        if rows_collected:\n",
    "            final_df = pd.DataFrame(rows_collected)\n",
    "            # Write header only if file didn't exist\n",
    "            header_mode = not file_exists\n",
    "            final_df.to_csv(OUTPUT_FILE, mode='a', header=header_mode, index=False)\n",
    "            file_exists = True # Now it exists\n",
    "            print(f\"    Batch Saved ({len(final_df)} rows)\")\n",
    "        \n",
    "        # E. Clear Memory\n",
    "        option_cache.clear()\n",
    "\n",
    "    print(f\"\\n SUCCESS! Full History Saved to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7be87cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Spot Data from Final_nifty_spot_1minute_fixed_trimmed.csv...\n",
      "\n",
      "   Loaded 550600 rows.\n",
      "2. Calculating Expiries & Strikes...\n",
      "   Loaded 550600 rows.\n",
      "2. Calculating Expiries & Strikes...\n",
      "Ready to Groww!\n",
      "Ready to Groww!\n",
      "\n",
      "--- Starting Full Download (312 Weeks) ---\n",
      "\n",
      "[1/312] Processing Week: 02Jan20\n",
      "--- Starting Full Download (312 Weeks) ---\n",
      "\n",
      "[1/312] Processing Week: 02Jan20\n",
      "\n",
      "   Date: 02Jan20 | Fetching 12 contracts...\n",
      "   Date: 02Jan20 | Fetching 12 contracts...\n",
      "    Batch Saved (750 rows)\n",
      "\n",
      "[2/312] Processing Week: 09Jan20\n",
      "    Batch Saved (750 rows)\n",
      "\n",
      "[2/312] Processing Week: 09Jan20\n",
      "   Date: 09Jan20 | Fetching 18 contracts...\n",
      "   Date: 09Jan20 | Fetching 18 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[3/312] Processing Week: 16Jan20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[3/312] Processing Week: 16Jan20\n",
      "   Date: 16Jan20 | Fetching 14 contracts...\n",
      "   Date: 16Jan20 | Fetching 14 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[4/312] Processing Week: 23Jan20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[4/312] Processing Week: 23Jan20\n",
      "   Date: 23Jan20 | Fetching 18 contracts...\n",
      "   Date: 23Jan20 | Fetching 18 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[5/312] Processing Week: 30Jan20    Batch Saved (1876 rows)\n",
      "\n",
      "[5/312] Processing Week: 30Jan20\n",
      "\n",
      "   Date: 30Jan20 | Fetching 16 contracts...   Date: 30Jan20 | Fetching 16 contracts...\n",
      "\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[6/312] Processing Week: 06Feb20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[6/312] Processing Week: 06Feb20\n",
      "   Date: 06Feb20 | Fetching 28 contracts...\n",
      "   Date: 06Feb20 | Fetching 28 contracts...\n",
      "    Batch Saved (2253 rows)\n",
      "\n",
      "[7/312] Processing Week: 13Feb20    Batch Saved (2253 rows)\n",
      "\n",
      "[7/312] Processing Week: 13Feb20\n",
      "\n",
      "   Date: 13Feb20 | Fetching 16 contracts...\n",
      "   Date: 13Feb20 | Fetching 16 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[8/312] Processing Week: 20Feb20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[8/312] Processing Week: 20Feb20\n",
      "   Date: 20Feb20 | Fetching 20 contracts...\n",
      "   Date: 20Feb20 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[9/312] Processing Week: 27Feb20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[9/312] Processing Week: 27Feb20\n",
      "   Date: 27Feb20 | Fetching 24 contracts...\n",
      "   Date: 27Feb20 | Fetching 24 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[10/312] Processing Week: 05Mar20\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[10/312] Processing Week: 05Mar20\n",
      "   Date: 05Mar20 | Fetching 22 contracts...\n",
      "   Date: 05Mar20 | Fetching 22 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[11/312] Processing Week: 12Mar20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[11/312] Processing Week: 12Mar20\n",
      "   Date: 11Mar20 | Fetching 62 contracts...\n",
      "   Date: 11Mar20 | Fetching 62 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[12/312] Processing Week: 19Mar20\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[12/312] Processing Week: 19Mar20\n",
      "   Date: 19Mar20 | Fetching 98 contracts...\n",
      "   Date: 19Mar20 | Fetching 98 contracts...\n",
      "    Batch Saved (1824 rows)\n",
      "\n",
      "[13/312] Processing Week: 26Mar20\n",
      "    Batch Saved (1824 rows)\n",
      "\n",
      "[13/312] Processing Week: 26Mar20\n",
      "   Date: 26Mar20 | Fetching 60 contracts...\n",
      "   Date: 26Mar20 | Fetching 60 contracts...\n",
      "    Batch Saved (1827 rows)\n",
      "\n",
      "[14/312] Processing Week: 02Apr20\n",
      "    Batch Saved (1827 rows)\n",
      "\n",
      "[14/312] Processing Week: 02Apr20\n",
      "   Date: 01Apr20 | Fetching 40 contracts...\n",
      "   Date: 01Apr20 | Fetching 40 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[15/312] Processing Week: 09Apr20\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[15/312] Processing Week: 09Apr20\n",
      "   Date: 09Apr20 | Fetching 50 contracts...\n",
      "   Date: 09Apr20 | Fetching 50 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[16/312] Processing Week: 16Apr20\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[16/312] Processing Week: 16Apr20\n",
      "   Date: 16Apr20 | Fetching 22 contracts...\n",
      "   Date: 16Apr20 | Fetching 22 contracts...\n",
      "    Batch Saved (1126 rows)\n",
      "\n",
      "[17/312] Processing Week: 23Apr20\n",
      "    Batch Saved (1126 rows)\n",
      "\n",
      "[17/312] Processing Week: 23Apr20\n",
      "   Date: 23Apr20 | Fetching 24 contracts...\n",
      "   Date: 23Apr20 | Fetching 24 contracts...\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[18/312] Processing Week: 30Apr20\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[18/312] Processing Week: 30Apr20\n",
      "   Date: 30Apr20 | Fetching 36 contracts...\n",
      "   Date: 30Apr20 | Fetching 36 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[19/312] Processing Week: 07May20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[19/312] Processing Week: 07May20\n",
      "   Date: 07May20 | Fetching 22 contracts...\n",
      "   Date: 07May20 | Fetching 22 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[20/312] Processing Week: 14May20\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[20/312] Processing Week: 14May20\n",
      "   Date: 14May20 | Fetching 24 contracts...\n",
      "   Date: 14May20 | Fetching 24 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[21/312] Processing Week: 21May20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[21/312] Processing Week: 21May20\n",
      "   Date: 21May20 | Fetching 22 contracts...\n",
      "   Date: 21May20 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[22/312] Processing Week: 28May20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[22/312] Processing Week: 28May20\n",
      "   Date: 28May20 | Fetching 28 contracts...\n",
      "   Date: 28May20 | Fetching 28 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[23/312] Processing Week: 04Jun20\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[23/312] Processing Week: 04Jun20\n",
      "   Date: 04Jun20 | Fetching 36 contracts...\n",
      "   Date: 04Jun20 | Fetching 36 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[24/312] Processing Week: 11Jun20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[24/312] Processing Week: 11Jun20\n",
      "   Date: 11Jun20 | Fetching 24 contracts...\n",
      "   Date: 11Jun20 | Fetching 24 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[25/312] Processing Week: 18Jun20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[25/312] Processing Week: 18Jun20\n",
      "   Date: 18Jun20 | Fetching 24 contracts...\n",
      "   Date: 18Jun20 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[26/312] Processing Week: 25Jun20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[26/312] Processing Week: 25Jun20\n",
      "   Date: 25Jun20 | Fetching 24 contracts...\n",
      "   Date: 25Jun20 | Fetching 24 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[27/312] Processing Week: 02Jul20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[27/312] Processing Week: 02Jul20\n",
      "   Date: 02Jul20 | Fetching 20 contracts...\n",
      "   Date: 02Jul20 | Fetching 20 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[28/312] Processing Week: 09Jul20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[28/312] Processing Week: 09Jul20\n",
      "   Date: 09Jul20 | Fetching 18 contracts...\n",
      "   Date: 09Jul20 | Fetching 18 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[29/312] Processing Week: 16Jul20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[29/312] Processing Week: 16Jul20\n",
      "   Date: 16Jul20 | Fetching 20 contracts...\n",
      "   Date: 16Jul20 | Fetching 20 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[30/312] Processing Week: 23Jul20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[30/312] Processing Week: 23Jul20\n",
      "   Date: 23Jul20 | Fetching 24 contracts...\n",
      "   Date: 23Jul20 | Fetching 24 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[31/312] Processing Week: 30Jul20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[31/312] Processing Week: 30Jul20\n",
      "   Date: 30Jul20 | Fetching 16 contracts...\n",
      "   Date: 30Jul20 | Fetching 16 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[32/312] Processing Week: 06Aug20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[32/312] Processing Week: 06Aug20\n",
      "   Date: 06Aug20 | Fetching 20 contracts...\n",
      "   Date: 06Aug20 | Fetching 20 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[33/312] Processing Week: 13Aug20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[33/312] Processing Week: 13Aug20\n",
      "   Date: 13Aug20 | Fetching 14 contracts...\n",
      "   Date: 13Aug20 | Fetching 14 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[34/312] Processing Week: 20Aug20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[34/312] Processing Week: 20Aug20\n",
      "   Date: 20Aug20 | Fetching 20 contracts...\n",
      "   Date: 20Aug20 | Fetching 20 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[35/312] Processing Week: 27Aug20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[35/312] Processing Week: 27Aug20\n",
      "   Date: 27Aug20 | Fetching 16 contracts...\n",
      "   Date: 27Aug20 | Fetching 16 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[36/312] Processing Week: 03Sep20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[36/312] Processing Week: 03Sep20\n",
      "   Date: 03Sep20 | Fetching 24 contracts...\n",
      "   Date: 03Sep20 | Fetching 24 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[37/312] Processing Week: 10Sep20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[37/312] Processing Week: 10Sep20\n",
      "   Date: 10Sep20 | Fetching 16 contracts...\n",
      "   Date: 10Sep20 | Fetching 16 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[38/312] Processing Week: 17Sep20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[38/312] Processing Week: 17Sep20\n",
      "   Date: 17Sep20 | Fetching 14 contracts...\n",
      "   Date: 17Sep20 | Fetching 14 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[39/312] Processing Week: 24Sep20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[39/312] Processing Week: 24Sep20\n",
      "   Date: 24Sep20 | Fetching 38 contracts...\n",
      "   Date: 24Sep20 | Fetching 38 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[40/312] Processing Week: 01Oct20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[40/312] Processing Week: 01Oct20\n",
      "   Date: 01Oct20 | Fetching 30 contracts...\n",
      "   Date: 01Oct20 | Fetching 30 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[41/312] Processing Week: 08Oct20\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[41/312] Processing Week: 08Oct20\n",
      "   Date: 08Oct20 | Fetching 24 contracts...\n",
      "   Date: 08Oct20 | Fetching 24 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[42/312] Processing Week: 15Oct20\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[42/312] Processing Week: 15Oct20\n",
      "   Date: 15Oct20 | Fetching 20 contracts...\n",
      "   Date: 15Oct20 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[43/312] Processing Week: 22Oct20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[43/312] Processing Week: 22Oct20\n",
      "   Date: 22Oct20 | Fetching 20 contracts...\n",
      "   Date: 22Oct20 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[44/312] Processing Week: 29Oct20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[44/312] Processing Week: 29Oct20\n",
      "   Date: 29Oct20 | Fetching 20 contracts...\n",
      "   Date: 29Oct20 | Fetching 20 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[45/312] Processing Week: 05Nov20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[45/312] Processing Week: 05Nov20\n",
      "   Date: 05Nov20 | Fetching 30 contracts...\n",
      "   Date: 05Nov20 | Fetching 30 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[46/312] Processing Week: 12Nov20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[46/312] Processing Week: 12Nov20\n",
      "   Date: 12Nov20 | Fetching 30 contracts...\n",
      "   Date: 12Nov20 | Fetching 30 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[47/312] Processing Week: 19Nov20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[47/312] Processing Week: 19Nov20\n",
      "   Date: 19Nov20 | Fetching 20 contracts...\n",
      "   Date: 19Nov20 | Fetching 20 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[48/312] Processing Week: 26Nov20\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[48/312] Processing Week: 26Nov20\n",
      "   Date: 26Nov20 | Fetching 22 contracts...\n",
      "   Date: 26Nov20 | Fetching 22 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[49/312] Processing Week: 03Dec20\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[49/312] Processing Week: 03Dec20\n",
      "   Date: 03Dec20 | Fetching 16 contracts...\n",
      "   Date: 03Dec20 | Fetching 16 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[50/312] Processing Week: 10Dec20\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[50/312] Processing Week: 10Dec20\n",
      "   Date: 10Dec20 | Fetching 22 contracts...\n",
      "   Date: 10Dec20 | Fetching 22 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[51/312] Processing Week: 17Dec20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[51/312] Processing Week: 17Dec20\n",
      "   Date: 17Dec20 | Fetching 20 contracts...\n",
      "   Date: 17Dec20 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[52/312] Processing Week: 24Dec20\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[52/312] Processing Week: 24Dec20\n",
      "   Date: 24Dec20 | Fetching 30 contracts...\n",
      "   Date: 24Dec20 | Fetching 30 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[53/312] Processing Week: 31Dec20\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[53/312] Processing Week: 31Dec20\n",
      "   Date: 31Dec20 | Fetching 14 contracts...\n",
      "   Date: 31Dec20 | Fetching 14 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[54/312] Processing Week: 07Jan21\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[54/312] Processing Week: 07Jan21\n",
      "   Date: 07Jan21 | Fetching 18 contracts...\n",
      "   Date: 07Jan21 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[55/312] Processing Week: 14Jan21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[55/312] Processing Week: 14Jan21\n",
      "   Date: 14Jan21 | Fetching 22 contracts...\n",
      "   Date: 14Jan21 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[56/312] Processing Week: 21Jan21\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[56/312] Processing Week: 21Jan21\n",
      "   Date: 21Jan21 | Fetching 26 contracts...\n",
      "   Date: 21Jan21 | Fetching 26 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[57/312] Processing Week: 28Jan21\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[57/312] Processing Week: 28Jan21\n",
      "   Date: 28Jan21 | Fetching 40 contracts...\n",
      "   Date: 28Jan21 | Fetching 40 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[58/312] Processing Week: 04Feb21\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[58/312] Processing Week: 04Feb21\n",
      "   Date: 04Feb21 | Fetching 58 contracts...\n",
      "   Date: 04Feb21 | Fetching 58 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[59/312] Processing Week: 11Feb21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[59/312] Processing Week: 11Feb21\n",
      "   Date: 11Feb21 | Fetching 22 contracts...\n",
      "   Date: 11Feb21 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[60/312] Processing Week: 18Feb21\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[60/312] Processing Week: 18Feb21\n",
      "   Date: 18Feb21 | Fetching 20 contracts...\n",
      "   Date: 18Feb21 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[61/312] Processing Week: 25Feb21\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[61/312] Processing Week: 25Feb21\n",
      "   Date: 25Feb21 | Fetching 26 contracts...\n",
      "   Date: 25Feb21 | Fetching 26 contracts...\n",
      "    Batch Saved (1557 rows)\n",
      "\n",
      "[62/312] Processing Week: 04Mar21\n",
      "    Batch Saved (1557 rows)\n",
      "\n",
      "[62/312] Processing Week: 04Mar21\n",
      "   Date: 04Mar21 | Fetching 38 contracts...\n",
      "   Date: 04Mar21 | Fetching 38 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[63/312] Processing Week: 11Mar21\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[63/312] Processing Week: 11Mar21\n",
      "   Date: 10Mar21 | Fetching 20 contracts...\n",
      "   Date: 10Mar21 | Fetching 20 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[64/312] Processing Week: 18Mar21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[64/312] Processing Week: 18Mar21\n",
      "   Date: 18Mar21 | Fetching 40 contracts...\n",
      "   Date: 18Mar21 | Fetching 40 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[65/312] Processing Week: 25Mar21\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[65/312] Processing Week: 25Mar21\n",
      "   Date: 25Mar21 | Fetching 32 contracts...\n",
      "   Date: 25Mar21 | Fetching 32 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[66/312] Processing Week: 01Apr21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[66/312] Processing Week: 01Apr21\n",
      "   Date: 01Apr21 | Fetching 26 contracts...\n",
      "   Date: 01Apr21 | Fetching 26 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[67/312] Processing Week: 08Apr21\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[67/312] Processing Week: 08Apr21\n",
      "   Date: 08Apr21 | Fetching 28 contracts...\n",
      "   Date: 08Apr21 | Fetching 28 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[68/312] Processing Week: 15Apr21\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[68/312] Processing Week: 15Apr21\n",
      "   Date: 15Apr21 | Fetching 30 contracts...\n",
      "   Date: 15Apr21 | Fetching 30 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[69/312] Processing Week: 22Apr21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[69/312] Processing Week: 22Apr21\n",
      "   Date: 22Apr21 | Fetching 28 contracts...\n",
      "   Date: 22Apr21 | Fetching 28 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[70/312] Processing Week: 29Apr21\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[70/312] Processing Week: 29Apr21\n",
      "   Date: 29Apr21 | Fetching 36 contracts...\n",
      "   Date: 29Apr21 | Fetching 36 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[71/312] Processing Week: 06May21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[71/312] Processing Week: 06May21\n",
      "   Date: 06May21 | Fetching 22 contracts...\n",
      "   Date: 06May21 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[72/312] Processing Week: 13May21\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[72/312] Processing Week: 13May21\n",
      "   Date: 12May21 | Fetching 18 contracts...\n",
      "   Date: 12May21 | Fetching 18 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[73/312] Processing Week: 20May21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[73/312] Processing Week: 20May21\n",
      "   Date: 20May21 | Fetching 28 contracts...\n",
      "   Date: 20May21 | Fetching 28 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[74/312] Processing Week: 27May21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[74/312] Processing Week: 27May21\n",
      "   Date: 27May21 | Fetching 20 contracts...\n",
      "   Date: 27May21 | Fetching 20 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[75/312] Processing Week: 03Jun21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[75/312] Processing Week: 03Jun21\n",
      "   Date: 03Jun21 | Fetching 18 contracts...\n",
      "   Date: 03Jun21 | Fetching 18 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[76/312] Processing Week: 10Jun21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[76/312] Processing Week: 10Jun21\n",
      "   Date: 10Jun21 | Fetching 16 contracts...\n",
      "   Date: 10Jun21 | Fetching 16 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[77/312] Processing Week: 17Jun21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[77/312] Processing Week: 17Jun21\n",
      "   Date: 17Jun21 | Fetching 18 contracts...\n",
      "   Date: 17Jun21 | Fetching 18 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[78/312] Processing Week: 24Jun21\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[78/312] Processing Week: 24Jun21\n",
      "   Date: 24Jun21 | Fetching 24 contracts...\n",
      "   Date: 24Jun21 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[79/312] Processing Week: 01Jul21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[79/312] Processing Week: 01Jul21\n",
      "   Date: 01Jul21 | Fetching 16 contracts...\n",
      "   Date: 01Jul21 | Fetching 16 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[80/312] Processing Week: 08Jul21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[80/312] Processing Week: 08Jul21\n",
      "   Date: 08Jul21 | Fetching 16 contracts...\n",
      "   Date: 08Jul21 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[81/312] Processing Week: 15Jul21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[81/312] Processing Week: 15Jul21\n",
      "   Date: 15Jul21 | Fetching 18 contracts...\n",
      "   Date: 15Jul21 | Fetching 18 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[82/312] Processing Week: 22Jul21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[82/312] Processing Week: 22Jul21\n",
      "   Date: 22Jul21 | Fetching 20 contracts...\n",
      "   Date: 22Jul21 | Fetching 20 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[83/312] Processing Week: 29Jul21\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[83/312] Processing Week: 29Jul21\n",
      "   Date: 29Jul21 | Fetching 20 contracts...\n",
      "   Date: 29Jul21 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[84/312] Processing Week: 05Aug21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[84/312] Processing Week: 05Aug21\n",
      "   Date: 05Aug21 | Fetching 30 contracts...\n",
      "   Date: 05Aug21 | Fetching 30 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[85/312] Processing Week: 12Aug21\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[85/312] Processing Week: 12Aug21\n",
      "   Date: 12Aug21 | Fetching 14 contracts...\n",
      "   Date: 12Aug21 | Fetching 14 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[86/312] Processing Week: 19Aug21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[86/312] Processing Week: 19Aug21\n",
      "   Date: 18Aug21 | Fetching 18 contracts...\n",
      "   Date: 18Aug21 | Fetching 18 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[87/312] Processing Week: 26Aug21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[87/312] Processing Week: 26Aug21\n",
      "   Date: 26Aug21 | Fetching 18 contracts...\n",
      "   Date: 26Aug21 | Fetching 18 contracts...\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[88/312] Processing Week: 02Sep21\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[88/312] Processing Week: 02Sep21\n",
      "   Date: 02Sep21 | Fetching 34 contracts...\n",
      "   Date: 02Sep21 | Fetching 34 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[89/312] Processing Week: 09Sep21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[89/312] Processing Week: 09Sep21\n",
      "   Date: 09Sep21 | Fetching 16 contracts...\n",
      "   Date: 09Sep21 | Fetching 16 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[90/312] Processing Week: 16Sep21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[90/312] Processing Week: 16Sep21\n",
      "   Date: 16Sep21 | Fetching 22 contracts...\n",
      "   Date: 16Sep21 | Fetching 22 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[91/312] Processing Week: 23Sep21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[91/312] Processing Week: 23Sep21\n",
      "   Date: 23Sep21 | Fetching 26 contracts...\n",
      "   Date: 23Sep21 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[92/312] Processing Week: 30Sep21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[92/312] Processing Week: 30Sep21\n",
      "   Date: 30Sep21 | Fetching 20 contracts...\n",
      "   Date: 30Sep21 | Fetching 20 contracts...\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[93/312] Processing Week: 07Oct21\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[93/312] Processing Week: 07Oct21\n",
      "   Date: 07Oct21 | Fetching 24 contracts...\n",
      "   Date: 07Oct21 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[94/312] Processing Week: 14Oct21\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[94/312] Processing Week: 14Oct21\n",
      "   Date: 14Oct21 | Fetching 26 contracts...\n",
      "   Date: 14Oct21 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[95/312] Processing Week: 21Oct21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[95/312] Processing Week: 21Oct21\n",
      "   Date: 21Oct21 | Fetching 28 contracts...\n",
      "   Date: 21Oct21 | Fetching 28 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[96/312] Processing Week: 28Oct21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[96/312] Processing Week: 28Oct21\n",
      "   Date: 28Oct21 | Fetching 28 contracts...\n",
      "   Date: 28Oct21 | Fetching 28 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[97/312] Processing Week: 04Nov21\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[97/312] Processing Week: 04Nov21\n",
      "   Date: 03Nov21 | Fetching 22 contracts...\n",
      "   Date: 03Nov21 | Fetching 22 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[98/312] Processing Week: 11Nov21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[98/312] Processing Week: 11Nov21\n",
      "   Date: 11Nov21 | Fetching 18 contracts...\n",
      "   Date: 11Nov21 | Fetching 18 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[99/312] Processing Week: 18Nov21\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[99/312] Processing Week: 18Nov21\n",
      "   Date: 18Nov21 | Fetching 26 contracts...\n",
      "   Date: 18Nov21 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[100/312] Processing Week: 25Nov21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[100/312] Processing Week: 25Nov21\n",
      "   Date: 25Nov21 | Fetching 26 contracts...\n",
      "   Date: 25Nov21 | Fetching 26 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[101/312] Processing Week: 02Dec21\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[101/312] Processing Week: 02Dec21\n",
      "   Date: 02Dec21 | Fetching 30 contracts...\n",
      "   Date: 02Dec21 | Fetching 30 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[102/312] Processing Week: 09Dec21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[102/312] Processing Week: 09Dec21\n",
      "   Date: 09Dec21 | Fetching 32 contracts...\n",
      "   Date: 09Dec21 | Fetching 32 contracts...\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[103/312] Processing Week: 16Dec21\n",
      "    Batch Saved (1875 rows)\n",
      "\n",
      "[103/312] Processing Week: 16Dec21\n",
      "   Date: 16Dec21 | Fetching 24 contracts...\n",
      "   Date: 16Dec21 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[104/312] Processing Week: 23Dec21\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[104/312] Processing Week: 23Dec21\n",
      "   Date: 23Dec21 | Fetching 40 contracts...\n",
      "   Date: 23Dec21 | Fetching 40 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[105/312] Processing Week: 30Dec21\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[105/312] Processing Week: 30Dec21\n",
      "   Date: 30Dec21 | Fetching 24 contracts...\n",
      "   Date: 30Dec21 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[106/312] Processing Week: 06Jan22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[106/312] Processing Week: 06Jan22\n",
      "   Date: 06Jan22 | Fetching 32 contracts...\n",
      "   Date: 06Jan22 | Fetching 32 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[107/312] Processing Week: 13Jan22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[107/312] Processing Week: 13Jan22\n",
      "   Date: 13Jan22 | Fetching 28 contracts...\n",
      "   Date: 13Jan22 | Fetching 28 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[108/312] Processing Week: 20Jan22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[108/312] Processing Week: 20Jan22\n",
      "   Date: 20Jan22 | Fetching 34 contracts...\n",
      "   Date: 20Jan22 | Fetching 34 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[109/312] Processing Week: 27Jan22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[109/312] Processing Week: 27Jan22\n",
      "   Date: 27Jan22 | Fetching 40 contracts...\n",
      "   Date: 27Jan22 | Fetching 40 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[110/312] Processing Week: 03Feb22\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[110/312] Processing Week: 03Feb22\n",
      "   Date: 03Feb22 | Fetching 34 contracts...\n",
      "   Date: 03Feb22 | Fetching 34 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[111/312] Processing Week: 10Feb22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[111/312] Processing Week: 10Feb22\n",
      "   Date: 10Feb22 | Fetching 30 contracts...\n",
      "   Date: 10Feb22 | Fetching 30 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[112/312] Processing Week: 17Feb22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[112/312] Processing Week: 17Feb22\n",
      "   Date: 17Feb22 | Fetching 34 contracts...\n",
      "   Date: 17Feb22 | Fetching 34 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[113/312] Processing Week: 24Feb22\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[113/312] Processing Week: 24Feb22\n",
      "   Date: 24Feb22 | Fetching 54 contracts...\n",
      "   Date: 24Feb22 | Fetching 54 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[114/312] Processing Week: 03Mar22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[114/312] Processing Week: 03Mar22\n",
      "   Date: 03Mar22 | Fetching 24 contracts...\n",
      "   Date: 03Mar22 | Fetching 24 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[115/312] Processing Week: 10Mar22\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[115/312] Processing Week: 10Mar22\n",
      "   Date: 10Mar22 | Fetching 50 contracts...\n",
      "   Date: 10Mar22 | Fetching 50 contracts...\n",
      "    Batch Saved (1837 rows)\n",
      "\n",
      "[116/312] Processing Week: 17Mar22\n",
      "    Batch Saved (1837 rows)\n",
      "\n",
      "[116/312] Processing Week: 17Mar22\n",
      "   Date: 17Mar22 | Fetching 38 contracts...\n",
      "   Date: 17Mar22 | Fetching 38 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[117/312] Processing Week: 24Mar22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[117/312] Processing Week: 24Mar22\n",
      "   Date: 24Mar22 | Fetching 24 contracts...\n",
      "   Date: 24Mar22 | Fetching 24 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[118/312] Processing Week: 31Mar22\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[118/312] Processing Week: 31Mar22\n",
      "   Date: 31Mar22 | Fetching 28 contracts...\n",
      "   Date: 31Mar22 | Fetching 28 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[119/312] Processing Week: 07Apr22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[119/312] Processing Week: 07Apr22\n",
      "   Date: 07Apr22 | Fetching 32 contracts...\n",
      "   Date: 07Apr22 | Fetching 32 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[120/312] Processing Week: 14Apr22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[120/312] Processing Week: 14Apr22\n",
      "   Date: 13Apr22 | Fetching 22 contracts...\n",
      "   Date: 13Apr22 | Fetching 22 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[121/312] Processing Week: 21Apr22\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[121/312] Processing Week: 21Apr22\n",
      "   Date: 21Apr22 | Fetching 28 contracts...\n",
      "   Date: 21Apr22 | Fetching 28 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[122/312] Processing Week: 28Apr22\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[122/312] Processing Week: 28Apr22\n",
      "   Date: 28Apr22 | Fetching 22 contracts...\n",
      "   Date: 28Apr22 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[123/312] Processing Week: 05May22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[123/312] Processing Week: 05May22\n",
      "   Date: 05May22 | Fetching 34 contracts...\n",
      "   Date: 05May22 | Fetching 34 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[124/312] Processing Week: 12May22\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[124/312] Processing Week: 12May22\n",
      "   Date: 12May22 | Fetching 36 contracts...\n",
      "   Date: 12May22 | Fetching 36 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[125/312] Processing Week: 19May22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[125/312] Processing Week: 19May22\n",
      "   Date: 19May22 | Fetching 32 contracts...\n",
      "   Date: 19May22 | Fetching 32 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[126/312] Processing Week: 26May22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[126/312] Processing Week: 26May22\n",
      "   Date: 26May22 | Fetching 26 contracts...\n",
      "   Date: 26May22 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[127/312] Processing Week: 02Jun22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[127/312] Processing Week: 02Jun22\n",
      "   Date: 02Jun22 | Fetching 26 contracts...\n",
      "   Date: 02Jun22 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[128/312] Processing Week: 09Jun22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[128/312] Processing Week: 09Jun22\n",
      "   Date: 09Jun22 | Fetching 28 contracts...\n",
      "   Date: 09Jun22 | Fetching 28 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[129/312] Processing Week: 16Jun22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[129/312] Processing Week: 16Jun22\n",
      "   Date: 16Jun22 | Fetching 38 contracts...\n",
      "   Date: 16Jun22 | Fetching 38 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[130/312] Processing Week: 23Jun22\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[130/312] Processing Week: 23Jun22\n",
      "   Date: 23Jun22 | Fetching 26 contracts...\n",
      "   Date: 23Jun22 | Fetching 26 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[131/312] Processing Week: 30Jun22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[131/312] Processing Week: 30Jun22\n",
      "   Date: 30Jun22 | Fetching 18 contracts...\n",
      "   Date: 30Jun22 | Fetching 18 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[132/312] Processing Week: 07Jul22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[132/312] Processing Week: 07Jul22\n",
      "   Date: 07Jul22 | Fetching 32 contracts...\n",
      "   Date: 07Jul22 | Fetching 32 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[133/312] Processing Week: 14Jul22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[133/312] Processing Week: 14Jul22\n",
      "   Date: 14Jul22 | Fetching 22 contracts...\n",
      "   Date: 14Jul22 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[134/312] Processing Week: 21Jul22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[134/312] Processing Week: 21Jul22\n",
      "   Date: 21Jul22 | Fetching 32 contracts...\n",
      "   Date: 21Jul22 | Fetching 32 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[135/312] Processing Week: 28Jul22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[135/312] Processing Week: 28Jul22\n",
      "   Date: 28Jul22 | Fetching 26 contracts...\n",
      "   Date: 28Jul22 | Fetching 26 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[136/312] Processing Week: 04Aug22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[136/312] Processing Week: 04Aug22\n",
      "   Date: 04Aug22 | Fetching 26 contracts...\n",
      "   Date: 04Aug22 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[137/312] Processing Week: 11Aug22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[137/312] Processing Week: 11Aug22\n",
      "   Date: 11Aug22 | Fetching 20 contracts...\n",
      "   Date: 11Aug22 | Fetching 20 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[138/312] Processing Week: 18Aug22\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[138/312] Processing Week: 18Aug22\n",
      "   Date: 18Aug22 | Fetching 20 contracts...\n",
      "   Date: 18Aug22 | Fetching 20 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[139/312] Processing Week: 25Aug22\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[139/312] Processing Week: 25Aug22\n",
      "   Date: 25Aug22 | Fetching 30 contracts...\n",
      "   Date: 25Aug22 | Fetching 30 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[140/312] Processing Week: 01Sep22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[140/312] Processing Week: 01Sep22\n",
      "   Date: 01Sep22 | Fetching 32 contracts...\n",
      "   Date: 01Sep22 | Fetching 32 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[141/312] Processing Week: 08Sep22\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[141/312] Processing Week: 08Sep22\n",
      "   Date: 08Sep22 | Fetching 18 contracts...\n",
      "   Date: 08Sep22 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[142/312] Processing Week: 15Sep22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[142/312] Processing Week: 15Sep22\n",
      "   Date: 15Sep22 | Fetching 18 contracts...\n",
      "   Date: 15Sep22 | Fetching 18 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[143/312] Processing Week: 22Sep22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[143/312] Processing Week: 22Sep22\n",
      "   Date: 22Sep22 | Fetching 24 contracts...\n",
      "   Date: 22Sep22 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[144/312] Processing Week: 29Sep22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[144/312] Processing Week: 29Sep22\n",
      "   Date: 29Sep22 | Fetching 40 contracts...\n",
      "   Date: 29Sep22 | Fetching 40 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[145/312] Processing Week: 06Oct22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[145/312] Processing Week: 06Oct22\n",
      "   Date: 06Oct22 | Fetching 32 contracts...\n",
      "   Date: 06Oct22 | Fetching 32 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[146/312] Processing Week: 13Oct22\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[146/312] Processing Week: 13Oct22\n",
      "   Date: 13Oct22 | Fetching 22 contracts...\n",
      "   Date: 13Oct22 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[147/312] Processing Week: 20Oct22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[147/312] Processing Week: 20Oct22\n",
      "   Date: 20Oct22 | Fetching 26 contracts...\n",
      "   Date: 20Oct22 | Fetching 26 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[148/312] Processing Week: 27Oct22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[148/312] Processing Week: 27Oct22\n",
      "   Date: 27Oct22 | Fetching 18 contracts...\n",
      "   Date: 27Oct22 | Fetching 18 contracts...\n",
      "    Batch Saved (1127 rows)\n",
      "\n",
      "[149/312] Processing Week: 03Nov22\n",
      "    Batch Saved (1127 rows)\n",
      "\n",
      "[149/312] Processing Week: 03Nov22\n",
      "   Date: 03Nov22 | Fetching 22 contracts...\n",
      "   Date: 03Nov22 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[150/312] Processing Week: 10Nov22\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[150/312] Processing Week: 10Nov22\n",
      "   Date: 10Nov22 | Fetching 18 contracts...\n",
      "   Date: 10Nov22 | Fetching 18 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[151/312] Processing Week: 17Nov22\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[151/312] Processing Week: 17Nov22\n",
      "   Date: 17Nov22 | Fetching 14 contracts...\n",
      "   Date: 17Nov22 | Fetching 14 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[152/312] Processing Week: 24Nov22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[152/312] Processing Week: 24Nov22\n",
      "   Date: 24Nov22 | Fetching 20 contracts...\n",
      "   Date: 24Nov22 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[153/312] Processing Week: 01Dec22\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[153/312] Processing Week: 01Dec22\n",
      "   Date: 01Dec22 | Fetching 24 contracts...\n",
      "   Date: 01Dec22 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[154/312] Processing Week: 08Dec22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[154/312] Processing Week: 08Dec22\n",
      "   Date: 08Dec22 | Fetching 14 contracts...\n",
      "   Date: 08Dec22 | Fetching 14 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[155/312] Processing Week: 15Dec22\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[155/312] Processing Week: 15Dec22\n",
      "   Date: 15Dec22 | Fetching 20 contracts...\n",
      "   Date: 15Dec22 | Fetching 20 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[156/312] Processing Week: 22Dec22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[156/312] Processing Week: 22Dec22\n",
      "   Date: 22Dec22 | Fetching 22 contracts...\n",
      "   Date: 22Dec22 | Fetching 22 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[157/312] Processing Week: 29Dec22\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[157/312] Processing Week: 29Dec22\n",
      "   Date: 29Dec22 | Fetching 22 contracts...\n",
      "   Date: 29Dec22 | Fetching 22 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[158/312] Processing Week: 05Jan23\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[158/312] Processing Week: 05Jan23\n",
      "   Date: 05Jan23 | Fetching 20 contracts...\n",
      "   Date: 05Jan23 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[159/312] Processing Week: 12Jan23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[159/312] Processing Week: 12Jan23\n",
      "   Date: 12Jan23 | Fetching 22 contracts...\n",
      "   Date: 12Jan23 | Fetching 22 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[160/312] Processing Week: 19Jan23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[160/312] Processing Week: 19Jan23\n",
      "   Date: 19Jan23 | Fetching 24 contracts...\n",
      "   Date: 19Jan23 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[161/312] Processing Week: 26Jan23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[161/312] Processing Week: 26Jan23\n",
      "   Date: 25Jan23 | Fetching 20 contracts...\n",
      "   Date: 25Jan23 | Fetching 20 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[162/312] Processing Week: 02Feb23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[162/312] Processing Week: 02Feb23\n",
      "   Date: 02Feb23 | Fetching 30 contracts...\n",
      "   Date: 02Feb23 | Fetching 30 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[163/312] Processing Week: 09Feb23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[163/312] Processing Week: 09Feb23\n",
      "   Date: 09Feb23 | Fetching 18 contracts...\n",
      "   Date: 09Feb23 | Fetching 18 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[164/312] Processing Week: 16Feb23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[164/312] Processing Week: 16Feb23\n",
      "   Date: 16Feb23 | Fetching 24 contracts...\n",
      "   Date: 16Feb23 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[165/312] Processing Week: 23Feb23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[165/312] Processing Week: 23Feb23\n",
      "   Date: 23Feb23 | Fetching 30 contracts...\n",
      "   Date: 23Feb23 | Fetching 30 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[166/312] Processing Week: 02Mar23\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[166/312] Processing Week: 02Mar23\n",
      "   Date: 02Mar23 | Fetching 20 contracts...\n",
      "   Date: 02Mar23 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[167/312] Processing Week: 09Mar23\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[167/312] Processing Week: 09Mar23\n",
      "   Date: 09Mar23 | Fetching 20 contracts...\n",
      "   Date: 09Mar23 | Fetching 20 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[168/312] Processing Week: 16Mar23\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[168/312] Processing Week: 16Mar23\n",
      "   Date: 16Mar23 | Fetching 34 contracts...\n",
      "   Date: 16Mar23 | Fetching 34 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[169/312] Processing Week: 23Mar23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[169/312] Processing Week: 23Mar23\n",
      "   Date: 23Mar23 | Fetching 20 contracts...\n",
      "   Date: 23Mar23 | Fetching 20 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[170/312] Processing Week: 30Mar23\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[170/312] Processing Week: 30Mar23\n",
      "   Date: 29Mar23 | Fetching 14 contracts...\n",
      "   Date: 29Mar23 | Fetching 14 contracts...\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[171/312] Processing Week: 06Apr23\n",
      "    Batch Saved (1500 rows)\n",
      "\n",
      "[171/312] Processing Week: 06Apr23\n",
      "   Date: 06Apr23 | Fetching 22 contracts...\n",
      "   Date: 06Apr23 | Fetching 22 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[172/312] Processing Week: 13Apr23\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[172/312] Processing Week: 13Apr23\n",
      "   Date: 13Apr23 | Fetching 16 contracts...\n",
      "   Date: 13Apr23 | Fetching 16 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[173/312] Processing Week: 20Apr23\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[173/312] Processing Week: 20Apr23\n",
      "   Date: 20Apr23 | Fetching 12 contracts...\n",
      "   Date: 20Apr23 | Fetching 12 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[174/312] Processing Week: 27Apr23\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[174/312] Processing Week: 27Apr23\n",
      "   Date: 27Apr23 | Fetching 22 contracts...\n",
      "   Date: 27Apr23 | Fetching 22 contracts...\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[175/312] Processing Week: 04May23\n",
      "    Batch Saved (1876 rows)\n",
      "\n",
      "[175/312] Processing Week: 04May23\n",
      "   Date: 04May23 | Fetching 20 contracts...\n",
      "   Date: 04May23 | Fetching 20 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[176/312] Processing Week: 11May23\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[176/312] Processing Week: 11May23\n",
      "   Date: 11May23 | Fetching 18 contracts...\n",
      "   Date: 11May23 | Fetching 18 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[177/312] Processing Week: 18May23\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[177/312] Processing Week: 18May23\n",
      "   Date: 18May23 | Fetching 20 contracts...\n",
      "   Date: 18May23 | Fetching 20 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[178/312] Processing Week: 25May23\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[178/312] Processing Week: 25May23\n",
      "   Date: 25May23 | Fetching 20 contracts...\n",
      "   Date: 25May23 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[179/312] Processing Week: 01Jun23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[179/312] Processing Week: 01Jun23\n",
      "   Date: 01Jun23 | Fetching 18 contracts...\n",
      "   Date: 01Jun23 | Fetching 18 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[180/312] Processing Week: 08Jun23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[180/312] Processing Week: 08Jun23\n",
      "   Date: 08Jun23 | Fetching 18 contracts...\n",
      "   Date: 08Jun23 | Fetching 18 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[181/312] Processing Week: 15Jun23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[181/312] Processing Week: 15Jun23\n",
      "   Date: 15Jun23 | Fetching 16 contracts...\n",
      "   Date: 15Jun23 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[182/312] Processing Week: 22Jun23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[182/312] Processing Week: 22Jun23\n",
      "   Date: 22Jun23 | Fetching 16 contracts...\n",
      "   Date: 22Jun23 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[183/312] Processing Week: 29Jun23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[183/312] Processing Week: 29Jun23\n",
      "   Date: 28Jun23 | Fetching 20 contracts...\n",
      "   Date: 28Jun23 | Fetching 20 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[184/312] Processing Week: 06Jul23\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[184/312] Processing Week: 06Jul23\n",
      "   Date: 06Jul23 | Fetching 24 contracts...\n",
      "   Date: 06Jul23 | Fetching 24 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[185/312] Processing Week: 13Jul23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[185/312] Processing Week: 13Jul23\n",
      "   Date: 13Jul23 | Fetching 16 contracts...\n",
      "   Date: 13Jul23 | Fetching 16 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[186/312] Processing Week: 20Jul23\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[186/312] Processing Week: 20Jul23\n",
      "   Date: 20Jul23 | Fetching 28 contracts...\n",
      "   Date: 20Jul23 | Fetching 28 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[187/312] Processing Week: 27Jul23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[187/312] Processing Week: 27Jul23\n",
      "   Date: 27Jul23 | Fetching 18 contracts...\n",
      "   Date: 27Jul23 | Fetching 18 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[188/312] Processing Week: 03Aug23\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[188/312] Processing Week: 03Aug23\n",
      "   Date: 03Aug23 | Fetching 26 contracts...\n",
      "   Date: 03Aug23 | Fetching 26 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[189/312] Processing Week: 10Aug23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[189/312] Processing Week: 10Aug23\n",
      "   Date: 10Aug23 | Fetching 14 contracts...\n",
      "   Date: 10Aug23 | Fetching 14 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[190/312] Processing Week: 17Aug23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[190/312] Processing Week: 17Aug23\n",
      "   Date: 17Aug23 | Fetching 16 contracts...\n",
      "   Date: 17Aug23 | Fetching 16 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[191/312] Processing Week: 24Aug23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[191/312] Processing Week: 24Aug23\n",
      "   Date: 24Aug23 | Fetching 20 contracts...\n",
      "   Date: 24Aug23 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[192/312] Processing Week: 31Aug23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[192/312] Processing Week: 31Aug23\n",
      "   Date: 31Aug23 | Fetching 14 contracts...\n",
      "   Date: 31Aug23 | Fetching 14 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[193/312] Processing Week: 07Sep23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[193/312] Processing Week: 07Sep23\n",
      "   Date: 07Sep23 | Fetching 26 contracts...\n",
      "   Date: 07Sep23 | Fetching 26 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[194/312] Processing Week: 14Sep23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[194/312] Processing Week: 14Sep23\n",
      "   Date: 14Sep23 | Fetching 22 contracts...\n",
      "   Date: 14Sep23 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[195/312] Processing Week: 21Sep23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[195/312] Processing Week: 21Sep23\n",
      "   Date: 21Sep23 | Fetching 26 contracts...\n",
      "   Date: 21Sep23 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[196/312] Processing Week: 28Sep23\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[196/312] Processing Week: 28Sep23\n",
      "   Date: 28Sep23 | Fetching 18 contracts...\n",
      "   Date: 28Sep23 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[197/312] Processing Week: 05Oct23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[197/312] Processing Week: 05Oct23\n",
      "   Date: 05Oct23 | Fetching 20 contracts...\n",
      "   Date: 05Oct23 | Fetching 20 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[198/312] Processing Week: 12Oct23\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[198/312] Processing Week: 12Oct23\n",
      "   Date: 12Oct23 | Fetching 20 contracts...\n",
      "   Date: 12Oct23 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[199/312] Processing Week: 19Oct23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[199/312] Processing Week: 19Oct23\n",
      "   Date: 19Oct23 | Fetching 20 contracts...\n",
      "   Date: 19Oct23 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[200/312] Processing Week: 26Oct23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[200/312] Processing Week: 26Oct23\n",
      "   Date: 26Oct23 | Fetching 36 contracts...\n",
      "   Date: 26Oct23 | Fetching 36 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[201/312] Processing Week: 02Nov23\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[201/312] Processing Week: 02Nov23\n",
      "   Date: 02Nov23 | Fetching 16 contracts...\n",
      "   Date: 02Nov23 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[202/312] Processing Week: 09Nov23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[202/312] Processing Week: 09Nov23\n",
      "   Date: 09Nov23 | Fetching 16 contracts...\n",
      "   Date: 09Nov23 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[203/312] Processing Week: 16Nov23\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[203/312] Processing Week: 16Nov23\n",
      "   Date: 16Nov23 | Fetching 26 contracts...\n",
      "   Date: 16Nov23 | Fetching 26 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[204/312] Processing Week: 23Nov23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[204/312] Processing Week: 23Nov23\n",
      "   Date: 23Nov23 | Fetching 14 contracts...\n",
      "   Date: 23Nov23 | Fetching 14 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[205/312] Processing Week: 30Nov23\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[205/312] Processing Week: 30Nov23\n",
      "   Date: 30Nov23 | Fetching 22 contracts...\n",
      "   Date: 30Nov23 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[206/312] Processing Week: 07Dec23\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[206/312] Processing Week: 07Dec23\n",
      "   Date: 07Dec23 | Fetching 34 contracts...\n",
      "   Date: 07Dec23 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[207/312] Processing Week: 14Dec23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[207/312] Processing Week: 14Dec23\n",
      "   Date: 14Dec23 | Fetching 24 contracts...\n",
      "   Date: 14Dec23 | Fetching 24 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[208/312] Processing Week: 21Dec23\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[208/312] Processing Week: 21Dec23\n",
      "   Date: 21Dec23 | Fetching 30 contracts...\n",
      "   Date: 21Dec23 | Fetching 30 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[209/312] Processing Week: 28Dec23\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[209/312] Processing Week: 28Dec23\n",
      "   Date: 28Dec23 | Fetching 28 contracts...\n",
      "   Date: 28Dec23 | Fetching 28 contracts...\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[210/312] Processing Week: 04Jan24\n",
      "    Batch Saved (1501 rows)\n",
      "\n",
      "[210/312] Processing Week: 04Jan24\n",
      "   Date: 04Jan24 | Fetching 20 contracts...\n",
      "   Date: 04Jan24 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[211/312] Processing Week: 11Jan24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[211/312] Processing Week: 11Jan24\n",
      "   Date: 11Jan24 | Fetching 16 contracts...\n",
      "   Date: 11Jan24 | Fetching 16 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[212/312] Processing Week: 18Jan24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[212/312] Processing Week: 18Jan24\n",
      "   Date: 18Jan24 | Fetching 38 contracts...\n",
      "   Date: 18Jan24 | Fetching 38 contracts...\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[213/312] Processing Week: 25Jan24\n",
      "    Batch Saved (1877 rows)\n",
      "\n",
      "[213/312] Processing Week: 25Jan24\n",
      "   Date: 25Jan24 | Fetching 30 contracts...\n",
      "   Date: 25Jan24 | Fetching 30 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[214/312] Processing Week: 01Feb24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[214/312] Processing Week: 01Feb24\n",
      "   Date: 01Feb24 | Fetching 22 contracts...\n",
      "   Date: 01Feb24 | Fetching 22 contracts...\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[215/312] Processing Week: 08Feb24\n",
      "    Batch Saved (1502 rows)\n",
      "\n",
      "[215/312] Processing Week: 08Feb24\n",
      "   Date: 08Feb24 | Fetching 24 contracts...\n",
      "   Date: 08Feb24 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[216/312] Processing Week: 15Feb24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[216/312] Processing Week: 15Feb24\n",
      "   Date: 15Feb24 | Fetching 22 contracts...\n",
      "   Date: 15Feb24 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[217/312] Processing Week: 22Feb24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[217/312] Processing Week: 22Feb24\n",
      "   Date: 22Feb24 | Fetching 20 contracts...\n",
      "   Date: 22Feb24 | Fetching 20 contracts...\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[218/312] Processing Week: 29Feb24\n",
      "    Batch Saved (1879 rows)\n",
      "\n",
      "[218/312] Processing Week: 29Feb24\n",
      "   Date: 29Feb24 | Fetching 24 contracts...\n",
      "   Date: 29Feb24 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[219/312] Processing Week: 07Mar24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[219/312] Processing Week: 07Mar24\n",
      "   Date: 07Mar24 | Fetching 22 contracts...\n",
      "   Date: 07Mar24 | Fetching 22 contracts...\n",
      "    Batch Saved (1988 rows)\n",
      "\n",
      "[220/312] Processing Week: 14Mar24\n",
      "    Batch Saved (1988 rows)\n",
      "\n",
      "[220/312] Processing Week: 14Mar24\n",
      "   Date: 14Mar24 | Fetching 30 contracts...\n",
      "   Date: 14Mar24 | Fetching 30 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[221/312] Processing Week: 21Mar24\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[221/312] Processing Week: 21Mar24\n",
      "   Date: 21Mar24 | Fetching 22 contracts...\n",
      "   Date: 21Mar24 | Fetching 22 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[222/312] Processing Week: 28Mar24\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[222/312] Processing Week: 28Mar24\n",
      "   Date: 28Mar24 | Fetching 30 contracts...\n",
      "   Date: 28Mar24 | Fetching 30 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[223/312] Processing Week: 04Apr24\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[223/312] Processing Week: 04Apr24\n",
      "   Date: 04Apr24 | Fetching 18 contracts...\n",
      "   Date: 04Apr24 | Fetching 18 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[224/312] Processing Week: 11Apr24\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[224/312] Processing Week: 11Apr24\n",
      "   Date: 10Apr24 | Fetching 18 contracts...\n",
      "   Date: 10Apr24 | Fetching 18 contracts...\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[225/312] Processing Week: 18Apr24\n",
      "    Batch Saved (1503 rows)\n",
      "\n",
      "[225/312] Processing Week: 18Apr24\n",
      "   Date: 18Apr24 | Fetching 36 contracts...\n",
      "   Date: 18Apr24 | Fetching 36 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[226/312] Processing Week: 25Apr24\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[226/312] Processing Week: 25Apr24\n",
      "   Date: 25Apr24 | Fetching 38 contracts...\n",
      "   Date: 25Apr24 | Fetching 38 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[227/312] Processing Week: 02May24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[227/312] Processing Week: 02May24\n",
      "   Date: 02May24 | Fetching 22 contracts...\n",
      "   Date: 02May24 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[228/312] Processing Week: 09May24\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[228/312] Processing Week: 09May24\n",
      "   Date: 09May24 | Fetching 40 contracts...\n",
      "   Date: 09May24 | Fetching 40 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[229/312] Processing Week: 16May24\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[229/312] Processing Week: 16May24\n",
      "   Date: 16May24 | Fetching 32 contracts...\n",
      "   Date: 16May24 | Fetching 32 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[230/312] Processing Week: 23May24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[230/312] Processing Week: 23May24\n",
      "   Date: 23May24 | Fetching 32 contracts...\n",
      "   Date: 23May24 | Fetching 32 contracts...\n",
      "    Batch Saved (1616 rows)\n",
      "\n",
      "[231/312] Processing Week: 30May24\n",
      "    Batch Saved (1616 rows)\n",
      "\n",
      "[231/312] Processing Week: 30May24\n",
      "   Date: 30May24 | Fetching 34 contracts...\n",
      "   Date: 30May24 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[232/312] Processing Week: 06Jun24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[232/312] Processing Week: 06Jun24\n",
      "   Date: 06Jun24 | Fetching 86 contracts...\n",
      "   Date: 06Jun24 | Fetching 86 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[233/312] Processing Week: 13Jun24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[233/312] Processing Week: 13Jun24\n",
      "   Date: 13Jun24 | Fetching 32 contracts...\n",
      "   Date: 13Jun24 | Fetching 32 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[234/312] Processing Week: 20Jun24\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[234/312] Processing Week: 20Jun24\n",
      "   Date: 20Jun24 | Fetching 18 contracts...\n",
      "   Date: 20Jun24 | Fetching 18 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[235/312] Processing Week: 27Jun24\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[235/312] Processing Week: 27Jun24\n",
      "   Date: 27Jun24 | Fetching 36 contracts...\n",
      "   Date: 27Jun24 | Fetching 36 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[236/312] Processing Week: 04Jul24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[236/312] Processing Week: 04Jul24\n",
      "   Date: 04Jul24 | Fetching 22 contracts...\n",
      "   Date: 04Jul24 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[237/312] Processing Week: 11Jul24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[237/312] Processing Week: 11Jul24\n",
      "   Date: 11Jul24 | Fetching 18 contracts...\n",
      "   Date: 11Jul24 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[238/312] Processing Week: 18Jul24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[238/312] Processing Week: 18Jul24\n",
      "   Date: 18Jul24 | Fetching 26 contracts...\n",
      "   Date: 18Jul24 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[239/312] Processing Week: 25Jul24\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[239/312] Processing Week: 25Jul24\n",
      "   Date: 25Jul24 | Fetching 34 contracts...\n",
      "   Date: 25Jul24 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[240/312] Processing Week: 01Aug24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[240/312] Processing Week: 01Aug24\n",
      "   Date: 01Aug24 | Fetching 30 contracts...\n",
      "   Date: 01Aug24 | Fetching 30 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[241/312] Processing Week: 08Aug24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[241/312] Processing Week: 08Aug24\n",
      "   Date: 08Aug24 | Fetching 38 contracts...\n",
      "   Date: 08Aug24 | Fetching 38 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[242/312] Processing Week: 15Aug24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[242/312] Processing Week: 15Aug24\n",
      "   Date: 14Aug24 | Fetching 20 contracts...\n",
      "   Date: 14Aug24 | Fetching 20 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[243/312] Processing Week: 22Aug24\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[243/312] Processing Week: 22Aug24\n",
      "   Date: 22Aug24 | Fetching 32 contracts...\n",
      "   Date: 22Aug24 | Fetching 32 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[244/312] Processing Week: 29Aug24\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[244/312] Processing Week: 29Aug24\n",
      "   Date: 29Aug24 | Fetching 22 contracts...\n",
      "   Date: 29Aug24 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[245/312] Processing Week: 05Sep24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[245/312] Processing Week: 05Sep24\n",
      "   Date: 05Sep24 | Fetching 14 contracts...\n",
      "   Date: 05Sep24 | Fetching 14 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[246/312] Processing Week: 12Sep24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[246/312] Processing Week: 12Sep24\n",
      "   Date: 12Sep24 | Fetching 34 contracts...\n",
      "   Date: 12Sep24 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[247/312] Processing Week: 19Sep24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[247/312] Processing Week: 19Sep24\n",
      "   Date: 19Sep24 | Fetching 18 contracts...\n",
      "   Date: 19Sep24 | Fetching 18 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[248/312] Processing Week: 26Sep24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[248/312] Processing Week: 26Sep24\n",
      "   Date: 26Sep24 | Fetching 38 contracts...\n",
      "   Date: 26Sep24 | Fetching 38 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[249/312] Processing Week: 03Oct24\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[249/312] Processing Week: 03Oct24\n",
      "   Date: 03Oct24 | Fetching 46 contracts...\n",
      "   Date: 03Oct24 | Fetching 46 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[250/312] Processing Week: 10Oct24\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[250/312] Processing Week: 10Oct24\n",
      "   Date: 10Oct24 | Fetching 38 contracts...\n",
      "   Date: 10Oct24 | Fetching 38 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[251/312] Processing Week: 17Oct24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[251/312] Processing Week: 17Oct24\n",
      "   Date: 17Oct24 | Fetching 24 contracts...\n",
      "   Date: 17Oct24 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[252/312] Processing Week: 24Oct24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[252/312] Processing Week: 24Oct24\n",
      "   Date: 24Oct24 | Fetching 30 contracts...\n",
      "   Date: 24Oct24 | Fetching 30 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[253/312] Processing Week: 31Oct24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[253/312] Processing Week: 31Oct24\n",
      "   Date: 31Oct24 | Fetching 24 contracts...\n",
      "   Date: 31Oct24 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[254/312] Processing Week: 07Nov24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[254/312] Processing Week: 07Nov24\n",
      "   Date: 07Nov24 | Fetching 36 contracts...\n",
      "   Date: 07Nov24 | Fetching 36 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[255/312] Processing Week: 14Nov24\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[255/312] Processing Week: 14Nov24\n",
      "   Date: 14Nov24 | Fetching 40 contracts...\n",
      "   Date: 14Nov24 | Fetching 40 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[256/312] Processing Week: 21Nov24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[256/312] Processing Week: 21Nov24\n",
      "   Date: 21Nov24 | Fetching 28 contracts...\n",
      "   Date: 21Nov24 | Fetching 28 contracts...\n",
      "    Batch Saved (1129 rows)\n",
      "\n",
      "[257/312] Processing Week: 28Nov24\n",
      "    Batch Saved (1129 rows)\n",
      "\n",
      "[257/312] Processing Week: 28Nov24\n",
      "   Date: 28Nov24 | Fetching 44 contracts...\n",
      "   Date: 28Nov24 | Fetching 44 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[258/312] Processing Week: 05Dec24\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[258/312] Processing Week: 05Dec24\n",
      "   Date: 05Dec24 | Fetching 42 contracts...\n",
      "   Date: 05Dec24 | Fetching 42 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[259/312] Processing Week: 12Dec24\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[259/312] Processing Week: 12Dec24\n",
      "   Date: 12Dec24 | Fetching 16 contracts...\n",
      "   Date: 12Dec24 | Fetching 16 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[260/312] Processing Week: 19Dec24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[260/312] Processing Week: 19Dec24\n",
      "   Date: 19Dec24 | Fetching 42 contracts...\n",
      "   Date: 19Dec24 | Fetching 42 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[261/312] Processing Week: 26Dec24\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[261/312] Processing Week: 26Dec24\n",
      "   Date: 26Dec24 | Fetching 26 contracts...\n",
      "   Date: 26Dec24 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[262/312] Processing Week: 02Jan25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[262/312] Processing Week: 02Jan25\n",
      "   Date: 02Jan25 | Fetching 36 contracts...\n",
      "   Date: 02Jan25 | Fetching 36 contracts...\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[263/312] Processing Week: 09Jan25\n",
      "    Batch Saved (1878 rows)\n",
      "\n",
      "[263/312] Processing Week: 09Jan25\n",
      "   Date: 09Jan25 | Fetching 34 contracts...\n",
      "   Date: 09Jan25 | Fetching 34 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[264/312] Processing Week: 16Jan25\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[264/312] Processing Week: 16Jan25\n",
      "   Date: 16Jan25 | Fetching 28 contracts...\n",
      "   Date: 16Jan25 | Fetching 28 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[265/312] Processing Week: 23Jan25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[265/312] Processing Week: 23Jan25\n",
      "   Date: 23Jan25 | Fetching 22 contracts...\n",
      "   Date: 23Jan25 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[266/312] Processing Week: 30Jan25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[266/312] Processing Week: 30Jan25\n",
      "   Date: 30Jan25 | Fetching 28 contracts...\n",
      "   Date: 30Jan25 | Fetching 28 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[267/312] Processing Week: 06Feb25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[267/312] Processing Week: 06Feb25\n",
      "   Date: 06Feb25 | Fetching 28 contracts...\n",
      "   Date: 06Feb25 | Fetching 28 contracts...\n",
      "    Batch Saved (2256 rows)\n",
      "\n",
      "[268/312] Processing Week: 13Feb25\n",
      "    Batch Saved (2256 rows)\n",
      "\n",
      "[268/312] Processing Week: 13Feb25\n",
      "   Date: 13Feb25 | Fetching 42 contracts...\n",
      "   Date: 13Feb25 | Fetching 42 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[269/312] Processing Week: 20Feb25\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[269/312] Processing Week: 20Feb25\n",
      "   Date: 20Feb25 | Fetching 22 contracts...\n",
      "   Date: 20Feb25 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[270/312] Processing Week: 27Feb25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[270/312] Processing Week: 27Feb25\n",
      "   Date: 27Feb25 | Fetching 22 contracts...\n",
      "   Date: 27Feb25 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[271/312] Processing Week: 06Mar25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[271/312] Processing Week: 06Mar25\n",
      "   Date: 06Mar25 | Fetching 30 contracts...\n",
      "   Date: 06Mar25 | Fetching 30 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[272/312] Processing Week: 13Mar25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[272/312] Processing Week: 13Mar25\n",
      "   Date: 13Mar25 | Fetching 20 contracts...\n",
      "   Date: 13Mar25 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[273/312] Processing Week: 20Mar25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[273/312] Processing Week: 20Mar25\n",
      "   Date: 20Mar25 | Fetching 36 contracts...\n",
      "   Date: 20Mar25 | Fetching 36 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[274/312] Processing Week: 27Mar25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[274/312] Processing Week: 27Mar25\n",
      "   Date: 27Mar25 | Fetching 34 contracts...\n",
      "   Date: 27Mar25 | Fetching 34 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[275/312] Processing Week: 03Apr25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[275/312] Processing Week: 03Apr25\n",
      "   Date: 03Apr25 | Fetching 26 contracts...\n",
      "   Date: 03Apr25 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[276/312] Processing Week: 10Apr25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[276/312] Processing Week: 10Apr25\n",
      "   Date: 09Apr25 | Fetching 60 contracts...\n",
      "   Date: 09Apr25 | Fetching 60 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[277/312] Processing Week: 17Apr25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[277/312] Processing Week: 17Apr25\n",
      "   Date: 17Apr25 | Fetching 44 contracts...\n",
      "   Date: 17Apr25 | Fetching 44 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[278/312] Processing Week: 24Apr25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[278/312] Processing Week: 24Apr25\n",
      "   Date: 24Apr25 | Fetching 24 contracts...\n",
      "   Date: 24Apr25 | Fetching 24 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[279/312] Processing Week: 01May25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[279/312] Processing Week: 01May25\n",
      "   Date: 30Apr25 | Fetching 30 contracts...\n",
      "   Date: 30Apr25 | Fetching 30 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[280/312] Processing Week: 08May25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[280/312] Processing Week: 08May25\n",
      "   Date: 08May25 | Fetching 24 contracts...\n",
      "   Date: 08May25 | Fetching 24 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[281/312] Processing Week: 15May25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[281/312] Processing Week: 15May25\n",
      "   Date: 15May25 | Fetching 44 contracts...\n",
      "   Date: 15May25 | Fetching 44 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[282/312] Processing Week: 22May25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[282/312] Processing Week: 22May25\n",
      "   Date: 22May25 | Fetching 30 contracts...\n",
      "   Date: 22May25 | Fetching 30 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[283/312] Processing Week: 29May25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[283/312] Processing Week: 29May25\n",
      "   Date: 29May25 | Fetching 26 contracts...\n",
      "   Date: 29May25 | Fetching 26 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[284/312] Processing Week: 05Jun25\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[284/312] Processing Week: 05Jun25\n",
      "   Date: 05Jun25 | Fetching 22 contracts...\n",
      "   Date: 05Jun25 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[285/312] Processing Week: 12Jun25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[285/312] Processing Week: 12Jun25\n",
      "   Date: 12Jun25 | Fetching 26 contracts...\n",
      "   Date: 12Jun25 | Fetching 26 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[286/312] Processing Week: 19Jun25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[286/312] Processing Week: 19Jun25\n",
      "   Date: 19Jun25 | Fetching 22 contracts...\n",
      "   Date: 19Jun25 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[287/312] Processing Week: 26Jun25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[287/312] Processing Week: 26Jun25\n",
      "   Date: 26Jun25 | Fetching 36 contracts...\n",
      "   Date: 26Jun25 | Fetching 36 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[288/312] Processing Week: 03Jul25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[288/312] Processing Week: 03Jul25\n",
      "   Date: 03Jul25 | Fetching 16 contracts...\n",
      "   Date: 03Jul25 | Fetching 16 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[289/312] Processing Week: 10Jul25\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[289/312] Processing Week: 10Jul25\n",
      "   Date: 10Jul25 | Fetching 14 contracts...\n",
      "   Date: 10Jul25 | Fetching 14 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[290/312] Processing Week: 17Jul25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[290/312] Processing Week: 17Jul25\n",
      "   Date: 17Jul25 | Fetching 18 contracts...\n",
      "   Date: 17Jul25 | Fetching 18 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[291/312] Processing Week: 24Jul25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[291/312] Processing Week: 24Jul25\n",
      "   Date: 24Jul25 | Fetching 20 contracts...\n",
      "   Date: 24Jul25 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[292/312] Processing Week: 31Jul25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[292/312] Processing Week: 31Jul25\n",
      "   Date: 31Jul25 | Fetching 22 contracts...\n",
      "   Date: 31Jul25 | Fetching 22 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[293/312] Processing Week: 07Aug25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[293/312] Processing Week: 07Aug25\n",
      "   Date: 07Aug25 | Fetching 24 contracts...\n",
      "   Date: 07Aug25 | Fetching 24 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[294/312] Processing Week: 14Aug25\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[294/312] Processing Week: 14Aug25\n",
      "   Date: 14Aug25 | Fetching 20 contracts...\n",
      "   Date: 14Aug25 | Fetching 20 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[295/312] Processing Week: 21Aug25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[295/312] Processing Week: 21Aug25\n",
      "   Date: 21Aug25 | Fetching 18 contracts...\n",
      "   Date: 21Aug25 | Fetching 18 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[296/312] Processing Week: 28Aug25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[296/312] Processing Week: 28Aug25\n",
      "   Date: 28Aug25 | Fetching 28 contracts...\n",
      "   Date: 28Aug25 | Fetching 28 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[297/312] Processing Week: 04Sep25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[297/312] Processing Week: 04Sep25\n",
      "   Date: 03Sep25 | Fetching 12 contracts...\n",
      "   Date: 03Sep25 | Fetching 12 contracts...\n",
      "    Batch Saved (376 rows)\n",
      "\n",
      "[298/312] Processing Week: 02Sep25\n",
      "    Batch Saved (376 rows)\n",
      "\n",
      "[298/312] Processing Week: 02Sep25\n",
      "   Date: 02Sep25 | Fetching 16 contracts...\n",
      "   Date: 02Sep25 | Fetching 16 contracts...\n",
      "    Batch Saved (752 rows)\n",
      "\n",
      "[299/312] Processing Week: 09Sep25\n",
      "    Batch Saved (752 rows)\n",
      "\n",
      "[299/312] Processing Week: 09Sep25\n",
      "   Date: 09Sep25 | Fetching 22 contracts...\n",
      "   Date: 09Sep25 | Fetching 22 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[300/312] Processing Week: 16Sep25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[300/312] Processing Week: 16Sep25\n",
      "   Date: 16Sep25 | Fetching 20 contracts...\n",
      "   Date: 16Sep25 | Fetching 20 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[301/312] Processing Week: 23Sep25\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[301/312] Processing Week: 23Sep25\n",
      "   Date: 23Sep25 | Fetching 20 contracts...\n",
      "   Date: 23Sep25 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[302/312] Processing Week: 30Sep25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[302/312] Processing Week: 30Sep25\n",
      "   Date: 30Sep25 | Fetching 28 contracts...\n",
      "   Date: 30Sep25 | Fetching 28 contracts...\n",
      "    Batch Saved (1827 rows)\n",
      "\n",
      "[303/312] Processing Week: 07Oct25\n",
      "    Batch Saved (1827 rows)\n",
      "\n",
      "[303/312] Processing Week: 07Oct25\n",
      "   Date: 07Oct25 | Fetching 30 contracts...\n",
      "   Date: 07Oct25 | Fetching 30 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[304/312] Processing Week: 14Oct25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[304/312] Processing Week: 14Oct25\n",
      "   Date: 14Oct25 | Fetching 18 contracts...\n",
      "   Date: 14Oct25 | Fetching 18 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[305/312] Processing Week: 21Oct25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[305/312] Processing Week: 21Oct25\n",
      "   Date: 20Oct25 | Fetching 38 contracts...\n",
      "   Date: 20Oct25 | Fetching 38 contracts...\n",
      "    Batch Saved (1601 rows)\n",
      "\n",
      "[306/312] Processing Week: 28Oct25\n",
      "    Batch Saved (1601 rows)\n",
      "\n",
      "[306/312] Processing Week: 28Oct25\n",
      "   Date: 28Oct25 | Fetching 22 contracts...\n",
      "   Date: 28Oct25 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[307/312] Processing Week: 04Nov25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[307/312] Processing Week: 04Nov25\n",
      "   Date: 04Nov25 | Fetching 26 contracts...\n",
      "   Date: 04Nov25 | Fetching 26 contracts...\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[308/312] Processing Week: 11Nov25\n",
      "    Batch Saved (1505 rows)\n",
      "\n",
      "[308/312] Processing Week: 11Nov25\n",
      "   Date: 11Nov25 | Fetching 22 contracts...\n",
      "   Date: 11Nov25 | Fetching 22 contracts...\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[309/312] Processing Week: 18Nov25\n",
      "    Batch Saved (1504 rows)\n",
      "\n",
      "[309/312] Processing Week: 18Nov25\n",
      "   Date: 18Nov25 | Fetching 16 contracts...\n",
      "   Date: 18Nov25 | Fetching 16 contracts...\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[310/312] Processing Week: 25Nov25\n",
      "    Batch Saved (1881 rows)\n",
      "\n",
      "[310/312] Processing Week: 25Nov25\n",
      "   Date: 25Nov25 | Fetching 22 contracts...\n",
      "   Date: 25Nov25 | Fetching 22 contracts...\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[311/312] Processing Week: 02Dec25\n",
      "    Batch Saved (1882 rows)\n",
      "\n",
      "[311/312] Processing Week: 02Dec25\n",
      "   Date: 02Dec25 | Fetching 20 contracts...\n",
      "   Date: 02Dec25 | Fetching 20 contracts...\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[312/312] Processing Week: 09Dec25\n",
      "    Batch Saved (1880 rows)\n",
      "\n",
      "[312/312] Processing Week: 09Dec25\n",
      "   Date: 09Dec25 | Fetching 18 contracts...\n",
      "   Date: 09Dec25 | Fetching 18 contracts...\n",
      "    Batch Saved (1423 rows)\n",
      "\n",
      " SUCCESS! Full History Saved to Order_nifty_full_market_data_2020_2025.csv\n",
      "    Batch Saved (1423 rows)\n",
      "\n",
      " SUCCESS! Full History Saved to Order_nifty_full_market_data_2020_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from growwapi import GrowwAPI\n",
    "\n",
    "# --- CREDENTIALS ---\n",
    "API_KEY = \"eyJraWQiOiJaTUtjVXciLCJhbGciOiJFUzI1NiJ9.eyJleHAiOjI1NTM1Njg0NzYsImlhdCI6MTc2NTE2ODQ3NiwibmJmIjoxNzY1MTY4NDc2LCJzdWIiOiJ7XCJ0b2tlblJlZklkXCI6XCJhMTg3NDVhMy1hN2M1LTRlOTQtODE1MS1lZjUxZDQ5OGE2Y2RcIixcInZlbmRvckludGVncmF0aW9uS2V5XCI6XCJlMzFmZjIzYjA4NmI0MDZjODg3NGIyZjZkODQ5NTMxM1wiLFwidXNlckFjY291bnRJZFwiOlwiMDdmMDA0MGMtZTk4Zi00ZDNmLTk5Y2EtZDc1ZjBlYWU5M2NlXCIsXCJkZXZpY2VJZFwiOlwiZDMyMWIxMzUtZWQ5Mi01ZWJkLWJjMDUtZTY1NDY2OWRiMDM5XCIsXCJzZXNzaW9uSWRcIjpcIjBlOWMyYWZmLTM0NzktNDUyMi1iODE4LTczNTZlMzFkYmY1Y1wiLFwiYWRkaXRpb25hbERhdGFcIjpcIno1NC9NZzltdjE2WXdmb0gvS0EwYk1yOE5XVzhzdTNvZ080am1ZUzIwZEpSTkczdTlLa2pWZDNoWjU1ZStNZERhWXBOVi9UOUxIRmtQejFFQisybTdRPT1cIixcInJvbGVcIjpcImF1dGgtdG90cFwiLFwic291cmNlSXBBZGRyZXNzXCI6XCIyNDA5OjQwOTA6MTA4ZjpkYzA1OjNkMWQ6MWZmMDo1YWFjOjYwNTYsMTcyLjcxLjE5OC4xOSwzNS4yNDEuMjMuMTIzXCIsXCJ0d29GYUV4cGlyeVRzXCI6MjU1MzU2ODQ3NjQzNn0iLCJpc3MiOiJhcGV4LWF1dGgtcHJvZC1hcHAifQ.VuAMgqoC3e32gduObByNz97jFfG-ikXoREum26XPkvyMpj9JgCedXBI81jxGTPTrZD9i1wIL0s38LPd9vc9ApA\"\n",
    "API_SECRET = \"xy0sbQ4r*!HN3&&UKc9vpwti4xx8PR)(\"\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SPOT_FILE = \"Final_nifty_spot_1minute_fixed_trimmed.csv\"  # Your verified spot file\n",
    "OUTPUT_FILE = \"Order_nifty_full_market_data_2020_2025.csv\"      # The final result\n",
    "\n",
    "def auth():\n",
    "    try:\n",
    "        token = GrowwAPI.get_access_token(api_key=API_KEY, secret=API_SECRET)\n",
    "        return GrowwAPI(token)\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL: Auth failed. Error: {e}\")\n",
    "        exit()\n",
    "\n",
    "# --- 1. SMART EXPIRY LOGIC (Handles 2025 Rule Change) ---\n",
    "def get_target_expiry_date(date_obj):\n",
    "    # Remove timezone info for safe comparison\n",
    "    date_obj = date_obj.replace(tzinfo=None)\n",
    "    \n",
    "    # Logic: Thursday before Sep 1, 2025. Tuesday after.\n",
    "    switch_date = pd.Timestamp(\"2025-09-01\")\n",
    "    target_day = 1 if date_obj >= switch_date else 3 # 1=Tue, 3=Thu\n",
    "    \n",
    "    days_ahead = target_day - date_obj.weekday()\n",
    "    if days_ahead < 0: \n",
    "        days_ahead += 7\n",
    "        \n",
    "    return date_obj + timedelta(days=days_ahead)\n",
    "\n",
    "def main():\n",
    "    # 1. Load Data\n",
    "    print(f\"1. Loading Spot Data from {SPOT_FILE}...\")\n",
    "    try:\n",
    "        df_spot = pd.read_csv(SPOT_FILE)\n",
    "        \n",
    "        # Robust Timestamp Parsing\n",
    "        if pd.api.types.is_numeric_dtype(df_spot['timestamp']):\n",
    "            df_spot['timestamp'] = pd.to_datetime(df_spot['timestamp'], unit='s')\n",
    "        else:\n",
    "            df_spot['timestamp'] = pd.to_datetime(df_spot['timestamp'])\n",
    "            \n",
    "        # Normalize Timezone (Remove +05:30 for sorting)\n",
    "        df_spot['timestamp'] = df_spot['timestamp'].dt.tz_localize(None)\n",
    "        \n",
    "        # CRITICAL: Sort Spot Data to ensure chronological order\n",
    "        df_spot.sort_values('timestamp', inplace=True)\n",
    "        print(f\"   Loaded {len(df_spot)} rows.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"   Error: Spot file not found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Prepare Metadata\n",
    "    print(\"2. Calculating Expiries & Strikes...\")\n",
    "    df_spot['atm_strike'] = (df_spot['close'] / 50).round() * 50\n",
    "    df_spot['expiry_dt'] = df_spot['timestamp'].apply(get_target_expiry_date)\n",
    "    # Groww Format: 09Jan20\n",
    "    df_spot['expiry_str'] = df_spot['expiry_dt'].dt.strftime(\"%d%b%y\")\n",
    "    \n",
    "    # 3. Start Download Loop\n",
    "    groww = auth()\n",
    "    option_cache = {}\n",
    "    \n",
    "    # CRITICAL FIX: sort=False ensures we process Jan 2020 -> Feb 2020 ... -> Dec 2025\n",
    "    grouped = df_spot.groupby('expiry_str', sort=False)\n",
    "    \n",
    "    print(f\"\\n--- Starting Full Download ({len(grouped)} Weeks) ---\")\n",
    "    \n",
    "    # Check if we are resuming (append mode)\n",
    "    file_exists = False\n",
    "    try:\n",
    "        pd.read_csv(OUTPUT_FILE, nrows=1)\n",
    "        file_exists = True\n",
    "        print(\"   (Appending to existing file...)\")\n",
    "    except FileNotFoundError:\n",
    "        file_exists = False\n",
    "\n",
    "    # Counters for progress\n",
    "    processed_weeks = 0\n",
    "    total_weeks = len(grouped)\n",
    "\n",
    "    for expiry_str, group in grouped:\n",
    "        processed_weeks += 1\n",
    "        print(f\"\\n[{processed_weeks}/{total_weeks}] Processing Week: {expiry_str}\")\n",
    "        \n",
    "        # A. Identify Strikes to Fetch (ATM, ITM, OTM)\n",
    "        atm_strikes = group['atm_strike'].unique().astype(int)\n",
    "        strikes_to_fetch = set()\n",
    "        for k in atm_strikes:\n",
    "            strikes_to_fetch.add(k)      # ATM\n",
    "            strikes_to_fetch.add(k - 50) # ITM Call / OTM Put\n",
    "            strikes_to_fetch.add(k + 50) # OTM Call / ITM Put\n",
    "        \n",
    "        # B. Smart Date Detection (Primary vs Backup)\n",
    "        primary_dt = group['expiry_dt'].iloc[0]\n",
    "        backup_dt = primary_dt - timedelta(days=1)\n",
    "        fmt_primary = primary_dt.strftime(\"%d%b%y\")\n",
    "        fmt_backup = backup_dt.strftime(\"%d%b%y\")\n",
    "        \n",
    "        active_fmt = fmt_primary\n",
    "        \n",
    "        # Quick Check: Does Primary Date have data?\n",
    "        # We test the first strike to avoid wasting API calls on holidays\n",
    "        test_sym = f\"NSE-NIFTY-{fmt_primary}-{list(strikes_to_fetch)[0]}-CE\"\n",
    "        try:\n",
    "            check_start = group['timestamp'].min().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            check_end = (group['timestamp'].min() + timedelta(days=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            resp = groww.get_historical_candles(\n",
    "                exchange=\"NSE\", segment=\"FNO\", groww_symbol=test_sym,\n",
    "                start_time=check_start, end_time=check_end, candle_interval=\"1minute\"\n",
    "            )\n",
    "            # If empty list or None, assume holiday -> Switch to Backup\n",
    "            if not (resp and \"candles\" in resp and len(resp[\"candles\"]) > 0):\n",
    "                active_fmt = fmt_backup\n",
    "        except:\n",
    "            active_fmt = fmt_backup\n",
    "            \n",
    "        print(f\"   Date: {active_fmt} | Fetching {len(strikes_to_fetch)*2} contracts...\")\n",
    "\n",
    "        # C. Download Contracts\n",
    "        start_dt_str = group['timestamp'].min().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        end_dt_str = group['timestamp'].max().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        for strike in strikes_to_fetch:\n",
    "            for opt_type in ['CE', 'PE']:\n",
    "                sym = f\"NSE-NIFTY-{active_fmt}-{strike}-{opt_type}\"\n",
    "                if sym in option_cache: continue\n",
    "                \n",
    "                try:\n",
    "                    resp = groww.get_historical_candles(\n",
    "                        exchange=\"NSE\", segment=\"FNO\", groww_symbol=sym,\n",
    "                        start_time=start_dt_str, end_time=end_dt_str, candle_interval=\"1minute\"\n",
    "                    )\n",
    "                    \n",
    "                    if resp and \"candles\" in resp and len(resp[\"candles\"]) > 0:\n",
    "                        df = pd.DataFrame(resp[\"candles\"])\n",
    "                        \n",
    "                        # FIX: Handle Column Variations (6 vs 7 cols)\n",
    "                        if len(df.columns) == 7:\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close', 'v', 'oi']\n",
    "                        elif len(df.columns) == 6:\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close', 'v']\n",
    "                            df['oi'] = 0 # Default if missing\n",
    "                        else:\n",
    "                            df = df.iloc[:, :5]\n",
    "                            df.columns = ['ts', 'o', 'h', 'l', 'close']\n",
    "                            df['oi'] = 0\n",
    "                            \n",
    "                        # FIX: Handle String vs Int Timestamps\n",
    "                        if isinstance(df['ts'].iloc[0], str):\n",
    "                            df['timestamp'] = pd.to_datetime(df['ts'])\n",
    "                        else:\n",
    "                            df['timestamp'] = pd.to_datetime(df['ts'], unit='s')\n",
    "                        \n",
    "                        # Remove timezone for clean merging\n",
    "                        df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "                        \n",
    "                        df.set_index('timestamp', inplace=True)\n",
    "                        df = df[~df.index.duplicated(keep='first')]\n",
    "                        option_cache[sym] = df\n",
    "                except Exception:\n",
    "                    pass\n",
    "        \n",
    "        # D. Stitch & Save\n",
    "        rows_collected = []\n",
    "        for index, row in group.iterrows():\n",
    "            ts = row['timestamp']\n",
    "            atm = int(row['atm_strike'])\n",
    "            \n",
    "            # Data Retrieval Helper\n",
    "            def get_data(s, t):\n",
    "                k = f\"NSE-NIFTY-{active_fmt}-{s}-{t}\"\n",
    "                if k in option_cache and ts in option_cache[k].index:\n",
    "                    d = option_cache[k].loc[ts]\n",
    "                    return d['close'], d.get('oi', 0)\n",
    "                return None, None\n",
    "\n",
    "            # Fetch all needed data points\n",
    "            atm_ce, atm_ce_oi = get_data(atm, \"CE\")\n",
    "            atm_pe, atm_pe_oi = get_data(atm, \"PE\")\n",
    "            itm_ce, itm_ce_oi = get_data(atm-50, \"CE\")\n",
    "            itm_pe, itm_pe_oi = get_data(atm+50, \"PE\")\n",
    "            \n",
    "            rows_collected.append({\n",
    "                \"timestamp\": ts,\n",
    "                \"nifty_open\": row['open'],\n",
    "                \"nifty_high\": row['high'],\n",
    "                \"nifty_low\": row['low'],\n",
    "                \"nifty_close\": row['close'],\n",
    "                # \"nifty_vol\": row.get('volume', 0), # Optional\n",
    "                \"expiry\": expiry_str,\n",
    "                \"atm_strike\": atm,\n",
    "                \"atm_ce_ltp\": atm_ce, \"atm_ce_oi\": atm_ce_oi,\n",
    "                \"atm_pe_ltp\": atm_pe, \"atm_pe_oi\": atm_pe_oi,\n",
    "                \"itm_ce_ltp\": itm_ce, \"itm_ce_oi\": itm_ce_oi,\n",
    "                \"itm_pe_ltp\": itm_pe, \"itm_pe_oi\": itm_pe_oi\n",
    "            })\n",
    "        \n",
    "        # Save Batch to Disk\n",
    "        if rows_collected:\n",
    "            final_df = pd.DataFrame(rows_collected)\n",
    "            # Write header only if file didn't exist\n",
    "            header_mode = not file_exists\n",
    "            final_df.to_csv(OUTPUT_FILE, mode='a', header=header_mode, index=False)\n",
    "            file_exists = True # Now it exists\n",
    "            print(f\"    Batch Saved ({len(final_df)} rows)\")\n",
    "        \n",
    "        # E. Clear Memory\n",
    "        option_cache.clear()\n",
    "\n",
    "    print(f\"\\n SUCCESS! Full History Saved to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57e667a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Order_nifty_full_market_data_2020_2025.csv...\n",
      "\n",
      "2. Filling missing values (Forward Fill)...\n",
      "2. Filling missing values (Forward Fill)...\n",
      "3. Normalizing Open Interest (Fixing 2025 Drop)...\n",
      "3. Normalizing Open Interest (Fixing 2025 Drop)...\n",
      "------------------------------\n",
      " SUCCESS! Cleaned file saved: nifty_data_fixed_oi.csv\n",
      "Total Rows: 550481\n",
      "New Columns Added: atm_ce_oi_norm, atm_pe_oi_norm, etc.\n",
      "------------------------------\n",
      " SUCCESS! Cleaned file saved: nifty_data_fixed_oi.csv\n",
      "Total Rows: 550481\n",
      "New Columns Added: atm_ce_oi_norm, atm_pe_oi_norm, etc.\n",
      "------------------------------\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE = \"Order_nifty_full_market_data_2020_2025.csv\"\n",
    "OUTPUT_FILE = \"nifty_data_fixed_oi.csv\"\n",
    "\n",
    "def fix_data():\n",
    "    print(f\"1. Loading {INPUT_FILE}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found.\")\n",
    "        return\n",
    "\n",
    "    # Ensure Timestamp is clean\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # --- STEP 1: FIX MISSING VALUES (GAPS) ---\n",
    "    print(\"2. Filling missing values (Forward Fill)...\")\n",
    "    \n",
    "    # These columns often have gaps because NSE updates them every 3 mins\n",
    "    cols_to_fix = [\n",
    "        'atm_ce_ltp', 'atm_ce_oi', \n",
    "        'atm_pe_ltp', 'atm_pe_oi',\n",
    "        'itm_ce_ltp', 'itm_ce_oi',\n",
    "        'itm_pe_ltp', 'itm_pe_oi'\n",
    "    ]\n",
    "    \n",
    "    # Forward Fill: If data is missing at 09:16, use the value from 09:15\n",
    "    df[cols_to_fix] = df[cols_to_fix].ffill()\n",
    "    \n",
    "    # Drop any rows that are STILL empty (e.g., the very first minute of 2020)\n",
    "    df.dropna(subset=cols_to_fix, inplace=True)\n",
    "\n",
    "    # --- STEP 2: FIX OI SCALING (NORMALIZATION) ---\n",
    "    print(\"3. Normalizing Open Interest (Fixing 2025 Drop)...\")\n",
    "    \n",
    "    # We create NEW columns called '_norm' (Normalized)\n",
    "    # This solves the \"Quantity vs Lots\" issue by looking at RELATIVE changes\n",
    "    oi_cols = ['atm_ce_oi', 'atm_pe_oi', 'itm_ce_oi', 'itm_pe_oi']\n",
    "    \n",
    "    for col in oi_cols:\n",
    "        # Calculate Rolling Stats (2 Hours window)\n",
    "        roll_mean = df[col].rolling(window=120).mean()\n",
    "        roll_std = df[col].rolling(window=120).std()\n",
    "        \n",
    "        # Create Normalized Column (Z-Score)\n",
    "        # 0 = Normal, +2 = Very High, -2 = Very Low\n",
    "        # This makes 2024 and 2025 look exactly the same to the AI\n",
    "        df[f'{col}_norm'] = (df[col] - roll_mean) / (roll_std + 1e-9)\n",
    "        \n",
    "        # We KEEP the original column too, just in case you want to see it.\n",
    "\n",
    "    # Drop the first 120 rows where rolling mean is calculating\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # --- SAVE ---\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(\"-\" * 30)\n",
    "    print(f\" SUCCESS! Cleaned file saved: {OUTPUT_FILE}\")\n",
    "    print(f\"Total Rows: {len(df)}\")\n",
    "    print(\"New Columns Added: atm_ce_oi_norm, atm_pe_oi_norm, etc.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fix_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae1c0741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (550481, 19) (550481, 19)\n",
      "\n",
      "Columns:\n",
      " \n",
      "\n",
      "Columns:\n",
      " ['timestamp', 'nifty_open', 'nifty_high', 'nifty_low', 'nifty_close', 'expiry', 'atm_strike', 'atm_ce_ltp', 'atm_ce_oi', 'atm_pe_ltp', 'atm_pe_oi', 'itm_ce_ltp', 'itm_ce_oi', 'itm_pe_ltp', 'itm_pe_oi', 'atm_ce_oi_norm', 'atm_pe_oi_norm', 'itm_ce_oi_norm', 'itm_pe_oi_norm']\n",
      "\n",
      "First 20 rows (Forced string representation):\n",
      "['timestamp', 'nifty_open', 'nifty_high', 'nifty_low', 'nifty_close', 'expiry', 'atm_strike', 'atm_ce_ltp', 'atm_ce_oi', 'atm_pe_ltp', 'atm_pe_oi', 'itm_ce_ltp', 'itm_ce_oi', 'itm_pe_ltp', 'itm_pe_oi', 'atm_ce_oi_norm', 'atm_pe_oi_norm', 'itm_ce_oi_norm', 'itm_pe_oi_norm']\n",
      "\n",
      "First 20 rows (Forced string representation):\n",
      "              timestamp  nifty_open  nifty_high  nifty_low  nifty_close   expiry  atm_strike  atm_ce_ltp  atm_ce_oi  atm_pe_ltp  atm_pe_oi  itm_ce_ltp  itm_ce_oi  itm_pe_ltp  itm_pe_oi  atm_ce_oi_norm  atm_pe_oi_norm  itm_ce_oi_norm  itm_pe_oi_norm\n",
      "0   2020-01-01 11:14:00    12184.15    12184.85   12183.10     12183.40  02Jan20       12200       25.35  3725100.0       38.70  2533425.0       53.55   783300.0       73.80   864000.0        1.161842       -0.171532        1.464612       -0.113680\n",
      "1   2020-01-01 11:15:00    12183.15    12186.80   12182.75     12186.80  02Jan20       12200       26.85  3725100.0       36.90  2533425.0       56.10   783300.0       71.15   864000.0        1.145919       -0.205069        1.441459       -0.120252\n",
      "2   2020-01-01 11:16:00    12186.75    12187.15   12185.90     12186.65  02Jan20       12200       26.70  3725100.0       37.20  2533425.0       55.80   783300.0       71.60   864000.0        1.130502       -0.242445        1.419152       -0.126872\n",
      "3   2020-01-01 11:17:00    12186.50    12187.10   12185.30     12186.65  02Jan20       12200       26.50  3758550.0       37.45  2535075.0       55.45   787950.0       71.90   863400.0        1.186154       -0.260863        1.442843       -0.135301\n",
      "4   2020-01-01 11:18:00    12186.45    12186.90   12184.00     12184.00  02Jan20       12200       26.20  3758550.0       38.15  2535075.0       54.80   787950.0       73.00   863400.0        1.168320       -0.291433        1.420939       -0.141144\n",
      "5   2020-01-01 11:19:00    12184.20    12184.70   12182.65     12184.05  02Jan20       12200       25.95  3758550.0       38.55  2535075.0       54.05   787950.0       73.75   863400.0        1.150959       -0.324726        1.399858       -0.147022\n",
      "6   2020-01-01 11:20:00    12184.35    12185.15   12181.20     12182.35  02Jan20       12200       25.35  3765750.0       39.15  2545125.0       53.30   792900.0       74.65   868125.0        1.148480       -0.280758        1.427947       -0.131028\n",
      "7   2020-01-01 11:21:00    12182.25    12182.50   12179.95     12180.65  02Jan20       12200       24.85  3765750.0       39.85  2545125.0       52.55   792900.0       76.00   868125.0        1.130314       -0.304529        1.407057       -0.135861\n",
      "8   2020-01-01 11:22:00    12180.20    12180.95   12179.25     12179.85  02Jan20       12200       24.50  3765750.0       39.85  2545125.0       52.15   792900.0       75.00   868125.0        1.112561       -0.329707        1.386984       -0.140716\n",
      "9   2020-01-01 11:23:00    12180.05    12180.80   12177.75     12177.90  02Jan20       12200       24.60  3793350.0       40.40  2560275.0       51.55   793725.0       76.20   870225.0        1.155360       -0.234281        1.374914       -0.134603\n",
      "10  2020-01-01 11:24:00    12178.15    12178.35   12176.70     12177.50  02Jan20       12200       24.60  3793350.0       40.20  2560275.0       51.70   793725.0       75.65   870225.0        1.136371       -0.246440        1.355215       -0.137798\n",
      "11  2020-01-01 11:25:00    12177.40    12177.85   12175.55     12176.10  02Jan20       12200       24.20  3793350.0       40.90  2560275.0       50.60   793725.0       76.60   870225.0        1.117795       -0.258858        1.336260       -0.141000\n",
      "12  2020-01-01 11:26:00    12176.50    12177.00   12175.65     12175.65  02Jan20       12200       24.40  3789900.0       41.00  2528625.0       51.15   823575.0       77.05   865125.0        1.091709       -0.494714        1.617468       -0.165473\n",
      "13  2020-01-01 11:27:00    12176.30    12178.00   12175.50     12177.70  02Jan20       12200       25.35  3789900.0       38.90  2528625.0       53.10   823575.0       74.35   865125.0        1.073775       -0.500508        1.592351       -0.167297\n",
      "14  2020-01-01 11:28:00    12177.75    12179.90   12177.75     12178.35  02Jan20       12200       25.10  3789900.0       39.70  2528625.0       52.20   823575.0       75.25   865125.0        1.056188       -0.506354        1.568377       -0.169123\n",
      "\n",
      "last 20 rows (Forced string representation):\n",
      "              timestamp  nifty_open  nifty_high  nifty_low  nifty_close   expiry  atm_strike  atm_ce_ltp  atm_ce_oi  atm_pe_ltp  atm_pe_oi  itm_ce_ltp  itm_ce_oi  itm_pe_ltp  itm_pe_oi  atm_ce_oi_norm  atm_pe_oi_norm  itm_ce_oi_norm  itm_pe_oi_norm\n",
      "0   2020-01-01 11:14:00    12184.15    12184.85   12183.10     12183.40  02Jan20       12200       25.35  3725100.0       38.70  2533425.0       53.55   783300.0       73.80   864000.0        1.161842       -0.171532        1.464612       -0.113680\n",
      "1   2020-01-01 11:15:00    12183.15    12186.80   12182.75     12186.80  02Jan20       12200       26.85  3725100.0       36.90  2533425.0       56.10   783300.0       71.15   864000.0        1.145919       -0.205069        1.441459       -0.120252\n",
      "2   2020-01-01 11:16:00    12186.75    12187.15   12185.90     12186.65  02Jan20       12200       26.70  3725100.0       37.20  2533425.0       55.80   783300.0       71.60   864000.0        1.130502       -0.242445        1.419152       -0.126872\n",
      "3   2020-01-01 11:17:00    12186.50    12187.10   12185.30     12186.65  02Jan20       12200       26.50  3758550.0       37.45  2535075.0       55.45   787950.0       71.90   863400.0        1.186154       -0.260863        1.442843       -0.135301\n",
      "4   2020-01-01 11:18:00    12186.45    12186.90   12184.00     12184.00  02Jan20       12200       26.20  3758550.0       38.15  2535075.0       54.80   787950.0       73.00   863400.0        1.168320       -0.291433        1.420939       -0.141144\n",
      "5   2020-01-01 11:19:00    12184.20    12184.70   12182.65     12184.05  02Jan20       12200       25.95  3758550.0       38.55  2535075.0       54.05   787950.0       73.75   863400.0        1.150959       -0.324726        1.399858       -0.147022\n",
      "6   2020-01-01 11:20:00    12184.35    12185.15   12181.20     12182.35  02Jan20       12200       25.35  3765750.0       39.15  2545125.0       53.30   792900.0       74.65   868125.0        1.148480       -0.280758        1.427947       -0.131028\n",
      "7   2020-01-01 11:21:00    12182.25    12182.50   12179.95     12180.65  02Jan20       12200       24.85  3765750.0       39.85  2545125.0       52.55   792900.0       76.00   868125.0        1.130314       -0.304529        1.407057       -0.135861\n",
      "8   2020-01-01 11:22:00    12180.20    12180.95   12179.25     12179.85  02Jan20       12200       24.50  3765750.0       39.85  2545125.0       52.15   792900.0       75.00   868125.0        1.112561       -0.329707        1.386984       -0.140716\n",
      "9   2020-01-01 11:23:00    12180.05    12180.80   12177.75     12177.90  02Jan20       12200       24.60  3793350.0       40.40  2560275.0       51.55   793725.0       76.20   870225.0        1.155360       -0.234281        1.374914       -0.134603\n",
      "10  2020-01-01 11:24:00    12178.15    12178.35   12176.70     12177.50  02Jan20       12200       24.60  3793350.0       40.20  2560275.0       51.70   793725.0       75.65   870225.0        1.136371       -0.246440        1.355215       -0.137798\n",
      "11  2020-01-01 11:25:00    12177.40    12177.85   12175.55     12176.10  02Jan20       12200       24.20  3793350.0       40.90  2560275.0       50.60   793725.0       76.60   870225.0        1.117795       -0.258858        1.336260       -0.141000\n",
      "12  2020-01-01 11:26:00    12176.50    12177.00   12175.65     12175.65  02Jan20       12200       24.40  3789900.0       41.00  2528625.0       51.15   823575.0       77.05   865125.0        1.091709       -0.494714        1.617468       -0.165473\n",
      "13  2020-01-01 11:27:00    12176.30    12178.00   12175.50     12177.70  02Jan20       12200       25.35  3789900.0       38.90  2528625.0       53.10   823575.0       74.35   865125.0        1.073775       -0.500508        1.592351       -0.167297\n",
      "14  2020-01-01 11:28:00    12177.75    12179.90   12177.75     12178.35  02Jan20       12200       25.10  3789900.0       39.70  2528625.0       52.20   823575.0       75.25   865125.0        1.056188       -0.506354        1.568377       -0.169123\n",
      "\n",
      "last 20 rows (Forced string representation):\n",
      "                  timestamp  nifty_open  nifty_high  nifty_low  nifty_close   expiry  atm_strike  atm_ce_ltp  atm_ce_oi  atm_pe_ltp  atm_pe_oi  itm_ce_ltp  itm_ce_oi  itm_pe_ltp  itm_pe_oi  atm_ce_oi_norm  atm_pe_oi_norm  itm_ce_oi_norm  itm_pe_oi_norm\n",
      "550466  2025-12-08 13:54:00    25933.15    25934.85   25928.40     25933.65  09Dec25       25950       72.65    99075.0       68.15   106474.0      102.55    89276.0       95.50   127517.0       -0.421922       -0.872067        0.493548       -0.003630\n",
      "550467  2025-12-08 13:55:00    25933.50    25933.85   25925.20     25926.50  09Dec25       25950       69.80    99075.0       71.85   106474.0       98.45    89276.0       99.65   127517.0       -0.424395       -0.866846        0.495672        0.004355\n",
      "550468  2025-12-08 13:56:00    25926.05    25926.15   25915.70     25918.45  09Dec25       25900       94.60    89956.0       52.30   179516.0      128.90    14043.0       74.20   103375.0       -0.667677        0.386044       -1.021056       -0.769479\n",
      "550469  2025-12-08 13:57:00    25919.00    25925.05   25918.75     25923.70  09Dec25       25900       97.55    89956.0       50.60   179516.0      131.00    14043.0       72.00   103375.0       -0.667650        0.378963       -1.004477       -0.756152\n",
      "550470  2025-12-08 13:58:00    25923.25    25933.60   25920.15     25932.90  09Dec25       25950       72.85    89956.0       66.85   179516.0      102.95    14043.0       94.00   103375.0       -0.666932        0.371848       -0.988152       -0.742924\n",
      "550471  2025-12-08 13:59:00    25933.15    25934.40   25928.25     25929.65  09Dec25       25950       70.90   103185.0       69.90   104313.0      100.50    96567.0       97.85   123625.0       -0.316881       -0.921021        0.683960       -0.070336\n",
      "550472  2025-12-08 14:00:00    25929.30    25930.40   25919.75     25923.60  09Dec25       25900       96.20   103185.0       51.25   104313.0      130.45    96567.0       73.50   123625.0       -0.319688       -0.915193        0.684702       -0.061393\n",
      "550473  2025-12-08 14:01:00    25922.95    25926.70   25917.45     25920.00  09Dec25       25900       94.40   103185.0       51.90   104313.0      128.25    96567.0       74.45   123625.0       -0.321763       -0.909655        0.686183       -0.052535\n",
      "550474  2025-12-08 14:02:00    25920.05    25923.20   25918.75     25921.90  09Dec25       25900       95.35   100666.0       51.50   181604.0      128.80    15445.0       73.90   101474.0       -0.390650        0.407706       -0.943502       -0.774766\n",
      "550475  2025-12-08 14:03:00    25922.40    25922.65   25908.45     25914.30  09Dec25       25900       91.00   100666.0       54.65   181604.0      123.70    15445.0       77.95   101474.0       -0.392145        0.400185       -0.928063       -0.761240\n",
      "550476  2025-12-08 14:04:00    25913.40    25923.20   25911.65     25921.85  09Dec25       25900       96.80   100666.0       50.70   181604.0      130.50    15445.0       72.75   101474.0       -0.392485        0.392932       -0.912735       -0.747901\n",
      "550477  2025-12-08 14:05:00    25922.10    25923.30   25916.50     25918.20  09Dec25       25900       95.10   101465.0       52.40   179530.0      128.05    15492.0       74.95    99895.0       -0.371622        0.350421       -0.896683       -0.786900\n",
      "550478  2025-12-08 14:06:00    25918.40    25920.45   25916.20     25918.45  09Dec25       25900       93.90   101465.0       52.55   179530.0      127.40    15492.0       75.20    99895.0       -0.372164        0.343515       -0.881784       -0.773227\n",
      "550479  2025-12-08 14:07:00    25919.00    25927.05   25918.25     25923.80  09Dec25       25900       96.05   101465.0       51.40   179530.0      130.15    15492.0       73.60    99895.0       -0.371903        0.336561       -0.867017       -0.759730\n",
      "550480  2025-12-08 14:08:00    25924.25    25924.30   25918.30     25918.85  09Dec25       25900       94.25   104751.0       52.50   178020.0      127.70    16068.0       74.90    92625.0       -0.284395        0.303875       -0.840905       -0.987915\n",
      "\n",
      "Missing values summary:\n",
      "                  timestamp  nifty_open  nifty_high  nifty_low  nifty_close   expiry  atm_strike  atm_ce_ltp  atm_ce_oi  atm_pe_ltp  atm_pe_oi  itm_ce_ltp  itm_ce_oi  itm_pe_ltp  itm_pe_oi  atm_ce_oi_norm  atm_pe_oi_norm  itm_ce_oi_norm  itm_pe_oi_norm\n",
      "550466  2025-12-08 13:54:00    25933.15    25934.85   25928.40     25933.65  09Dec25       25950       72.65    99075.0       68.15   106474.0      102.55    89276.0       95.50   127517.0       -0.421922       -0.872067        0.493548       -0.003630\n",
      "550467  2025-12-08 13:55:00    25933.50    25933.85   25925.20     25926.50  09Dec25       25950       69.80    99075.0       71.85   106474.0       98.45    89276.0       99.65   127517.0       -0.424395       -0.866846        0.495672        0.004355\n",
      "550468  2025-12-08 13:56:00    25926.05    25926.15   25915.70     25918.45  09Dec25       25900       94.60    89956.0       52.30   179516.0      128.90    14043.0       74.20   103375.0       -0.667677        0.386044       -1.021056       -0.769479\n",
      "550469  2025-12-08 13:57:00    25919.00    25925.05   25918.75     25923.70  09Dec25       25900       97.55    89956.0       50.60   179516.0      131.00    14043.0       72.00   103375.0       -0.667650        0.378963       -1.004477       -0.756152\n",
      "550470  2025-12-08 13:58:00    25923.25    25933.60   25920.15     25932.90  09Dec25       25950       72.85    89956.0       66.85   179516.0      102.95    14043.0       94.00   103375.0       -0.666932        0.371848       -0.988152       -0.742924\n",
      "550471  2025-12-08 13:59:00    25933.15    25934.40   25928.25     25929.65  09Dec25       25950       70.90   103185.0       69.90   104313.0      100.50    96567.0       97.85   123625.0       -0.316881       -0.921021        0.683960       -0.070336\n",
      "550472  2025-12-08 14:00:00    25929.30    25930.40   25919.75     25923.60  09Dec25       25900       96.20   103185.0       51.25   104313.0      130.45    96567.0       73.50   123625.0       -0.319688       -0.915193        0.684702       -0.061393\n",
      "550473  2025-12-08 14:01:00    25922.95    25926.70   25917.45     25920.00  09Dec25       25900       94.40   103185.0       51.90   104313.0      128.25    96567.0       74.45   123625.0       -0.321763       -0.909655        0.686183       -0.052535\n",
      "550474  2025-12-08 14:02:00    25920.05    25923.20   25918.75     25921.90  09Dec25       25900       95.35   100666.0       51.50   181604.0      128.80    15445.0       73.90   101474.0       -0.390650        0.407706       -0.943502       -0.774766\n",
      "550475  2025-12-08 14:03:00    25922.40    25922.65   25908.45     25914.30  09Dec25       25900       91.00   100666.0       54.65   181604.0      123.70    15445.0       77.95   101474.0       -0.392145        0.400185       -0.928063       -0.761240\n",
      "550476  2025-12-08 14:04:00    25913.40    25923.20   25911.65     25921.85  09Dec25       25900       96.80   100666.0       50.70   181604.0      130.50    15445.0       72.75   101474.0       -0.392485        0.392932       -0.912735       -0.747901\n",
      "550477  2025-12-08 14:05:00    25922.10    25923.30   25916.50     25918.20  09Dec25       25900       95.10   101465.0       52.40   179530.0      128.05    15492.0       74.95    99895.0       -0.371622        0.350421       -0.896683       -0.786900\n",
      "550478  2025-12-08 14:06:00    25918.40    25920.45   25916.20     25918.45  09Dec25       25900       93.90   101465.0       52.55   179530.0      127.40    15492.0       75.20    99895.0       -0.372164        0.343515       -0.881784       -0.773227\n",
      "550479  2025-12-08 14:07:00    25919.00    25927.05   25918.25     25923.80  09Dec25       25900       96.05   101465.0       51.40   179530.0      130.15    15492.0       73.60    99895.0       -0.371903        0.336561       -0.867017       -0.759730\n",
      "550480  2025-12-08 14:08:00    25924.25    25924.30   25918.30     25918.85  09Dec25       25900       94.25   104751.0       52.50   178020.0      127.70    16068.0       74.90    92625.0       -0.284395        0.303875       -0.840905       -0.987915\n",
      "\n",
      "Missing values summary:\n",
      "timestamp         0\n",
      "nifty_open        0\n",
      "nifty_high        0\n",
      "nifty_low         0\n",
      "nifty_close       0\n",
      "expiry            0\n",
      "atm_strike        0\n",
      "atm_ce_ltp        0\n",
      "atm_ce_oi         0\n",
      "atm_pe_ltp        0\n",
      "atm_pe_oi         0\n",
      "itm_ce_ltp        0\n",
      "itm_ce_oi         0\n",
      "itm_pe_ltp        0\n",
      "itm_pe_oi         0\n",
      "atm_ce_oi_norm    0\n",
      "atm_pe_oi_norm    0\n",
      "itm_ce_oi_norm    0\n",
      "itm_pe_oi_norm    0\n",
      "dtype: int64\n",
      "timestamp         0\n",
      "nifty_open        0\n",
      "nifty_high        0\n",
      "nifty_low         0\n",
      "nifty_close       0\n",
      "expiry            0\n",
      "atm_strike        0\n",
      "atm_ce_ltp        0\n",
      "atm_ce_oi         0\n",
      "atm_pe_ltp        0\n",
      "atm_pe_oi         0\n",
      "itm_ce_ltp        0\n",
      "itm_ce_oi         0\n",
      "itm_pe_ltp        0\n",
      "itm_pe_oi         0\n",
      "atm_ce_oi_norm    0\n",
      "atm_pe_oi_norm    0\n",
      "itm_ce_oi_norm    0\n",
      "itm_pe_oi_norm    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"nifty_data_norm_oi.csv\")\n",
    "\n",
    "# Set option (this should ideally work)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\\n\", df.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst 20 rows (Forced string representation):\")\n",
    "# Use .to_string() to force rendering without truncation\n",
    "print(df.head(15).to_string()) \n",
    "\n",
    "print(\"\\nlast 20 rows (Forced string representation):\")\n",
    "print(df.tail(15).to_string())\n",
    "\n",
    "print(\"\\nMissing values summary:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ce98e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: datetime64[ns]\n",
      "min/max: 2020-01-01 11:14:00 datetime64[ns]\n",
      "min/max: 2020-01-01 11:14:00 2025-12-08 14:08:00\n",
      "tz info (should be None or with tz): None 2025-12-08 14:08:00\n",
      "tz info (should be None or with tz): None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "print(\"dtype:\", df['timestamp'].dtype)\n",
    "print(\"min/max:\", df['timestamp'].min(), df['timestamp'].max())\n",
    "print(\"tz info (should be None or with tz):\", df['timestamp'].dt.tz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d778713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows outside 09:15-15:30: 0\n",
      "Empty DataFrame\n",
      "Columns: [timestamp, nifty_open, nifty_high, nifty_low, nifty_close, expiry, atm_strike, atm_ce_ltp, atm_ce_oi, atm_pe_ltp, atm_pe_oi, itm_ce_ltp, itm_ce_oi, itm_pe_ltp, itm_pe_oi, atm_ce_oi_norm, atm_pe_oi_norm, itm_ce_oi_norm, itm_pe_oi_norm, ts, time]\n",
      "Index: []\n",
      " 0\n",
      "Empty DataFrame\n",
      "Columns: [timestamp, nifty_open, nifty_high, nifty_low, nifty_close, expiry, atm_strike, atm_ce_ltp, atm_ce_oi, atm_pe_ltp, atm_pe_oi, itm_ce_ltp, itm_ce_oi, itm_pe_ltp, itm_pe_oi, atm_ce_oi_norm, atm_pe_oi_norm, itm_ce_oi_norm, itm_pe_oi_norm, ts, time]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df['ts'] = pd.to_datetime(df['timestamp']).dt.tz_localize(None)\n",
    "df['time'] = df['ts'].dt.time\n",
    "outside = df[~df['ts'].dt.strftime(\"%H:%M:%S\").between(\"09:15:00\",\"15:30:00\")]\n",
    "print(\"Rows outside 09:15-15:30:\", len(outside))\n",
    "print(outside.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f71a1495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate timestamp rows: 580\n",
      " 580\n"
     ]
    }
   ],
   "source": [
    "dups = df[df.duplicated(subset='timestamp', keep=False)]\n",
    "print(\"duplicate timestamp rows:\", len(dups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a4b1b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample day missing minutes (first 30 days):\n",
      "{'2020-01-01': 120, '2020-01-02': 1, '2020-01-03': 1, '2020-01-06': 0, '2020-01-07': 1, '2020-01-08': 1, '2020-01-09': 1, '2020-01-10': 1, '2020-01-13': 1, '2020-01-14': 0}\n",
      "\n",
      "{'2020-01-01': 120, '2020-01-02': 1, '2020-01-03': 1, '2020-01-06': 0, '2020-01-07': 1, '2020-01-08': 1, '2020-01-09': 1, '2020-01-10': 1, '2020-01-13': 1, '2020-01-14': 0}\n"
     ]
    }
   ],
   "source": [
    "df['ts'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.set_index('ts')\n",
    "days = df.index.normalize().unique()\n",
    "miss = {}\n",
    "import pandas as pd\n",
    "for d in days[:30]:   # check first 30 days quickly\n",
    "    start = d + pd.Timedelta(hours=9, minutes=15)\n",
    "    end   = d + pd.Timedelta(hours=15, minutes=30)\n",
    "    full = pd.date_range(start=start, end=end, freq='1min')\n",
    "    actual = df.loc[start:end].index.unique()\n",
    "    miss_count = len(full) - len(actual)\n",
    "    miss[str(d.date())] = miss_count\n",
    "print(\"sample day missing minutes (first 30 days):\")\n",
    "print({k:v for k,v in list(miss.items())[:10]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4d7a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique mod50:  [np.int64(11950), np.int64(12000), np.int64(12050), np.int64(12100), np.int64(12150), np.int64(12200), np.int64(12250), np.int64(12300), np.int64(12350), np.int64(12400)]\n",
      "any non-multiple of 50? [np.int64(11950), np.int64(12000), np.int64(12050), np.int64(12100), np.int64(12150), np.int64(12200), np.int64(12250), np.int64(12300), np.int64(12350), np.int64(12400)]\n",
      "any non-multiple of 50? 0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"unique mod50:\", sorted(df['atm_strike'].unique()[:10]))\n",
    "print(\"any non-multiple of 50?\", (df['atm_strike'] % 50).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c15e662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr(spot,ce): 0.03158469935514146\n",
      "corr(spot,pe): 0.03158469935514146\n",
      "corr(spot,pe): -0.01680718375752286\n",
      " -0.01680718375752286\n"
     ]
    }
   ],
   "source": [
    "df['nifty_ret_1'] = df['nifty_close'].pct_change()\n",
    "df['ce_ret_1'] = df['atm_ce_ltp'].pct_change()\n",
    "df['pe_ret_1'] = df['atm_pe_ltp'].pct_change()\n",
    "print(\"corr(spot,ce):\", df['nifty_ret_1'].corr(df['ce_ret_1']))\n",
    "print(\"corr(spot,pe):\", df['nifty_ret_1'].corr(df['pe_ret_1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ba66ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed: 290\n",
      "\n",
      "Rows before cleaning: 550481\n",
      "Rows before cleaning: 550481\n",
      "Rows after dedupe & trim: 550191\n",
      "Rows after dedupe & trim: 550191\n",
      "Rows dropped for heavy-gap days: 10\n",
      "Rows dropped for heavy-gap days: 10\n",
      "Option values forward-filled total: 4944Option values forward-filled total: 4944\n",
      "Rows dropped due to missing spot: 618\n",
      "Rows dropped due to missing spot: 618\n",
      "Final rows: 547966\n",
      "Final rows: 547966\n",
      "\n",
      "Saved: master_ml_dataset.parquet Saved: master_ml_dataset.parquet gap_report.csv\n",
      "gap_report.csv\n"
     ]
    }
   ],
   "source": [
    "# clean_and_make_features.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "IN = \"nifty_data_norm_oi.csv\"\n",
    "OUT_PARQUET = \"master_ml_dataset.parquet\"\n",
    "GAP_REPORT = \"gap_report.csv\"\n",
    "MARKET_TZ = \"Asia/Kolkata\"\n",
    "\n",
    "df = pd.read_csv(IN)\n",
    "\n",
    "# 1) parse timestamp and localize if naive\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "if df['timestamp'].dt.tz is None:\n",
    "    df['timestamp'] = df['timestamp'].dt.tz_localize(MARKET_TZ)\n",
    "else:\n",
    "    df['timestamp'] = df['timestamp'].dt.tz_convert(MARKET_TZ)\n",
    "\n",
    "# 2) sort & remove duplicates (keep last)\n",
    "before = len(df)\n",
    "df = df.sort_values('timestamp').drop_duplicates(subset='timestamp', keep='last').reset_index(drop=True)\n",
    "dups_removed = before - len(df)\n",
    "print(f\"Duplicates removed: {dups_removed}\")\n",
    "\n",
    "# 3) trim strictly to market hours 09:15 - 15:30 (inclusive)\n",
    "df = df.set_index('timestamp').sort_index()\n",
    "df = df.between_time(\"09:15\", \"15:30\")\n",
    "df = df.reset_index()\n",
    "\n",
    "# 4) per-day gap analysis and safe forward-fill for option columns\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "option_cols = ['atm_ce_ltp','atm_pe_ltp','itm_ce_ltp','itm_pe_ltp','atm_ce_oi','atm_pe_oi','itm_ce_oi','itm_pe_oi']\n",
    "report = []\n",
    "filled_rows = 0\n",
    "kept_rows = 0\n",
    "rows_after = len(df)\n",
    "\n",
    "# Group by date and handle each day individually\n",
    "out_frames = []\n",
    "for date_val, grp in df.groupby('date'):\n",
    "    grp = grp.sort_values('timestamp').set_index('timestamp')\n",
    "    start = pd.Timestamp(str(date_val) + \" 09:15:00\").tz_localize(MARKET_TZ)\n",
    "    end   = pd.Timestamp(str(date_val) + \" 15:30:00\").tz_localize(MARKET_TZ)\n",
    "    full_idx = pd.date_range(start=start, end=end, freq='1min', tz=MARKET_TZ)\n",
    "    missing = len(full_idx) - len(grp)\n",
    "    # If a huge gap (e.g., > 30 missing minutes), mark day as bad and skip (likely holiday/partial)\n",
    "    if missing > 30:\n",
    "        report.append({'date': str(date_val), 'missing_minutes': missing, 'action': 'DROP_DAY'})\n",
    "        continue\n",
    "    # Reindex and forward-fill option columns but limit fill to <=2 consecutive minutes\n",
    "    re = grp.reindex(full_idx)\n",
    "    # Count how many NaNs exist before fill\n",
    "    na_before = re[option_cols].isna().sum().sum()\n",
    "    # Forward fill with limit=2 for each option col\n",
    "    for c in option_cols:\n",
    "        if c in re.columns:\n",
    "            re[c] = re[c].ffill(limit=2)\n",
    "    na_after = re[option_cols].isna().sum().sum()\n",
    "    filled = na_before - na_after\n",
    "    filled_rows += filled\n",
    "    # For spot columns (nifty_*), DO NOT fill  keep NaN if any (should be rare). We'll drop rows with spot NaN.\n",
    "    re['date'] = date_val\n",
    "    out_frames.append(re)\n",
    "    report.append({'date': str(date_val), 'missing_minutes': missing, 'filled_option_values': int(filled), 'action': 'KEEP'})\n",
    "\n",
    "# concat kept days\n",
    "if out_frames:\n",
    "    df_clean = pd.concat(out_frames).reset_index().rename(columns={'index':'timestamp'})\n",
    "else:\n",
    "    raise SystemExit(\"No valid trading days after gap filter - check data!\")\n",
    "\n",
    "# drop rows where spot is NaN (if any)\n",
    "before_drop = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=['nifty_close'])\n",
    "dropped_for_spot = before_drop - len(df_clean)\n",
    "\n",
    "# 5) rolling OI z-score per expiry (60-min window) - safer normalization\n",
    "df_clean['atm_ce_oi'] = pd.to_numeric(df_clean['atm_ce_oi'], errors='coerce')\n",
    "df_clean['atm_pe_oi'] = pd.to_numeric(df_clean['atm_pe_oi'], errors='coerce')\n",
    "df_clean['itm_ce_oi'] = pd.to_numeric(df_clean['itm_ce_oi'], errors='coerce')\n",
    "df_clean['itm_pe_oi'] = pd.to_numeric(df_clean['itm_pe_oi'], errors='coerce')\n",
    "\n",
    "def rolling_z(s, w=60):\n",
    "    mu = s.rolling(window=w, min_periods=1).mean()\n",
    "    sd = s.rolling(window=w, min_periods=1).std(ddof=0).replace(0, np.nan)\n",
    "    return (s - mu) / (sd + 1e-9)\n",
    "\n",
    "for col in ['atm_ce_oi','atm_pe_oi','itm_ce_oi','itm_pe_oi']:\n",
    "    df_clean[col + '_z60'] = df_clean.groupby('expiry')[col].transform(lambda s: rolling_z(s, w=60))\n",
    "\n",
    "# 6) core features\n",
    "df_clean['nifty_ret_1'] = df_clean['nifty_close'].pct_change().fillna(0)\n",
    "df_clean['nifty_ret_3'] = df_clean['nifty_close'].pct_change(3).fillna(0)\n",
    "df_clean['ce_ret_1'] = df_clean['atm_ce_ltp'].pct_change().fillna(0)\n",
    "df_clean['pe_ret_1'] = df_clean['atm_pe_ltp'].pct_change().fillna(0)\n",
    "df_clean['ce_pe_ratio'] = df_clean['atm_ce_ltp'] / (df_clean['atm_pe_ltp'] + 1e-9)\n",
    "df_clean['ce_minus_pe'] = df_clean['atm_ce_ltp'] - df_clean['atm_pe_ltp']\n",
    "# seasonality\n",
    "df_clean['minute_of_day'] = df_clean['timestamp'].dt.hour*60 + df_clean['timestamp'].dt.minute\n",
    "df_clean['sin_min'] = np.sin(2*np.pi*df_clean['minute_of_day']/390)\n",
    "df_clean['cos_min'] = np.cos(2*np.pi*df_clean['minute_of_day']/390)\n",
    "\n",
    "# 7) quick stats\n",
    "print(\"Rows before cleaning:\", before)\n",
    "print(\"Rows after dedupe & trim:\", rows_after)\n",
    "print(\"Rows dropped for heavy-gap days:\", len(report) - sum(1 for r in report if r['action']=='KEEP'))\n",
    "print(\"Option values forward-filled total:\", filled_rows)\n",
    "print(\"Rows dropped due to missing spot:\", dropped_for_spot)\n",
    "print(\"Final rows:\", len(df_clean))\n",
    "\n",
    "# 8) save outputs\n",
    "df_clean.to_parquet(OUT_PARQUET, index=False)\n",
    "pd.DataFrame(report).to_csv(GAP_REPORT, index=False)\n",
    "print(\"Saved:\", OUT_PARQUET, GAP_REPORT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68877761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 547963\n",
      "NaN summary:\n",
      " 547963\n",
      "NaN summary:\n",
      "ce_pe_ratio_lag1             1\n",
      "atm_itm_spread_ce_lag1       1\n",
      "atm_itm_spread_ce_lag2       2\n",
      "ce_pe_ratio_lag2             2\n",
      "itm_pe_ret_1_lag1            2\n",
      "ce_ret_1_lag1                2\n",
      "nifty_ret_1_lag1             2\n",
      "atm_itm_spread_pe_lag2       2\n",
      "ce_minus_pe_lag2             2\n",
      "pe_ret_1_lag1                2\n",
      "itm_ce_ret_1_lag1            2\n",
      "ce_minus_pe_lag3             3\n",
      "nifty_ret_1_lag2             3\n",
      "ce_ret_1_lag2                3\n",
      "atm_itm_spread_pe_lag3       3\n",
      "atm_itm_spread_ce_lag3       3\n",
      "itm_pe_ret_1_lag2            3\n",
      "pe_ret_1_lag2                3\n",
      "itm_ce_ret_1_lag2            3\n",
      "ce_pe_ratio_lag3             3\n",
      "nifty_ret_1_lag3             4\n",
      "ce_ret_1_lag3                4\n",
      "itm_pe_ret_1_lag3            4\n",
      "itm_ce_ret_1_lag3            4\n",
      "nifty_ret_3_lag1             4\n",
      "pe_ret_1_lag3                4\n",
      "nifty_ret_3_lag2             5\n",
      "nifty_ret_3_lag3             6\n",
      "itm_ce_oi_z60_lag1        2829\n",
      "itm_ce_oi_z60_lag2        2830\n",
      "itm_ce_oi_z60_lag3        2831\n",
      "itm_pe_oi_z60_lag1        2831\n",
      "itm_pe_oi_z60_lag2        2832\n",
      "itm_pe_oi_z60_lag3        2833\n",
      "atm_pe_oi_z60_lag1        2861\n",
      "atm_pe_oi_z60_lag2        2862\n",
      "atm_pe_oi_z60_lag3        2863\n",
      "atm_ce_oi_z60_lag1        2886\n",
      "atm_ce_oi_z60_lag2        2887\n",
      "atm_ce_oi_z60_lag3        2888\n",
      "dtype: int64\n",
      "ce_pe_ratio_lag1             1\n",
      "atm_itm_spread_ce_lag1       1\n",
      "atm_itm_spread_ce_lag2       2\n",
      "ce_pe_ratio_lag2             2\n",
      "itm_pe_ret_1_lag1            2\n",
      "ce_ret_1_lag1                2\n",
      "nifty_ret_1_lag1             2\n",
      "atm_itm_spread_pe_lag2       2\n",
      "ce_minus_pe_lag2             2\n",
      "pe_ret_1_lag1                2\n",
      "itm_ce_ret_1_lag1            2\n",
      "ce_minus_pe_lag3             3\n",
      "nifty_ret_1_lag2             3\n",
      "ce_ret_1_lag2                3\n",
      "atm_itm_spread_pe_lag3       3\n",
      "atm_itm_spread_ce_lag3       3\n",
      "itm_pe_ret_1_lag2            3\n",
      "pe_ret_1_lag2                3\n",
      "itm_ce_ret_1_lag2            3\n",
      "ce_pe_ratio_lag3             3\n",
      "nifty_ret_1_lag3             4\n",
      "ce_ret_1_lag3                4\n",
      "itm_pe_ret_1_lag3            4\n",
      "itm_ce_ret_1_lag3            4\n",
      "nifty_ret_3_lag1             4\n",
      "pe_ret_1_lag3                4\n",
      "nifty_ret_3_lag2             5\n",
      "nifty_ret_3_lag3             6\n",
      "itm_ce_oi_z60_lag1        2829\n",
      "itm_ce_oi_z60_lag2        2830\n",
      "itm_ce_oi_z60_lag3        2831\n",
      "itm_pe_oi_z60_lag1        2831\n",
      "itm_pe_oi_z60_lag2        2832\n",
      "itm_pe_oi_z60_lag3        2833\n",
      "atm_pe_oi_z60_lag1        2861\n",
      "atm_pe_oi_z60_lag2        2862\n",
      "atm_pe_oi_z60_lag3        2863\n",
      "atm_ce_oi_z60_lag1        2886\n",
      "atm_ce_oi_z60_lag2        2887\n",
      "atm_ce_oi_z60_lag3        2888\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"master_labeled.parquet\")\n",
    "\n",
    "print(\"Total rows:\", len(df))\n",
    "print(\"NaN summary:\")\n",
    "print(df.isna().sum().sort_values().tail(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0169fa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nifty_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "future_ret_1m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target_dir_1m",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target_up_small_1m",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "future_ret_3m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target_up_med_3m",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d4f116af-f2eb-41aa-b008-7cc7e2ecafd0",
       "rows": [
        [
         "472781",
         "23594.45",
         "4.026370608345129e-05",
         "1",
         "0",
         "-7.416998489051136e-05",
         "0"
        ],
        [
         "219459",
         "16262.15",
         "0.0008516709045236646",
         "1",
         "1",
         "0.0006579695796681294",
         "1"
        ],
        [
         "406637",
         "22945.65",
         "-0.00010459498859266791",
         "0",
         "0",
         "0.0006101374334568596",
         "1"
        ],
        [
         "398673",
         "22393.3",
         "0.0001741592351284215",
         "1",
         "0",
         "0.00029473101329423925",
         "0"
        ],
        [
         "359313",
         "19738.75",
         "-0.000493952251282351",
         "0",
         "0",
         "0.00011398898106515793",
         "0"
        ],
        [
         "362425",
         "20277.55",
         "0.0002342492066349123",
         "1",
         "1",
         "0.00012822061836869123",
         "0"
        ],
        [
         "88551",
         "13513.5",
         "0.00015540015540017082",
         "1",
         "0",
         "-0.0009583009583009412",
         "0"
        ],
        [
         "232112",
         "16022.35",
         "-0.00012170499333746958",
         "0",
         "0",
         "-0.000277737036077757",
         "0"
        ],
        [
         "208930",
         "18013.85",
         "-0.0004107950271595138",
         "0",
         "0",
         "-8.326926226208816e-05",
         "0"
        ],
        [
         "145062",
         "15750.35",
         "0.0",
         "0",
         "0",
         "-0.00010793410940078281",
         "0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nifty_close</th>\n",
       "      <th>future_ret_1m</th>\n",
       "      <th>target_dir_1m</th>\n",
       "      <th>target_up_small_1m</th>\n",
       "      <th>future_ret_3m</th>\n",
       "      <th>target_up_med_3m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>472781</th>\n",
       "      <td>23594.45</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219459</th>\n",
       "      <td>16262.15</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406637</th>\n",
       "      <td>22945.65</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398673</th>\n",
       "      <td>22393.30</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359313</th>\n",
       "      <td>19738.75</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362425</th>\n",
       "      <td>20277.55</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88551</th>\n",
       "      <td>13513.50</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232112</th>\n",
       "      <td>16022.35</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208930</th>\n",
       "      <td>18013.85</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145062</th>\n",
       "      <td>15750.35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nifty_close  future_ret_1m  target_dir_1m  target_up_small_1m  \\\n",
       "472781     23594.45       0.000040              1                   0   \n",
       "219459     16262.15       0.000852              1                   1   \n",
       "406637     22945.65      -0.000105              0                   0   \n",
       "398673     22393.30       0.000174              1                   0   \n",
       "359313     19738.75      -0.000494              0                   0   \n",
       "362425     20277.55       0.000234              1                   1   \n",
       "88551      13513.50       0.000155              1                   0   \n",
       "232112     16022.35      -0.000122              0                   0   \n",
       "208930     18013.85      -0.000411              0                   0   \n",
       "145062     15750.35       0.000000              0                   0   \n",
       "\n",
       "        future_ret_3m  target_up_med_3m  \n",
       "472781      -0.000074                 0  \n",
       "219459       0.000658                 1  \n",
       "406637       0.000610                 1  \n",
       "398673       0.000295                 0  \n",
       "359313       0.000114                 0  \n",
       "362425       0.000128                 0  \n",
       "88551       -0.000958                 0  \n",
       "232112      -0.000278                 0  \n",
       "208930      -0.000083                 0  \n",
       "145062      -0.000108                 0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['nifty_close', 'future_ret_1m', 'target_dir_1m', \n",
    "    'target_up_small_1m', 'future_ret_3m', 'target_up_med_3m']].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c70f7bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nifty_ret_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ce_ret_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pe_ret_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ce_pe_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "atm_ce_oi_z60",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7f7520fb-9047-42c3-9bab-f92c88f27feb",
       "rows": [
        [
         "nifty_ret_1",
         "1.0",
         "0.03392357556228801",
         "-0.024764365675853373",
         "-0.010959632294148092",
         "0.04822422125713625"
        ],
        [
         "ce_ret_1",
         "0.03392357556228801",
         "1.0",
         "0.0377373776754855",
         "0.022871632061322967",
         "-0.005033910182573339"
        ],
        [
         "pe_ret_1",
         "-0.024764365675853373",
         "0.0377373776754855",
         "1.0",
         "-0.0013380440678225389",
         "-0.002500680677634018"
        ],
        [
         "ce_pe_ratio",
         "-0.010959632294148092",
         "0.022871632061322967",
         "-0.0013380440678225389",
         "1.0",
         "-0.043751906830663226"
        ],
        [
         "atm_ce_oi_z60",
         "0.04822422125713625",
         "-0.005033910182573339",
         "-0.002500680677634018",
         "-0.043751906830663226",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nifty_ret_1</th>\n",
       "      <th>ce_ret_1</th>\n",
       "      <th>pe_ret_1</th>\n",
       "      <th>ce_pe_ratio</th>\n",
       "      <th>atm_ce_oi_z60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nifty_ret_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033924</td>\n",
       "      <td>-0.024764</td>\n",
       "      <td>-0.010960</td>\n",
       "      <td>0.048224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce_ret_1</th>\n",
       "      <td>0.033924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037737</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>-0.005034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe_ret_1</th>\n",
       "      <td>-0.024764</td>\n",
       "      <td>0.037737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001338</td>\n",
       "      <td>-0.002501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce_pe_ratio</th>\n",
       "      <td>-0.010960</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>-0.001338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_ce_oi_z60</th>\n",
       "      <td>0.048224</td>\n",
       "      <td>-0.005034</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>-0.043752</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nifty_ret_1  ce_ret_1  pe_ret_1  ce_pe_ratio  atm_ce_oi_z60\n",
       "nifty_ret_1       1.000000  0.033924 -0.024764    -0.010960       0.048224\n",
       "ce_ret_1          0.033924  1.000000  0.037737     0.022872      -0.005034\n",
       "pe_ret_1         -0.024764  0.037737  1.000000    -0.001338      -0.002501\n",
       "ce_pe_ratio      -0.010960  0.022872 -0.001338     1.000000      -0.043752\n",
       "atm_ce_oi_z60     0.048224 -0.005034 -0.002501    -0.043752       1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['nifty_ret_1','ce_ret_1','pe_ret_1','ce_pe_ratio','atm_ce_oi_z60']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b951cc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['future_close_1m', 'future_ret_1m', 'future_close_3m', 'future_ret_3m']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f for f in df.columns if 'future' in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af6da30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 10)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target_min",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "threshold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sl_frac",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tp_frac",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trades",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wins",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trades_per_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_pnl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_pnl",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e787ad5d-a675-4d5a-ba7b-d18ef993f823",
       "rows": [
        [
         "0",
         "1",
         "0.9",
         null,
         null,
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "1",
         "0.88",
         null,
         null,
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "1",
         "0.86",
         null,
         null,
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "1",
         "0.84",
         null,
         null,
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "1",
         "0.82",
         null,
         null,
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "1",
         "0.8",
         null,
         null,
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "6",
         "1",
         "0.78",
         null,
         null,
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "7",
         "1",
         "0.76",
         "0.0003",
         null,
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.22238083333309",
         "-129.66714249999927"
        ],
        [
         "8",
         "1",
         "0.76",
         "0.0003",
         "0.0006",
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.22238083333309",
         "-129.66714249999927"
        ],
        [
         "9",
         "1",
         "0.76",
         "0.0003",
         "0.001",
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.22238083333309",
         "-129.66714249999927"
        ],
        [
         "10",
         "1",
         "0.76",
         null,
         null,
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.57270916666605",
         "-130.71812749999816"
        ],
        [
         "11",
         "1",
         "0.76",
         null,
         "0.0006",
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.57270916666605",
         "-130.71812749999816"
        ],
        [
         "12",
         "1",
         "0.76",
         null,
         "0.001",
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.57270916666605",
         "-130.71812749999816"
        ],
        [
         "13",
         "1",
         "0.76",
         "0.0005",
         null,
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.57270916666605",
         "-130.71812749999816"
        ],
        [
         "14",
         "1",
         "0.76",
         "0.0005",
         "0.0006",
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.57270916666605",
         "-130.71812749999816"
        ],
        [
         "15",
         "1",
         "0.76",
         "0.0005",
         "0.001",
         "3",
         "0",
         "0.0",
         "0.0013856812933025",
         "-43.57270916666605",
         "-130.71812749999816"
        ],
        [
         "16",
         "1",
         "0.74",
         "0.0003",
         null,
         "11",
         "0",
         "0.0",
         "0.0050808314087759",
         "-42.51012611111074",
         "-382.5911349999967"
        ],
        [
         "17",
         "1",
         "0.74",
         "0.0003",
         "0.0006",
         "11",
         "0",
         "0.0",
         "0.0050808314087759",
         "-42.51012611111074",
         "-382.5911349999967"
        ],
        [
         "18",
         "1",
         "0.74",
         "0.0003",
         "0.001",
         "11",
         "0",
         "0.0",
         "0.0050808314087759",
         "-42.51012611111074",
         "-382.5911349999967"
        ],
        [
         "19",
         "1",
         "0.74",
         "0.0005",
         null,
         "11",
         "0",
         "0.0",
         "0.0050808314087759",
         "-42.98371888888841",
         "-386.8534699999957"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_min</th>\n",
       "      <th>threshold</th>\n",
       "      <th>sl_frac</th>\n",
       "      <th>tp_frac</th>\n",
       "      <th>trades</th>\n",
       "      <th>wins</th>\n",
       "      <th>precision</th>\n",
       "      <th>trades_per_day</th>\n",
       "      <th>avg_pnl</th>\n",
       "      <th>total_pnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.222381</td>\n",
       "      <td>-129.667142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.222381</td>\n",
       "      <td>-129.667142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.222381</td>\n",
       "      <td>-129.667142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.572709</td>\n",
       "      <td>-130.718127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.572709</td>\n",
       "      <td>-130.718127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.572709</td>\n",
       "      <td>-130.718127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.572709</td>\n",
       "      <td>-130.718127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.572709</td>\n",
       "      <td>-130.718127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-43.572709</td>\n",
       "      <td>-130.718127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-42.510126</td>\n",
       "      <td>-382.591135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-42.510126</td>\n",
       "      <td>-382.591135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-42.510126</td>\n",
       "      <td>-382.591135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-42.983719</td>\n",
       "      <td>-386.853470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target_min  threshold  sl_frac  tp_frac  trades  wins  precision  \\\n",
       "0            1       0.90      NaN      NaN       0     0        0.0   \n",
       "1            1       0.88      NaN      NaN       0     0        0.0   \n",
       "2            1       0.86      NaN      NaN       0     0        0.0   \n",
       "3            1       0.84      NaN      NaN       0     0        0.0   \n",
       "4            1       0.82      NaN      NaN       0     0        0.0   \n",
       "5            1       0.80      NaN      NaN       0     0        0.0   \n",
       "6            1       0.78      NaN      NaN       0     0        0.0   \n",
       "7            1       0.76   0.0003      NaN       3     0        0.0   \n",
       "8            1       0.76   0.0003   0.0006       3     0        0.0   \n",
       "9            1       0.76   0.0003   0.0010       3     0        0.0   \n",
       "10           1       0.76      NaN      NaN       3     0        0.0   \n",
       "11           1       0.76      NaN   0.0006       3     0        0.0   \n",
       "12           1       0.76      NaN   0.0010       3     0        0.0   \n",
       "13           1       0.76   0.0005      NaN       3     0        0.0   \n",
       "14           1       0.76   0.0005   0.0006       3     0        0.0   \n",
       "15           1       0.76   0.0005   0.0010       3     0        0.0   \n",
       "16           1       0.74   0.0003      NaN      11     0        0.0   \n",
       "17           1       0.74   0.0003   0.0006      11     0        0.0   \n",
       "18           1       0.74   0.0003   0.0010      11     0        0.0   \n",
       "19           1       0.74   0.0005      NaN      11     0        0.0   \n",
       "\n",
       "    trades_per_day    avg_pnl   total_pnl  \n",
       "0         0.000000   0.000000    0.000000  \n",
       "1         0.000000   0.000000    0.000000  \n",
       "2         0.000000   0.000000    0.000000  \n",
       "3         0.000000   0.000000    0.000000  \n",
       "4         0.000000   0.000000    0.000000  \n",
       "5         0.000000   0.000000    0.000000  \n",
       "6         0.000000   0.000000    0.000000  \n",
       "7         0.001386 -43.222381 -129.667142  \n",
       "8         0.001386 -43.222381 -129.667142  \n",
       "9         0.001386 -43.222381 -129.667142  \n",
       "10        0.001386 -43.572709 -130.718127  \n",
       "11        0.001386 -43.572709 -130.718127  \n",
       "12        0.001386 -43.572709 -130.718127  \n",
       "13        0.001386 -43.572709 -130.718127  \n",
       "14        0.001386 -43.572709 -130.718127  \n",
       "15        0.001386 -43.572709 -130.718127  \n",
       "16        0.005081 -42.510126 -382.591135  \n",
       "17        0.005081 -42.510126 -382.591135  \n",
       "18        0.005081 -42.510126 -382.591135  \n",
       "19        0.005081 -42.983719 -386.853470  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "threshold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sl_frac",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tp_frac",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trades",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wins",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trades_per_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_pnl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_pnl",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2e3b1bbc-3401-4747-aa94-6ee0b286852e",
       "rows": [
        [
         "count",
         "266.0",
         "266.0",
         "168.0",
         "168.0",
         "266.0",
         "266.0",
         "266.0",
         "266.0",
         "266.0",
         "266.0"
        ],
        [
         "mean",
         "2.0",
         "0.6410526315789473",
         "0.00039999999999999996",
         "0.0008000000000000001",
         "29391.157894736843",
         "6.203007518796992",
         "0.00027893538076168765",
         "13.575592561079374",
         "-39.96725672424901",
         "-183748.47486101504"
        ],
        [
         "std",
         "1.0018850158105272",
         "0.09204808552953414",
         "0.00010029895432915022",
         "0.00020059790865830043",
         "60111.41745802298",
         "29.334572146124266",
         "0.0009558562230362372",
         "27.765088895160737",
         "9.597999421938152",
         "324190.8976083748"
        ],
        [
         "min",
         "1.0",
         "0.5",
         "0.0003",
         "0.0006",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "-47.64277698275856",
         "-1237566.1927075"
        ],
        [
         "25%",
         "1.0",
         "0.56",
         "0.0003",
         "0.0006",
         "32.0",
         "0.0",
         "0.0",
         "0.0147806004618937",
         "-43.02295932589818",
         "-207441.72676749996"
        ],
        [
         "50%",
         "2.0",
         "0.64",
         "0.00039999999999999996",
         "0.0007999999999999999",
         "664.0",
         "0.0",
         "0.0",
         "0.3066974595842956",
         "-42.401339490798065",
         "-23668.938504999973"
        ],
        [
         "75%",
         "3.0",
         "0.72",
         "0.0005",
         "0.001",
         "24095.0",
         "0.0",
         "0.0",
         "11.129330254041571",
         "-41.548804865532446",
         "-1378.061592499996"
        ],
        [
         "max",
         "3.0",
         "0.9",
         "0.0005",
         "0.001",
         "218641.0",
         "234.0",
         "0.0057803468208092",
         "100.9889145496536",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_min</th>\n",
       "      <th>threshold</th>\n",
       "      <th>sl_frac</th>\n",
       "      <th>tp_frac</th>\n",
       "      <th>trades</th>\n",
       "      <th>wins</th>\n",
       "      <th>precision</th>\n",
       "      <th>trades_per_day</th>\n",
       "      <th>avg_pnl</th>\n",
       "      <th>total_pnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>168.0000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>2.660000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.641053</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>29391.157895</td>\n",
       "      <td>6.203008</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>13.575593</td>\n",
       "      <td>-39.967257</td>\n",
       "      <td>-1.837485e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001885</td>\n",
       "      <td>0.092048</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>60111.417458</td>\n",
       "      <td>29.334572</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>27.765089</td>\n",
       "      <td>9.597999</td>\n",
       "      <td>3.241909e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-47.642777</td>\n",
       "      <td>-1.237566e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>-43.022959</td>\n",
       "      <td>-2.074417e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>664.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306697</td>\n",
       "      <td>-42.401339</td>\n",
       "      <td>-2.366894e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>24095.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.129330</td>\n",
       "      <td>-41.548805</td>\n",
       "      <td>-1.378062e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>218641.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>100.988915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_min   threshold   sl_frac     tp_frac         trades  \\\n",
       "count  266.000000  266.000000  168.0000  168.000000     266.000000   \n",
       "mean     2.000000    0.641053    0.0004    0.000800   29391.157895   \n",
       "std      1.001885    0.092048    0.0001    0.000201   60111.417458   \n",
       "min      1.000000    0.500000    0.0003    0.000600       0.000000   \n",
       "25%      1.000000    0.560000    0.0003    0.000600      32.000000   \n",
       "50%      2.000000    0.640000    0.0004    0.000800     664.000000   \n",
       "75%      3.000000    0.720000    0.0005    0.001000   24095.000000   \n",
       "max      3.000000    0.900000    0.0005    0.001000  218641.000000   \n",
       "\n",
       "             wins   precision  trades_per_day     avg_pnl     total_pnl  \n",
       "count  266.000000  266.000000      266.000000  266.000000  2.660000e+02  \n",
       "mean     6.203008    0.000279       13.575593  -39.967257 -1.837485e+05  \n",
       "std     29.334572    0.000956       27.765089    9.597999  3.241909e+05  \n",
       "min      0.000000    0.000000        0.000000  -47.642777 -1.237566e+06  \n",
       "25%      0.000000    0.000000        0.014781  -43.022959 -2.074417e+05  \n",
       "50%      0.000000    0.000000        0.306697  -42.401339 -2.366894e+04  \n",
       "75%      0.000000    0.000000       11.129330  -41.548805 -1.378062e+03  \n",
       "max    234.000000    0.005780      100.988915    0.000000  0.000000e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sr = pd.read_csv(\"backtest_outputs/sweep_results.csv\")\n",
    "print(sr.shape)\n",
    "display(sr.head(20))\n",
    "display(sr.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf604b60",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/preds.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m preds = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath/to/preds.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# rename to your file/col\u001b[39;00m\n\u001b[32m      3\u001b[39m master = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mpath/to/master.csv\u001b[39m\u001b[33m\"\u001b[39m, parse_dates=[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# quick sanity\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\StockMarket\\StockMarket\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\StockMarket\\StockMarket\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\StockMarket\\StockMarket\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\StockMarket\\StockMarket\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\StockMarket\\StockMarket\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'path/to/preds.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "preds = pd.read_csv(\"path/to/preds.csv\", parse_dates=['timestamp']) # rename to your file/col\n",
    "master = pd.read_csv(\"path/to/master.csv\", parse_dates=['timestamp'])\n",
    "# quick sanity\n",
    "print(\"preds:\", preds.shape, \"master:\", master.shape)\n",
    "print(\"preds ts min/max:\", preds['timestamp'].min(), preds['timestamp'].max())\n",
    "print(\"master ts min/max:\", master['timestamp'].min(), master['timestamp'].max())\n",
    "\n",
    "# how many preds matched during merge (if you have a merge_count column or compute join)\n",
    "merged = preds.merge(master, on='timestamp', how='left', indicator=True)\n",
    "print(merged['_merge'].value_counts())\n",
    "# show rows that didn't match\n",
    "print(merged[merged['_merge']!='both'].head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
